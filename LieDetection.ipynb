{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27bec75d-06c4-430b-9e6f-db670fdb3490",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75c51ad6-fe6a-46f5-8ccc-e052db98da9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data: 152\n",
      "Number of testing data: 56\n",
      "Test truth subjects: ['09', '12']\n",
      "Test lie subjects: ['13', '06']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Set the data path\n",
    "data_path = r\"C:\\Users\\User\\Documents\\Lie detect data\\npy 데이터\"\n",
    "\n",
    "# Function to load data\n",
    "def load_data(data_path):\n",
    "    data = {}\n",
    "    for file_name in os.listdir(data_path):\n",
    "        if file_name.endswith('.pkl'):\n",
    "            with open(os.path.join(data_path, file_name), 'rb') as file:\n",
    "                data[file_name] = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "# Function to extract subject IDs\n",
    "def extract_subject_ids(data):\n",
    "    truth_subjects = set()\n",
    "    lie_subjects = set()\n",
    "\n",
    "    for name in data.keys():\n",
    "        parts = name.split('_')\n",
    "        if len(parts) >= 5:\n",
    "            subject_id = parts[4].replace('.pkl', '')\n",
    "        elif len(parts) == 4:\n",
    "            subject_id = parts[3].replace('.pkl', '')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if 'truth' in name:\n",
    "            truth_subjects.add(subject_id)\n",
    "        elif 'lie' in name:\n",
    "            lie_subjects.add(subject_id)\n",
    "\n",
    "    # Remove lie IDs from truth IDs\n",
    "    truth_subjects = [subj for subj in truth_subjects if subj not in lie_subjects]\n",
    "    \n",
    "    return truth_subjects, list(lie_subjects)\n",
    "\n",
    "# Function to randomly select 4 subjects (2 truth, 2 lie)\n",
    "def select_random_subjects(truth_subjects, lie_subjects, num_each=2):\n",
    "    test_truth_subjects = random.sample(truth_subjects, num_each)\n",
    "    test_lie_subjects = random.sample(lie_subjects, num_each)\n",
    "    \n",
    "    train_truth_subjects = [subj for subj in truth_subjects if subj not in test_truth_subjects]\n",
    "    train_lie_subjects = [subj for subj in lie_subjects if subj not in test_lie_subjects]\n",
    "    \n",
    "    return test_truth_subjects, test_lie_subjects, train_truth_subjects, train_lie_subjects\n",
    "\n",
    "# Load the data\n",
    "data = load_data(data_path)\n",
    "\n",
    "# Classify subject IDs\n",
    "truth_subjects, lie_subjects = extract_subject_ids(data)\n",
    "\n",
    "# Randomly select 4 subjects\n",
    "test_truth_subjects, test_lie_subjects, train_truth_subjects, train_lie_subjects = select_random_subjects(truth_subjects, lie_subjects)\n",
    "\n",
    "# Function to split data into training and testing sets\n",
    "def split_data(data, test_truth_subjects, test_lie_subjects):\n",
    "    train_data = {}\n",
    "    test_data = {}\n",
    "    \n",
    "    for key, value in data.items():\n",
    "        parts = key.split('_')\n",
    "        if len(parts) >= 5:\n",
    "            subject_id = parts[4].replace('.pkl', '')\n",
    "        elif len(parts) == 4:\n",
    "            subject_id = parts[3].replace('.pkl', '')\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        if subject_id in test_truth_subjects or subject_id in test_lie_subjects:\n",
    "            test_data[key] = value\n",
    "        else:\n",
    "            train_data[key] = value\n",
    "                \n",
    "    return train_data, test_data\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = split_data(data, test_truth_subjects, test_lie_subjects)\n",
    "\n",
    "# Output the results\n",
    "print(\"Number of training data:\", len(train_data))\n",
    "print(\"Number of testing data:\", len(test_data))\n",
    "print(\"Test truth subjects:\", test_truth_subjects)\n",
    "print(\"Test lie subjects:\", test_lie_subjects)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5930073b-cc83-43a0-90d3-ed770084ae77",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0890368c-a4eb-4223-96f4-73e38e5b3041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
