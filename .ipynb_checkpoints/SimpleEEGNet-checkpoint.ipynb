{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656cdbc2-da54-45ba-97fc-195b59bd7820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 0: Train Loss: 0.8027303616205851, Validation Loss: 0.6998121738433838\n",
      "Epoch 1: Train Loss: 0.8259380261103312, Validation Loss: 0.6943569183349609\n",
      "Epoch 2: Train Loss: 0.7277548710505167, Validation Loss: 0.6901412606239319\n",
      "Epoch 3: Train Loss: 0.6790034373601278, Validation Loss: 0.6751120090484619\n",
      "Epoch 4: Train Loss: 0.6831564704577128, Validation Loss: 0.6676633954048157\n",
      "Epoch 5: Train Loss: 0.6554517944653829, Validation Loss: 0.6535466909408569\n",
      "Epoch 6: Train Loss: 0.5421674648920695, Validation Loss: 0.6406780481338501\n",
      "Epoch 7: Train Loss: 0.5677085916201273, Validation Loss: 0.6296449899673462\n",
      "Epoch 8: Train Loss: 0.5669103264808655, Validation Loss: 0.6187238097190857\n",
      "Epoch 9: Train Loss: 0.5184780259927114, Validation Loss: 0.6089299321174622\n",
      "Epoch 10: Train Loss: 0.5805063247680664, Validation Loss: 0.5778708457946777\n",
      "Epoch 11: Train Loss: 0.4956453740596771, Validation Loss: 0.5453216433525085\n",
      "Epoch 12: Train Loss: 0.47614731391270954, Validation Loss: 0.546123743057251\n",
      "Epoch 13: Train Loss: 0.4564082821210225, Validation Loss: 0.4987320303916931\n",
      "Epoch 14: Train Loss: 0.48455430070559186, Validation Loss: 0.4804149568080902\n",
      "Epoch 15: Train Loss: 0.4339006145795186, Validation Loss: 0.5136573910713196\n",
      "Epoch 16: Train Loss: 0.4316928486029307, Validation Loss: 0.5767871737480164\n",
      "Epoch 17: Train Loss: 0.4693771302700043, Validation Loss: 0.5577383637428284\n",
      "Epoch 18: Train Loss: 0.4143555561701457, Validation Loss: 0.525945782661438\n",
      "Epoch 19: Train Loss: 0.3985441327095032, Validation Loss: 0.5065509676933289\n",
      "Epoch 20: Train Loss: 0.4619669516881307, Validation Loss: 0.4697876274585724\n",
      "Epoch 21: Train Loss: 0.4482729136943817, Validation Loss: 0.624864935874939\n",
      "Epoch 22: Train Loss: 0.38410988450050354, Validation Loss: 0.6851752996444702\n",
      "Epoch 23: Train Loss: 0.3750515977541606, Validation Loss: 0.47166308760643005\n",
      "Epoch 24: Train Loss: 0.3404653072357178, Validation Loss: 0.47176581621170044\n",
      "Epoch 25: Train Loss: 0.36258465051651, Validation Loss: 0.6026631593704224\n",
      "Epoch 26: Train Loss: 0.3337818483511607, Validation Loss: 0.6355078816413879\n",
      "Epoch 27: Train Loss: 0.3294517546892166, Validation Loss: 0.5762056112289429\n",
      "Epoch 28: Train Loss: 0.2884182830651601, Validation Loss: 0.5230957865715027\n",
      "Epoch 29: Train Loss: 0.3166196048259735, Validation Loss: 0.4951622188091278\n",
      "Epoch 30: Train Loss: 0.2895297904809316, Validation Loss: 0.5144108533859253\n",
      "Epoch 31: Train Loss: 0.29290135701497394, Validation Loss: 0.5950222015380859\n",
      "Epoch 32: Train Loss: 0.29341544210910797, Validation Loss: 0.6853207349777222\n",
      "Epoch 33: Train Loss: 0.2838118573029836, Validation Loss: 0.5422254800796509\n",
      "Epoch 34: Train Loss: 0.2932940324147542, Validation Loss: 0.5856143236160278\n",
      "Epoch 35: Train Loss: 0.25894013543923694, Validation Loss: 0.5218013525009155\n",
      "Epoch 36: Train Loss: 0.2313827176888784, Validation Loss: 0.4980440139770508\n",
      "Epoch 37: Train Loss: 0.2349123408397039, Validation Loss: 0.531501293182373\n",
      "Epoch 38: Train Loss: 0.246863121787707, Validation Loss: 0.5159230828285217\n",
      "Epoch 39: Train Loss: 0.2681134243806203, Validation Loss: 0.5020244717597961\n",
      "Epoch 40: Train Loss: 0.24367600679397583, Validation Loss: 0.43410274386405945\n",
      "Epoch 41: Train Loss: 0.2327096313238144, Validation Loss: 0.6634993553161621\n",
      "Epoch 42: Train Loss: 0.22212361792723337, Validation Loss: 0.6024062633514404\n",
      "Epoch 43: Train Loss: 0.21392558018366495, Validation Loss: 0.7703245282173157\n",
      "Epoch 44: Train Loss: 0.19599812726179758, Validation Loss: 0.550392746925354\n",
      "Epoch 45: Train Loss: 0.2005219062169393, Validation Loss: 0.7078660130500793\n",
      "Epoch 46: Train Loss: 0.1963993658622106, Validation Loss: 0.6739555597305298\n",
      "Epoch 47: Train Loss: 0.17802961667378744, Validation Loss: 0.5761484503746033\n",
      "Epoch 48: Train Loss: 0.16374029715855917, Validation Loss: 0.5183236598968506\n",
      "Epoch 49: Train Loss: 0.20439137518405914, Validation Loss: 0.4909767210483551\n",
      "Epoch 50: Train Loss: 0.1665325164794922, Validation Loss: 0.5481237769126892\n",
      "Epoch 51: Train Loss: 0.16650245835383734, Validation Loss: 0.6254070401191711\n",
      "Epoch 52: Train Loss: 0.15746061503887177, Validation Loss: 0.6525432467460632\n",
      "Epoch 53: Train Loss: 0.15439205865065256, Validation Loss: 0.41823744773864746\n",
      "Epoch 54: Train Loss: 0.16230017443497977, Validation Loss: 0.4858330190181732\n",
      "Epoch 55: Train Loss: 0.13831742107868195, Validation Loss: 0.6402637362480164\n",
      "Epoch 56: Train Loss: 0.1531850273410479, Validation Loss: 0.6353486776351929\n",
      "Epoch 57: Train Loss: 0.1252676546573639, Validation Loss: 0.521420955657959\n",
      "Epoch 58: Train Loss: 0.15093474090099335, Validation Loss: 0.49661266803741455\n",
      "Epoch 59: Train Loss: 0.14057242373625436, Validation Loss: 0.48922327160835266\n",
      "Epoch 60: Train Loss: 0.14065972963968912, Validation Loss: 0.5191651582717896\n",
      "Epoch 61: Train Loss: 0.1387366776665052, Validation Loss: 0.5220283269882202\n",
      "Epoch 62: Train Loss: 0.13553691655397415, Validation Loss: 0.7087687849998474\n",
      "Epoch 63: Train Loss: 0.1337918589512507, Validation Loss: 0.7140613198280334\n",
      "Epoch 64: Train Loss: 0.12881199518839517, Validation Loss: 0.6961393356323242\n",
      "Epoch 65: Train Loss: 0.11026712010304134, Validation Loss: 0.7110418081283569\n",
      "Epoch 66: Train Loss: 0.1143133466442426, Validation Loss: 0.5599167943000793\n",
      "Epoch 67: Train Loss: 0.12049981703360875, Validation Loss: 0.5033396482467651\n",
      "Epoch 68: Train Loss: 0.11349938064813614, Validation Loss: 0.5165459513664246\n",
      "Epoch 69: Train Loss: 0.11469787607590358, Validation Loss: 0.519591212272644\n",
      "Epoch 70: Train Loss: 0.15995307018359503, Validation Loss: 0.7973973155021667\n",
      "Epoch 71: Train Loss: 0.13534842183192572, Validation Loss: 0.4426637291908264\n",
      "Epoch 72: Train Loss: 0.17776326586802801, Validation Loss: 1.0459222793579102\n",
      "Early stopping at epoch 73\n",
      "Fold 2\n",
      "Epoch 0: Train Loss: 1.0757750074068706, Validation Loss: 0.6947908997535706\n",
      "Epoch 1: Train Loss: 0.8595775564511617, Validation Loss: 0.6948668360710144\n",
      "Epoch 2: Train Loss: 0.7024505734443665, Validation Loss: 0.6894466280937195\n",
      "Epoch 3: Train Loss: 0.7235763470331827, Validation Loss: 0.6895359754562378\n",
      "Epoch 4: Train Loss: 0.6839598814646403, Validation Loss: 0.683699905872345\n",
      "Epoch 5: Train Loss: 0.617148737112681, Validation Loss: 0.68711256980896\n",
      "Epoch 6: Train Loss: 0.6129990617434183, Validation Loss: 0.6935437917709351\n",
      "Epoch 7: Train Loss: 0.6358663439750671, Validation Loss: 0.6962056756019592\n",
      "Epoch 8: Train Loss: 0.6400773922602335, Validation Loss: 0.7018494606018066\n",
      "Epoch 9: Train Loss: 0.6388159791628519, Validation Loss: 0.7116540670394897\n",
      "Epoch 10: Train Loss: 0.6449247797330221, Validation Loss: 0.710987389087677\n",
      "Epoch 11: Train Loss: 0.5627860625584921, Validation Loss: 0.7076396942138672\n",
      "Epoch 12: Train Loss: 0.534919947385788, Validation Loss: 0.747734010219574\n",
      "Epoch 13: Train Loss: 0.5147325992584229, Validation Loss: 0.7442505955696106\n",
      "Epoch 14: Train Loss: 0.528509279092153, Validation Loss: 0.7742083072662354\n",
      "Epoch 15: Train Loss: 0.4867634375890096, Validation Loss: 0.7820225954055786\n",
      "Epoch 16: Train Loss: 0.41937939325968426, Validation Loss: 0.7707255482673645\n",
      "Epoch 17: Train Loss: 0.48012808958689374, Validation Loss: 0.7796264290809631\n",
      "Epoch 18: Train Loss: 0.4426982303460439, Validation Loss: 0.788766086101532\n",
      "Epoch 19: Train Loss: 0.43799688418706256, Validation Loss: 0.7941784262657166\n",
      "Epoch 20: Train Loss: 0.4733813901742299, Validation Loss: 0.89752197265625\n",
      "Epoch 21: Train Loss: 0.45034751296043396, Validation Loss: 0.8763951659202576\n",
      "Epoch 22: Train Loss: 0.42056212822596234, Validation Loss: 0.9157346487045288\n",
      "Epoch 23: Train Loss: 0.37799711028734845, Validation Loss: 1.0629312992095947\n",
      "Early stopping at epoch 24\n",
      "Fold 3\n",
      "Epoch 0: Train Loss: 0.7803472876548767, Validation Loss: 0.8086723685264587\n",
      "Epoch 1: Train Loss: 0.6686659852663676, Validation Loss: 0.8218781352043152\n",
      "Epoch 2: Train Loss: 0.7301325599352518, Validation Loss: 0.8483034372329712\n",
      "Epoch 3: Train Loss: 0.669670025507609, Validation Loss: 0.883063018321991\n",
      "Epoch 4: Train Loss: 0.6220294634501139, Validation Loss: 0.9274410009384155\n",
      "Epoch 5: Train Loss: 0.5770990053812662, Validation Loss: 0.9787455797195435\n",
      "Epoch 6: Train Loss: 0.6068476637204488, Validation Loss: 1.0432333946228027\n",
      "Epoch 7: Train Loss: 0.5810548861821493, Validation Loss: 1.120875597000122\n",
      "Epoch 8: Train Loss: 0.5574935078620911, Validation Loss: 1.2084698677062988\n",
      "Epoch 9: Train Loss: 0.5551237463951111, Validation Loss: 1.30152428150177\n",
      "Epoch 10: Train Loss: 0.5653971036275228, Validation Loss: 1.403062343597412\n",
      "Epoch 11: Train Loss: 0.5320267478624979, Validation Loss: 1.5173500776290894\n",
      "Epoch 12: Train Loss: 0.4878465433915456, Validation Loss: 1.6263891458511353\n",
      "Epoch 13: Train Loss: 0.42941079537073773, Validation Loss: 1.8086857795715332\n",
      "Epoch 14: Train Loss: 0.44934717814127606, Validation Loss: 1.885408878326416\n",
      "Epoch 15: Train Loss: 0.41557005047798157, Validation Loss: 1.9409770965576172\n",
      "Epoch 16: Train Loss: 0.41532452901204425, Validation Loss: 2.0087761878967285\n",
      "Epoch 17: Train Loss: 0.4039553801218669, Validation Loss: 2.0600171089172363\n",
      "Epoch 18: Train Loss: 0.41333399216334027, Validation Loss: 2.0902585983276367\n",
      "Epoch 19: Train Loss: 0.369430144627889, Validation Loss: 2.1098783016204834\n",
      "Early stopping at epoch 20\n",
      "Fold 4\n",
      "Epoch 0: Train Loss: 0.8586066166559855, Validation Loss: 0.797570526599884\n",
      "Epoch 1: Train Loss: 0.8512292504310608, Validation Loss: 0.7669017910957336\n",
      "Epoch 2: Train Loss: 0.7418782512346903, Validation Loss: 0.7226057648658752\n",
      "Epoch 3: Train Loss: 0.636468251546224, Validation Loss: 0.7376930713653564\n",
      "Epoch 4: Train Loss: 0.6642687916755676, Validation Loss: 0.7509555816650391\n",
      "Epoch 5: Train Loss: 0.6211245059967041, Validation Loss: 0.7443198561668396\n",
      "Epoch 6: Train Loss: 0.6452368299166361, Validation Loss: 0.7288683652877808\n",
      "Epoch 7: Train Loss: 0.6246516903241476, Validation Loss: 0.7169326543807983\n",
      "Epoch 8: Train Loss: 0.532758375008901, Validation Loss: 0.7071740031242371\n",
      "Epoch 9: Train Loss: 0.5695579648017883, Validation Loss: 0.701012134552002\n",
      "Epoch 10: Train Loss: 0.5918850104014078, Validation Loss: 0.7341465950012207\n",
      "Epoch 11: Train Loss: 0.55352055033048, Validation Loss: 0.7282131314277649\n",
      "Epoch 12: Train Loss: 0.5134670833746592, Validation Loss: 0.6443327069282532\n",
      "Epoch 13: Train Loss: 0.5066578487555186, Validation Loss: 0.6262286305427551\n",
      "Epoch 14: Train Loss: 0.46871184309323627, Validation Loss: 0.6286462545394897\n",
      "Epoch 15: Train Loss: 0.45674635966618854, Validation Loss: 0.6455252170562744\n",
      "Epoch 16: Train Loss: 0.45902488629023236, Validation Loss: 0.6385188698768616\n",
      "Epoch 17: Train Loss: 0.4409862260023753, Validation Loss: 0.6227434277534485\n",
      "Epoch 18: Train Loss: 0.40444983045260113, Validation Loss: 0.6206642985343933\n",
      "Epoch 19: Train Loss: 0.4115447998046875, Validation Loss: 0.6247063875198364\n",
      "Epoch 20: Train Loss: 0.45723013083140057, Validation Loss: 0.61887127161026\n",
      "Epoch 21: Train Loss: 0.36348175009091693, Validation Loss: 0.6124430894851685\n",
      "Epoch 22: Train Loss: 0.39690492550532025, Validation Loss: 0.5924030542373657\n",
      "Epoch 23: Train Loss: 0.4282337427139282, Validation Loss: 0.6515024900436401\n",
      "Epoch 24: Train Loss: 0.37499746680259705, Validation Loss: 0.5854154825210571\n",
      "Epoch 25: Train Loss: 0.3538542290528615, Validation Loss: 0.5945694446563721\n",
      "Epoch 26: Train Loss: 0.3470750153064728, Validation Loss: 0.5842504501342773\n",
      "Epoch 27: Train Loss: 0.32330530881881714, Validation Loss: 0.5769945979118347\n",
      "Epoch 28: Train Loss: 0.3590620954831441, Validation Loss: 0.5794975161552429\n",
      "Epoch 29: Train Loss: 0.32447341084480286, Validation Loss: 0.5840525031089783\n",
      "Epoch 30: Train Loss: 0.31744339565436047, Validation Loss: 0.585580587387085\n",
      "Epoch 31: Train Loss: 0.3192852238814036, Validation Loss: 0.5918590426445007\n",
      "Epoch 32: Train Loss: 0.2860059340794881, Validation Loss: 0.5640789866447449\n",
      "Epoch 33: Train Loss: 0.2732998877763748, Validation Loss: 0.5849530696868896\n",
      "Epoch 34: Train Loss: 0.2999582290649414, Validation Loss: 0.5890344381332397\n",
      "Epoch 35: Train Loss: 0.2804223299026489, Validation Loss: 0.5756557583808899\n",
      "Epoch 36: Train Loss: 0.29301119844118756, Validation Loss: 0.5859595537185669\n",
      "Epoch 37: Train Loss: 0.2511960019667943, Validation Loss: 0.6244311928749084\n",
      "Epoch 38: Train Loss: 0.25526049733161926, Validation Loss: 0.6296101808547974\n",
      "Epoch 39: Train Loss: 0.2557122011979421, Validation Loss: 0.6362064480781555\n",
      "Epoch 40: Train Loss: 0.2904425064722697, Validation Loss: 0.5889925956726074\n",
      "Epoch 41: Train Loss: 0.32227131724357605, Validation Loss: 0.820838987827301\n",
      "Epoch 42: Train Loss: 0.25232623020807904, Validation Loss: 0.6456001996994019\n",
      "Epoch 43: Train Loss: 0.2283866504828135, Validation Loss: 0.5745766162872314\n",
      "Epoch 44: Train Loss: 0.1912929266691208, Validation Loss: 0.6233883500099182\n",
      "Epoch 45: Train Loss: 0.22797914842764536, Validation Loss: 0.5772886872291565\n",
      "Epoch 46: Train Loss: 0.2190678964058558, Validation Loss: 0.5610594153404236\n",
      "Epoch 47: Train Loss: 0.205545574426651, Validation Loss: 0.5600820779800415\n",
      "Epoch 48: Train Loss: 0.23148030042648315, Validation Loss: 0.5692881941795349\n",
      "Epoch 49: Train Loss: 0.19609948496023813, Validation Loss: 0.5779904723167419\n",
      "Epoch 50: Train Loss: 0.19965330759684244, Validation Loss: 0.72300785779953\n",
      "Epoch 51: Train Loss: 0.2133988986412684, Validation Loss: 0.6479703783988953\n",
      "Epoch 52: Train Loss: 0.20644868165254593, Validation Loss: 0.5891557335853577\n",
      "Epoch 53: Train Loss: 0.1692454069852829, Validation Loss: 0.655484676361084\n",
      "Epoch 54: Train Loss: 0.19206193089485168, Validation Loss: 0.6595922708511353\n",
      "Epoch 55: Train Loss: 0.1653934915860494, Validation Loss: 0.6817774176597595\n",
      "Epoch 56: Train Loss: 0.1653290589650472, Validation Loss: 0.6129343509674072\n",
      "Epoch 57: Train Loss: 0.16241517663002014, Validation Loss: 0.6193704605102539\n",
      "Epoch 58: Train Loss: 0.180161714553833, Validation Loss: 0.6288778185844421\n",
      "Epoch 59: Train Loss: 0.14110454420248666, Validation Loss: 0.6326665878295898\n",
      "Epoch 60: Train Loss: 0.15623184541861215, Validation Loss: 0.620303213596344\n",
      "Epoch 61: Train Loss: 0.14484620839357376, Validation Loss: 0.6070961952209473\n",
      "Epoch 62: Train Loss: 0.19343924770752588, Validation Loss: 0.600077748298645\n",
      "Epoch 63: Train Loss: 0.16146878898143768, Validation Loss: 0.8032969236373901\n",
      "Epoch 64: Train Loss: 0.14619801193475723, Validation Loss: 0.5871716141700745\n",
      "Epoch 65: Train Loss: 0.14164032538731894, Validation Loss: 0.5900630950927734\n",
      "Epoch 66: Train Loss: 0.14617966612180075, Validation Loss: 0.6532361507415771\n",
      "Early stopping at epoch 67\n",
      "Fold 5\n",
      "Epoch 0: Train Loss: 0.7762134472529093, Validation Loss: 0.6867750287055969\n",
      "Epoch 1: Train Loss: 0.6351705193519592, Validation Loss: 0.676576554775238\n",
      "Epoch 2: Train Loss: 0.6262595454851786, Validation Loss: 0.6819654107093811\n",
      "Epoch 3: Train Loss: 0.5944327116012573, Validation Loss: 0.6877545714378357\n",
      "Epoch 4: Train Loss: 0.5526752471923828, Validation Loss: 0.7082309126853943\n",
      "Epoch 5: Train Loss: 0.5389337340990702, Validation Loss: 0.7093495726585388\n",
      "Epoch 6: Train Loss: 0.4834000766277313, Validation Loss: 0.7087096571922302\n",
      "Epoch 7: Train Loss: 0.5426151752471924, Validation Loss: 0.7245148420333862\n",
      "Epoch 8: Train Loss: 0.5308200716972351, Validation Loss: 0.7402703762054443\n",
      "Epoch 9: Train Loss: 0.4603773256142934, Validation Loss: 0.7527691125869751\n",
      "Epoch 10: Train Loss: 0.5465429623921713, Validation Loss: 0.8885064125061035\n",
      "Epoch 11: Train Loss: 0.5156895120938619, Validation Loss: 0.7441208958625793\n",
      "Epoch 12: Train Loss: 0.4592761695384979, Validation Loss: 0.7529655694961548\n",
      "Epoch 13: Train Loss: 0.4045652548472087, Validation Loss: 0.7677513957023621\n",
      "Epoch 14: Train Loss: 0.42850523193677265, Validation Loss: 0.7854771018028259\n",
      "Epoch 15: Train Loss: 0.40982021888097125, Validation Loss: 0.7103649377822876\n",
      "Epoch 16: Train Loss: 0.36160870393117267, Validation Loss: 0.716650128364563\n",
      "Epoch 17: Train Loss: 0.39694322148958844, Validation Loss: 0.7215808629989624\n",
      "Epoch 18: Train Loss: 0.35945456226666767, Validation Loss: 0.7230255603790283\n",
      "Epoch 19: Train Loss: 0.3910615344842275, Validation Loss: 0.7273320555686951\n",
      "Epoch 20: Train Loss: 0.3566569685935974, Validation Loss: 0.7027390599250793\n",
      "Epoch 21: Train Loss: 0.3301888207594554, Validation Loss: 0.6662603616714478\n",
      "Epoch 22: Train Loss: 0.311527560154597, Validation Loss: 0.8101564645767212\n",
      "Epoch 23: Train Loss: 0.30329790711402893, Validation Loss: 0.7118071913719177\n",
      "Epoch 24: Train Loss: 0.25448722143967945, Validation Loss: 0.6683153510093689\n",
      "Epoch 25: Train Loss: 0.28369570275147754, Validation Loss: 0.7094842195510864\n",
      "Epoch 26: Train Loss: 0.26330696046352386, Validation Loss: 0.8013331294059753\n",
      "Epoch 27: Train Loss: 0.3019733230272929, Validation Loss: 0.7874906063079834\n",
      "Epoch 28: Train Loss: 0.2839062263568242, Validation Loss: 0.7581436634063721\n",
      "Epoch 29: Train Loss: 0.27065130074818927, Validation Loss: 0.7440057992935181\n",
      "Epoch 30: Train Loss: 0.3000498563051224, Validation Loss: 0.6664051413536072\n",
      "Epoch 31: Train Loss: 0.248933936158816, Validation Loss: 1.0236073732376099\n",
      "Epoch 32: Train Loss: 0.3311885893344879, Validation Loss: 0.6736683249473572\n",
      "Epoch 33: Train Loss: 0.25203542908032733, Validation Loss: 0.7030059695243835\n",
      "Epoch 34: Train Loss: 0.22207390268643698, Validation Loss: 0.7226142287254333\n",
      "Epoch 35: Train Loss: 0.23001337548096976, Validation Loss: 0.6996628046035767\n",
      "Epoch 36: Train Loss: 0.2058791716893514, Validation Loss: 0.7316441535949707\n",
      "Epoch 37: Train Loss: 0.20977878073851267, Validation Loss: 0.7633180022239685\n",
      "Epoch 38: Train Loss: 0.2244863510131836, Validation Loss: 0.7619444131851196\n",
      "Epoch 39: Train Loss: 0.21365639567375183, Validation Loss: 0.7437477707862854\n",
      "Epoch 40: Train Loss: 0.20415856937567392, Validation Loss: 0.6860854625701904\n",
      "Early stopping at epoch 41\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 185\u001b[0m\n\u001b[0;32m    181\u001b[0m     fold_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Calculate additional metrics\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m(all_labels, all_predictions)\n\u001b[0;32m    186\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(all_labels, all_predictions)\n\u001b[0;32m    187\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(all_labels, all_predictions)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\\\n",
    "import pickle\n",
    "\n",
    "# Define a function to load and pad data\n",
    "def load_data(data_dir, max_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    file_list = os.listdir(data_dir)\n",
    "    for file in file_list:\n",
    "        with open(os.path.join(data_dir, file), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        label = 0 if 'truth' in file else 1\n",
    "        padded_data = np.zeros((65, max_length))\n",
    "        length = min(data.shape[1], max_length)\n",
    "        padded_data[:, :length] = data[:, :length]\n",
    "        X.append(padded_data)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Load dataset and pad the data\n",
    "data_dir = \"C:\\\\Users\\\\User\\\\Documents\\\\Lie detect data\\\\56M_DWTEEGData\"\n",
    "max_length = 1400  # Define maximum length for padding\n",
    "X, y = load_data(data_dir, max_length)\n",
    "\n",
    "# Define dataset class\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "# Define EEGNet model\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(65, 16, kernel_size=63, padding=31)  # Padding computed for 'same'\n",
    "        self.batchnorm1 = nn.BatchNorm1d(16)\n",
    "        self.depthwiseConv1d = nn.Conv1d(16, 32, kernel_size=65, groups=16, padding=32)  # Padding computed for 'same'\n",
    "        self.batchnorm2 = nn.BatchNorm1d(32)\n",
    "        self.activation = nn.ELU()\n",
    "        self.pooling = nn.AvgPool1d(kernel_size=4)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Calculate the number of features after the convolutions and pooling\n",
    "        self._calculate_num_features()\n",
    "        \n",
    "        self.fc = nn.Linear(self.num_features, num_classes)\n",
    "\n",
    "    def _calculate_num_features(self):\n",
    "        with torch.no_grad():\n",
    "            sample_input = torch.zeros(1, 65, 1400)\n",
    "            sample_output = self._forward_features(sample_input)\n",
    "            self.num_features = sample_output.shape[1]\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.depthwiseConv1d(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_and_evaluate(train_loader, val_loader, y_train):\n",
    "    model = EEGNet(num_classes=2).to(device)\n",
    "    \n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1)\n",
    "\n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    trigger_times = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = running_train_loss / len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(f'Early stopping at epoch {epoch}')\n",
    "                break\n",
    "\n",
    "        print(f'Epoch {epoch}: Train Loss: {avg_train_loss}, Validation Loss: {val_loss}')\n",
    "\n",
    "    return model\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_idx = 0\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "for train_index, val_index in kf.split(X, y):\n",
    "    print(f'Fold {fold_idx + 1}')\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    # Normalize data using scaler fitted on training data\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "    X_val = scaler.transform(X_val.reshape(X_val.shape[0], -1))\n",
    "    X_train = X_train.reshape(-1, 65, max_length)\n",
    "    X_val = X_val.reshape(-1, 65, max_length)\n",
    "\n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = EEGDataset(X_train, y_train)\n",
    "    val_dataset = EEGDataset(X_val, y_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = train_and_evaluate(train_loader, val_loader, y_train)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    fold_idx += 1\n",
    "\n",
    "\n",
    "# Calculate additional metrics\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "auc = roc_auc_score(all_labels, all_predictions)\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy},Precision: {precision}, Recall: {recall}, F1-score: {f1}, AUC: {auc}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66654d63-c450-4d9f-a3e3-63701fd1d41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934cb89-5ea1-4eb0-a152-00c71e49e06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
