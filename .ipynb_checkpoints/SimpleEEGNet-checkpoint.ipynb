{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "656cdbc2-da54-45ba-97fc-195b59bd7820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 0: Train Loss: 0.6569392482439677, Validation Loss: 0.6694141626358032\n",
      "Epoch 1: Train Loss: 0.6232163111368815, Validation Loss: 0.6567577719688416\n",
      "Epoch 2: Train Loss: 0.5966388583183289, Validation Loss: 0.641223669052124\n",
      "Epoch 3: Train Loss: 0.5778760313987732, Validation Loss: 0.6257113814353943\n",
      "Epoch 4: Train Loss: 0.5604292154312134, Validation Loss: 0.6116464734077454\n",
      "Epoch 5: Train Loss: 0.5522220134735107, Validation Loss: 0.5995446443557739\n",
      "Epoch 6: Train Loss: 0.5355083147684733, Validation Loss: 0.5892245173454285\n",
      "Epoch 7: Train Loss: 0.5361021558443705, Validation Loss: 0.5808311700820923\n",
      "Epoch 8: Train Loss: 0.5350726246833801, Validation Loss: 0.5731722116470337\n",
      "Epoch 9: Train Loss: 0.5279630223910013, Validation Loss: 0.5679006576538086\n",
      "Epoch 10: Train Loss: 0.5272724231084188, Validation Loss: 0.5510343909263611\n",
      "Epoch 11: Train Loss: 0.5116100907325745, Validation Loss: 0.5325568914413452\n",
      "Epoch 12: Train Loss: 0.489448885122935, Validation Loss: 0.5251153707504272\n",
      "Epoch 13: Train Loss: 0.492487500111262, Validation Loss: 0.5159879922866821\n",
      "Epoch 14: Train Loss: 0.4722083310286204, Validation Loss: 0.5086522102355957\n",
      "Epoch 15: Train Loss: 0.4602300723393758, Validation Loss: 0.5022502541542053\n",
      "Epoch 16: Train Loss: 0.4573124448458354, Validation Loss: 0.49619293212890625\n",
      "Epoch 17: Train Loss: 0.4630500872929891, Validation Loss: 0.4931170642375946\n",
      "Epoch 18: Train Loss: 0.44505160053571063, Validation Loss: 0.49027514457702637\n",
      "Epoch 19: Train Loss: 0.44895949959754944, Validation Loss: 0.488991916179657\n",
      "Epoch 20: Train Loss: 0.45213385423024494, Validation Loss: 0.4850350320339203\n",
      "Epoch 21: Train Loss: 0.4268353581428528, Validation Loss: 0.4809226989746094\n",
      "Epoch 22: Train Loss: 0.40613670150438946, Validation Loss: 0.47959089279174805\n",
      "Epoch 23: Train Loss: 0.4081030984719594, Validation Loss: 0.47575274109840393\n",
      "Epoch 24: Train Loss: 0.3901191254456838, Validation Loss: 0.472744345664978\n",
      "Epoch 25: Train Loss: 0.3828797439734141, Validation Loss: 0.46638330817222595\n",
      "Epoch 26: Train Loss: 0.39377694328625995, Validation Loss: 0.4594772160053253\n",
      "Epoch 27: Train Loss: 0.3729357918103536, Validation Loss: 0.45454883575439453\n",
      "Epoch 28: Train Loss: 0.37608980139096576, Validation Loss: 0.45267578959465027\n",
      "Epoch 29: Train Loss: 0.3721204996109009, Validation Loss: 0.4494924247264862\n",
      "Epoch 30: Train Loss: 0.3580655554930369, Validation Loss: 0.43655115365982056\n",
      "Epoch 31: Train Loss: 0.36130476991335553, Validation Loss: 0.440320760011673\n",
      "Epoch 32: Train Loss: 0.3505638043085734, Validation Loss: 0.45032262802124023\n",
      "Epoch 33: Train Loss: 0.33401097853978473, Validation Loss: 0.45275571942329407\n",
      "Epoch 34: Train Loss: 0.33108246326446533, Validation Loss: 0.4522450864315033\n",
      "Epoch 35: Train Loss: 0.32469214002291363, Validation Loss: 0.4504551291465759\n",
      "Epoch 36: Train Loss: 0.3158770302931468, Validation Loss: 0.4494035243988037\n",
      "Epoch 37: Train Loss: 0.30877092480659485, Validation Loss: 0.4449901580810547\n",
      "Epoch 38: Train Loss: 0.3057403763135274, Validation Loss: 0.4445013999938965\n",
      "Epoch 39: Train Loss: 0.30929027994473773, Validation Loss: 0.44361454248428345\n",
      "Epoch 40: Train Loss: 0.32050594687461853, Validation Loss: 0.4339168667793274\n",
      "Epoch 41: Train Loss: 0.3036509056886037, Validation Loss: 0.4289896786212921\n",
      "Epoch 42: Train Loss: 0.29236570994059247, Validation Loss: 0.42940428853034973\n",
      "Epoch 43: Train Loss: 0.2886345287164052, Validation Loss: 0.4313860833644867\n",
      "Epoch 44: Train Loss: 0.27503707508246106, Validation Loss: 0.4356948435306549\n",
      "Epoch 45: Train Loss: 0.2763599157333374, Validation Loss: 0.4354728162288666\n",
      "Epoch 46: Train Loss: 0.27217329541842145, Validation Loss: 0.43415355682373047\n",
      "Epoch 47: Train Loss: 0.2588520248730977, Validation Loss: 0.4364749789237976\n",
      "Epoch 48: Train Loss: 0.25710274279117584, Validation Loss: 0.4356521666049957\n",
      "Epoch 49: Train Loss: 0.25662291546662647, Validation Loss: 0.434322714805603\n",
      "Epoch 50: Train Loss: 0.24750328063964844, Validation Loss: 0.4350251257419586\n",
      "Early stopping at epoch 51\n",
      "Fold 2\n",
      "Epoch 0: Train Loss: 0.6873223185539246, Validation Loss: 0.6931831240653992\n",
      "Epoch 1: Train Loss: 0.6403620441754659, Validation Loss: 0.6915022730827332\n",
      "Epoch 2: Train Loss: 0.6090909639994303, Validation Loss: 0.6930034160614014\n",
      "Epoch 3: Train Loss: 0.5812703569730123, Validation Loss: 0.6973060965538025\n",
      "Epoch 4: Train Loss: 0.5706120928128561, Validation Loss: 0.7053225636482239\n",
      "Epoch 5: Train Loss: 0.5644863843917847, Validation Loss: 0.7165631055831909\n",
      "Epoch 6: Train Loss: 0.550065815448761, Validation Loss: 0.7309314608573914\n",
      "Epoch 7: Train Loss: 0.5410648783047994, Validation Loss: 0.7486974000930786\n",
      "Epoch 8: Train Loss: 0.5460993846257528, Validation Loss: 0.7680343985557556\n",
      "Epoch 9: Train Loss: 0.5354321002960205, Validation Loss: 0.7876476049423218\n",
      "Epoch 10: Train Loss: 0.5419514576594034, Validation Loss: 0.8152802586555481\n",
      "Early stopping at epoch 11\n",
      "Fold 3\n",
      "Epoch 0: Train Loss: 0.6982432206471761, Validation Loss: 0.6891500353813171\n",
      "Epoch 1: Train Loss: 0.6312917669614156, Validation Loss: 0.6896263360977173\n",
      "Epoch 2: Train Loss: 0.6125201980272929, Validation Loss: 0.6913219690322876\n",
      "Epoch 3: Train Loss: 0.5885873834292094, Validation Loss: 0.6922492980957031\n",
      "Epoch 4: Train Loss: 0.5795801083246866, Validation Loss: 0.6915640234947205\n",
      "Epoch 5: Train Loss: 0.567099372545878, Validation Loss: 0.6892144083976746\n",
      "Epoch 6: Train Loss: 0.5495284199714661, Validation Loss: 0.6831668019294739\n",
      "Epoch 7: Train Loss: 0.5610837340354919, Validation Loss: 0.6774035692214966\n",
      "Epoch 8: Train Loss: 0.5400698383649191, Validation Loss: 0.673531174659729\n",
      "Epoch 9: Train Loss: 0.5530169804890951, Validation Loss: 0.6709002256393433\n",
      "Epoch 10: Train Loss: 0.5376253326733907, Validation Loss: 0.6402168273925781\n",
      "Epoch 11: Train Loss: 0.5173161427179972, Validation Loss: 0.6140602231025696\n",
      "Epoch 12: Train Loss: 0.4985302686691284, Validation Loss: 0.5904827117919922\n",
      "Epoch 13: Train Loss: 0.4854782223701477, Validation Loss: 0.5761195421218872\n",
      "Epoch 14: Train Loss: 0.47891531387964886, Validation Loss: 0.570319414138794\n",
      "Epoch 15: Train Loss: 0.47941309213638306, Validation Loss: 0.5677493810653687\n",
      "Epoch 16: Train Loss: 0.4553130269050598, Validation Loss: 0.5664839148521423\n",
      "Epoch 17: Train Loss: 0.44702545801798504, Validation Loss: 0.5655462145805359\n",
      "Epoch 18: Train Loss: 0.4468490779399872, Validation Loss: 0.5653966069221497\n",
      "Epoch 19: Train Loss: 0.4463142653306325, Validation Loss: 0.5650139451026917\n",
      "Epoch 20: Train Loss: 0.446527232726415, Validation Loss: 0.5697256922721863\n",
      "Epoch 21: Train Loss: 0.4303006927172343, Validation Loss: 0.5642373561859131\n",
      "Epoch 22: Train Loss: 0.42315661907196045, Validation Loss: 0.5700158476829529\n",
      "Epoch 23: Train Loss: 0.3957187831401825, Validation Loss: 0.5708092451095581\n",
      "Epoch 24: Train Loss: 0.38667776187260944, Validation Loss: 0.5694226026535034\n",
      "Epoch 25: Train Loss: 0.38224053382873535, Validation Loss: 0.5677876472473145\n",
      "Epoch 26: Train Loss: 0.38665227095286053, Validation Loss: 0.5617843270301819\n",
      "Epoch 27: Train Loss: 0.38715479771296185, Validation Loss: 0.5607020258903503\n",
      "Epoch 28: Train Loss: 0.37632814049720764, Validation Loss: 0.5607134103775024\n",
      "Epoch 29: Train Loss: 0.37326979637145996, Validation Loss: 0.559981107711792\n",
      "Epoch 30: Train Loss: 0.3668324152628581, Validation Loss: 0.5540792942047119\n",
      "Epoch 31: Train Loss: 0.36849237481753033, Validation Loss: 0.5414754152297974\n",
      "Epoch 32: Train Loss: 0.3520733018716176, Validation Loss: 0.5450379848480225\n",
      "Epoch 33: Train Loss: 0.3395659923553467, Validation Loss: 0.5785287022590637\n",
      "Epoch 34: Train Loss: 0.32415637373924255, Validation Loss: 0.5967987775802612\n",
      "Epoch 35: Train Loss: 0.32163162032763165, Validation Loss: 0.594479501247406\n",
      "Epoch 36: Train Loss: 0.31529560685157776, Validation Loss: 0.5923917293548584\n",
      "Epoch 37: Train Loss: 0.305897980928421, Validation Loss: 0.5868860483169556\n",
      "Epoch 38: Train Loss: 0.31402942538261414, Validation Loss: 0.5893625617027283\n",
      "Epoch 39: Train Loss: 0.3182210425535838, Validation Loss: 0.587386965751648\n",
      "Epoch 40: Train Loss: 0.32382655143737793, Validation Loss: 0.5653442144393921\n",
      "Early stopping at epoch 41\n",
      "Fold 4\n",
      "Epoch 0: Train Loss: 0.7266864975293478, Validation Loss: 0.7098075151443481\n",
      "Epoch 1: Train Loss: 0.6495608488718668, Validation Loss: 0.70857173204422\n",
      "Epoch 2: Train Loss: 0.6189901232719421, Validation Loss: 0.7088422179222107\n",
      "Epoch 3: Train Loss: 0.5979856252670288, Validation Loss: 0.7081683874130249\n",
      "Epoch 4: Train Loss: 0.5746861497561137, Validation Loss: 0.7070916295051575\n",
      "Epoch 5: Train Loss: 0.5739066004753113, Validation Loss: 0.7068909406661987\n",
      "Epoch 6: Train Loss: 0.5628374616305033, Validation Loss: 0.7058042883872986\n",
      "Epoch 7: Train Loss: 0.547284205754598, Validation Loss: 0.7049460411071777\n",
      "Epoch 8: Train Loss: 0.5346187949180603, Validation Loss: 0.703801691532135\n",
      "Epoch 9: Train Loss: 0.5575724045435587, Validation Loss: 0.7025507688522339\n",
      "Epoch 10: Train Loss: 0.5516421496868134, Validation Loss: 0.6939713358879089\n",
      "Epoch 11: Train Loss: 0.5092674593130747, Validation Loss: 0.6865055561065674\n",
      "Epoch 12: Train Loss: 0.5244455337524414, Validation Loss: 0.6761974096298218\n",
      "Epoch 13: Train Loss: 0.48524486025174457, Validation Loss: 0.6684020161628723\n",
      "Epoch 14: Train Loss: 0.47594736019770306, Validation Loss: 0.6616377830505371\n",
      "Epoch 15: Train Loss: 0.4739599625269572, Validation Loss: 0.6542113423347473\n",
      "Epoch 16: Train Loss: 0.4599153200785319, Validation Loss: 0.6502345204353333\n",
      "Epoch 17: Train Loss: 0.4492107629776001, Validation Loss: 0.6487904191017151\n",
      "Epoch 18: Train Loss: 0.43482417861620587, Validation Loss: 0.6478925347328186\n",
      "Epoch 19: Train Loss: 0.4546266595522563, Validation Loss: 0.6486477255821228\n",
      "Epoch 20: Train Loss: 0.44355161984761554, Validation Loss: 0.6355506181716919\n",
      "Epoch 21: Train Loss: 0.4271324773629506, Validation Loss: 0.6242413520812988\n",
      "Epoch 22: Train Loss: 0.4226704140504201, Validation Loss: 0.6151244640350342\n",
      "Epoch 23: Train Loss: 0.42261677980422974, Validation Loss: 0.6089842915534973\n",
      "Epoch 24: Train Loss: 0.3893658518791199, Validation Loss: 0.601224958896637\n",
      "Epoch 25: Train Loss: 0.3847621480623881, Validation Loss: 0.5973487496376038\n",
      "Epoch 26: Train Loss: 0.389480580886205, Validation Loss: 0.5955989360809326\n",
      "Epoch 27: Train Loss: 0.3859359721342723, Validation Loss: 0.5955432653427124\n",
      "Epoch 28: Train Loss: 0.3715909520785014, Validation Loss: 0.5973117351531982\n",
      "Epoch 29: Train Loss: 0.4020206232865651, Validation Loss: 0.5991124510765076\n",
      "Epoch 30: Train Loss: 0.36782438556353253, Validation Loss: 0.5925040245056152\n",
      "Epoch 31: Train Loss: 0.3603547016779582, Validation Loss: 0.5825750827789307\n",
      "Epoch 32: Train Loss: 0.35570359230041504, Validation Loss: 0.5748560428619385\n",
      "Epoch 33: Train Loss: 0.3349534571170807, Validation Loss: 0.5646862983703613\n",
      "Epoch 34: Train Loss: 0.31980032722155255, Validation Loss: 0.5589497685432434\n",
      "Epoch 35: Train Loss: 0.3168545166651408, Validation Loss: 0.5541520714759827\n",
      "Epoch 36: Train Loss: 0.31752634048461914, Validation Loss: 0.5525564551353455\n",
      "Epoch 37: Train Loss: 0.3176492253939311, Validation Loss: 0.553028404712677\n",
      "Epoch 38: Train Loss: 0.33047281702359516, Validation Loss: 0.5542904138565063\n",
      "Epoch 39: Train Loss: 0.31470107038815814, Validation Loss: 0.5558274984359741\n",
      "Epoch 40: Train Loss: 0.3152804672718048, Validation Loss: 0.5521116256713867\n",
      "Epoch 41: Train Loss: 0.3119301398595174, Validation Loss: 0.5459747314453125\n",
      "Epoch 42: Train Loss: 0.29335586229960126, Validation Loss: 0.544465959072113\n",
      "Epoch 43: Train Loss: 0.2870243440071742, Validation Loss: 0.5338553190231323\n",
      "Epoch 44: Train Loss: 0.30001290639241535, Validation Loss: 0.5320724248886108\n",
      "Epoch 45: Train Loss: 0.28617924948533374, Validation Loss: 0.5338743925094604\n",
      "Epoch 46: Train Loss: 0.2697826474905014, Validation Loss: 0.5384088754653931\n",
      "Epoch 47: Train Loss: 0.2677203019460042, Validation Loss: 0.5398530960083008\n",
      "Epoch 48: Train Loss: 0.26420795420805615, Validation Loss: 0.5378684401512146\n",
      "Epoch 49: Train Loss: 0.26696649193763733, Validation Loss: 0.5373744964599609\n",
      "Epoch 50: Train Loss: 0.2723408838113149, Validation Loss: 0.5238538980484009\n",
      "Epoch 51: Train Loss: 0.2750170628229777, Validation Loss: 0.5312519073486328\n",
      "Epoch 52: Train Loss: 0.2584780553976695, Validation Loss: 0.5392876267433167\n",
      "Epoch 53: Train Loss: 0.2485244224468867, Validation Loss: 0.5318686366081238\n",
      "Epoch 54: Train Loss: 0.240817129611969, Validation Loss: 0.5250309109687805\n",
      "Epoch 55: Train Loss: 0.24344076216220856, Validation Loss: 0.5251703858375549\n",
      "Epoch 56: Train Loss: 0.24605758984883627, Validation Loss: 0.5271502733230591\n",
      "Epoch 57: Train Loss: 0.2458208998044332, Validation Loss: 0.5280213356018066\n",
      "Epoch 58: Train Loss: 0.23879597584406534, Validation Loss: 0.5283677577972412\n",
      "Epoch 59: Train Loss: 0.23116999367872873, Validation Loss: 0.5283225774765015\n",
      "Early stopping at epoch 60\n",
      "Fold 5\n",
      "Epoch 0: Train Loss: 0.6775930126508077, Validation Loss: 0.6950721740722656\n",
      "Epoch 1: Train Loss: 0.6395730972290039, Validation Loss: 0.692699134349823\n",
      "Epoch 2: Train Loss: 0.6083047986030579, Validation Loss: 0.6870156526565552\n",
      "Epoch 3: Train Loss: 0.5873854160308838, Validation Loss: 0.6775403618812561\n",
      "Epoch 4: Train Loss: 0.5783889293670654, Validation Loss: 0.666120707988739\n",
      "Epoch 5: Train Loss: 0.5705429911613464, Validation Loss: 0.6556018590927124\n",
      "Epoch 6: Train Loss: 0.5525024135907491, Validation Loss: 0.6450068354606628\n",
      "Epoch 7: Train Loss: 0.5407962997754415, Validation Loss: 0.6352919340133667\n",
      "Epoch 8: Train Loss: 0.5489520827929179, Validation Loss: 0.6271966695785522\n",
      "Epoch 9: Train Loss: 0.5371261040369669, Validation Loss: 0.6197262406349182\n",
      "Epoch 10: Train Loss: 0.5306680003801981, Validation Loss: 0.6017728447914124\n",
      "Epoch 11: Train Loss: 0.5209226608276367, Validation Loss: 0.5855086445808411\n",
      "Epoch 12: Train Loss: 0.5093461771806082, Validation Loss: 0.5766850709915161\n",
      "Epoch 13: Train Loss: 0.4855591853459676, Validation Loss: 0.5707972049713135\n",
      "Epoch 14: Train Loss: 0.4783203105131785, Validation Loss: 0.5618829131126404\n",
      "Epoch 15: Train Loss: 0.46231218179066974, Validation Loss: 0.5582454800605774\n",
      "Epoch 16: Train Loss: 0.4518970449765523, Validation Loss: 0.5546303391456604\n",
      "Epoch 17: Train Loss: 0.4476883312066396, Validation Loss: 0.5536231398582458\n",
      "Epoch 18: Train Loss: 0.4520443379878998, Validation Loss: 0.5524205565452576\n",
      "Epoch 19: Train Loss: 0.4472290476163228, Validation Loss: 0.5544901490211487\n",
      "Epoch 20: Train Loss: 0.4628426134586334, Validation Loss: 0.5476762652397156\n",
      "Epoch 21: Train Loss: 0.4366385042667389, Validation Loss: 0.5474168062210083\n",
      "Epoch 22: Train Loss: 0.4242580235004425, Validation Loss: 0.5481356382369995\n",
      "Epoch 23: Train Loss: 0.40425726771354675, Validation Loss: 0.552252471446991\n",
      "Epoch 24: Train Loss: 0.40059857567151386, Validation Loss: 0.5428819060325623\n",
      "Epoch 25: Train Loss: 0.38586440682411194, Validation Loss: 0.5367273688316345\n",
      "Epoch 26: Train Loss: 0.3924458523591359, Validation Loss: 0.5306372046470642\n",
      "Epoch 27: Train Loss: 0.3769045372804006, Validation Loss: 0.5316256880760193\n",
      "Epoch 28: Train Loss: 0.3657323519388835, Validation Loss: 0.5311235785484314\n",
      "Epoch 29: Train Loss: 0.4032011528809865, Validation Loss: 0.531057596206665\n",
      "Epoch 30: Train Loss: 0.36783818403879803, Validation Loss: 0.5263751745223999\n",
      "Epoch 31: Train Loss: 0.35432393352190655, Validation Loss: 0.5227242112159729\n",
      "Epoch 32: Train Loss: 0.3530689279238383, Validation Loss: 0.5320309400558472\n",
      "Epoch 33: Train Loss: 0.33235300580660504, Validation Loss: 0.5341718792915344\n",
      "Epoch 34: Train Loss: 0.33174731334050495, Validation Loss: 0.5417741537094116\n",
      "Epoch 35: Train Loss: 0.3232201337814331, Validation Loss: 0.5454305410385132\n",
      "Epoch 36: Train Loss: 0.31254397829373676, Validation Loss: 0.5470007061958313\n",
      "Epoch 37: Train Loss: 0.31388771533966064, Validation Loss: 0.5491567850112915\n",
      "Epoch 38: Train Loss: 0.31953373551368713, Validation Loss: 0.5510711073875427\n",
      "Epoch 39: Train Loss: 0.3092394272486369, Validation Loss: 0.5501753687858582\n",
      "Epoch 40: Train Loss: 0.3125629723072052, Validation Loss: 0.5547690987586975\n",
      "Early stopping at epoch 41\n",
      "Accuracy: 0.725,Precision: 0.7547169811320755, Recall: 0.6666666666666666, F1-score: 0.7079646017699115, AUC: 0.7249999999999999\n",
      "Confusion Matrix:\n",
      "[[47 13]\n",
      " [20 40]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nweight decay = 1e-7\\nlearning rate = 0.0001\\nepoch = 100\\nbatch size = 32\\nearly stopping patience = 10\\nstandard scaler\\nReLU\\ncross entropy loss\\ndrop out = 0.8\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import pickle\n",
    "\n",
    "model_save_dir = r'C:\\Users\\User\\Documents\\Lie detect data\\Model'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# Define a function to load, cut and pad data\n",
    "def load_data(data_dir, max_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    file_list = os.listdir(data_dir)\n",
    "    for file in file_list:\n",
    "        with open(os.path.join(data_dir, file), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        label = 1 if 'truth' in file else 0\n",
    "        if data.shape[1] > max_length:\n",
    "            processed_data = data[:, :max_length]  # Cut data if it exceeds max_length\n",
    "        else:\n",
    "            processed_data = np.zeros((data.shape[0], max_length))\n",
    "            processed_data[:, :data.shape[1]] = data  # Pad data if it is shorter than max_length\n",
    "        X.append(processed_data)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Load dataset and process the data\n",
    "data_dir = \"C:\\\\Users\\\\User\\\\Documents\\\\Lie detect data\\\\56M_DWTEEGData\"\n",
    "max_length = 1400  # Define maximum length for cutting and padding\n",
    "X, y = load_data(data_dir, max_length)\n",
    "\n",
    "# Define dataset class\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "# Define EEGNet model\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(65, 32, kernel_size=63, padding=31)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(32)\n",
    "        self.depthwiseConv1d = nn.Conv1d(32, 64, kernel_size=65, groups=32, padding=32)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)  # Additional convolutional layer\n",
    "        self.batchnorm3 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.pooling = nn.AvgPool1d(kernel_size=4)\n",
    "        self.dropout = nn.Dropout(0.8)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)  # Global average pooling\n",
    "        \n",
    "        self._calculate_num_features()\n",
    "        self.fc = nn.Linear(self.num_features, num_classes)\n",
    "\n",
    "    def _calculate_num_features(self):\n",
    "        with torch.no_grad():\n",
    "            sample_input = torch.zeros(1, 65, 1400)\n",
    "            sample_output = self._forward_features(sample_input)\n",
    "            self.num_features = sample_output.shape[1]\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.depthwiseConv1d(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.conv2(x)  # Additional convolutional layer\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.global_pool(x)  # Global average pooling layer\n",
    "        x = torch.flatten(x, 1)  # Flatten the output for the fully connected layer\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_and_evaluate(train_loader, val_loader, y_train):\n",
    "    model = EEGNet(num_classes=2).to(device)\n",
    "    \n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1)\n",
    "\n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    trigger_times = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = running_train_loss / len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            trigger_times = 0\n",
    "            fold_model_path = os.path.join(model_save_dir, f'fold3_model_fold_{fold_idx}.pth')\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'val_loss': best_val_loss,\n",
    "            }, fold_model_path)\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(f'Early stopping at epoch {epoch}')\n",
    "                break\n",
    "\n",
    "        print(f'Epoch {epoch}: Train Loss: {avg_train_loss}, Validation Loss: {val_loss}')\n",
    "\n",
    "    return model\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_idx = 0\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "for train_index, val_index in kf.split(X, y):\n",
    "    print(f'Fold {fold_idx + 1}')\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    # Normalize data using scaler fitted on training data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "    X_val = scaler.transform(X_val.reshape(X_val.shape[0], -1))\n",
    "    X_train = X_train.reshape(-1, 65, max_length)\n",
    "    X_val = X_val.reshape(-1, 65, max_length)\n",
    "\n",
    "    # Save the scaler to a file\n",
    "    with open(r'C:\\Users\\User\\Documents\\Lie detect data\\Model\\simpleEEGNet_scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "\n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = EEGDataset(X_train, y_train)\n",
    "    val_dataset = EEGDataset(X_val, y_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = train_and_evaluate(train_loader, val_loader, y_train)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    fold_idx += 1\n",
    "\n",
    "\n",
    "# Calculate additional metrics\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "auc = roc_auc_score(all_labels, all_predictions)\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy},Precision: {precision}, Recall: {recall}, F1-score: {f1}, AUC: {auc}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "weight decay = 1e-7\n",
    "learning rate = 0.0001\n",
    "epoch = 100\n",
    "batch size = 32\n",
    "early stopping patience = 10\n",
    "standard scaler\n",
    "ReLU\n",
    "cross entropy loss\n",
    "drop out = 0.8\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66654d63-c450-4d9f-a3e3-63701fd1d41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934cb89-5ea1-4eb0-a152-00c71e49e06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
