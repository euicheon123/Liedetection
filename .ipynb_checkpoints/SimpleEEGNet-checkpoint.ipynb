{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "656cdbc2-da54-45ba-97fc-195b59bd7820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 0: Train Loss: 0.682653546333313, Validation Loss: 0.682653546333313\n",
      "Epoch 1: Train Loss: 0.6606600880622864, Validation Loss: 0.6606600880622864\n",
      "Epoch 2: Train Loss: 0.6439411044120789, Validation Loss: 0.6439411044120789\n",
      "Epoch 3: Train Loss: 0.6378569006919861, Validation Loss: 0.6378569006919861\n",
      "Epoch 4: Train Loss: 0.6088013052940369, Validation Loss: 0.6088013052940369\n",
      "Epoch 5: Train Loss: 0.5953277349472046, Validation Loss: 0.5953277349472046\n",
      "Epoch 6: Train Loss: 0.5836688280105591, Validation Loss: 0.5836688280105591\n",
      "Epoch 7: Train Loss: 0.5695340037345886, Validation Loss: 0.5695340037345886\n",
      "Epoch 8: Train Loss: 0.5577611923217773, Validation Loss: 0.5577611923217773\n",
      "Epoch 9: Train Loss: 0.548721194267273, Validation Loss: 0.548721194267273\n",
      "Epoch 10: Train Loss: 0.5575345754623413, Validation Loss: 0.5575345754623413\n",
      "Epoch 11: Train Loss: 0.5613561272621155, Validation Loss: 0.5613561272621155\n",
      "Epoch 12: Train Loss: 0.5213754773139954, Validation Loss: 0.5213754773139954\n",
      "Epoch 13: Train Loss: 0.5370635390281677, Validation Loss: 0.5370635390281677\n",
      "Epoch 14: Train Loss: 0.622917115688324, Validation Loss: 0.622917115688324\n",
      "Epoch 15: Train Loss: 0.5220728516578674, Validation Loss: 0.5220728516578674\n",
      "Epoch 16: Train Loss: 0.47287607192993164, Validation Loss: 0.47287607192993164\n",
      "Epoch 17: Train Loss: 0.47501417994499207, Validation Loss: 0.47501417994499207\n",
      "Epoch 18: Train Loss: 0.4777139127254486, Validation Loss: 0.4777139127254486\n",
      "Epoch 19: Train Loss: 0.4730861783027649, Validation Loss: 0.4730861783027649\n",
      "Epoch 20: Train Loss: 0.5313934683799744, Validation Loss: 0.5313934683799744\n",
      "Epoch 21: Train Loss: 0.4496384263038635, Validation Loss: 0.4496384263038635\n",
      "Epoch 22: Train Loss: 0.5795031785964966, Validation Loss: 0.5795031785964966\n",
      "Epoch 23: Train Loss: 0.5767677426338196, Validation Loss: 0.5767677426338196\n",
      "Epoch 24: Train Loss: 0.49906790256500244, Validation Loss: 0.49906790256500244\n",
      "Epoch 25: Train Loss: 0.5216045379638672, Validation Loss: 0.5216045379638672\n",
      "Epoch 26: Train Loss: 0.5726461410522461, Validation Loss: 0.5726461410522461\n",
      "Epoch 27: Train Loss: 0.5409775972366333, Validation Loss: 0.5409775972366333\n",
      "Epoch 28: Train Loss: 0.5113946795463562, Validation Loss: 0.5113946795463562\n",
      "Epoch 29: Train Loss: 0.49107205867767334, Validation Loss: 0.49107205867767334\n",
      "Epoch 30: Train Loss: 0.43971017003059387, Validation Loss: 0.43971017003059387\n",
      "Epoch 31: Train Loss: 0.8301213383674622, Validation Loss: 0.8301213383674622\n",
      "Epoch 32: Train Loss: 0.4292902946472168, Validation Loss: 0.4292902946472168\n",
      "Epoch 33: Train Loss: 0.5151781439781189, Validation Loss: 0.5151781439781189\n",
      "Epoch 34: Train Loss: 0.5987547039985657, Validation Loss: 0.5987547039985657\n",
      "Epoch 35: Train Loss: 0.38170403242111206, Validation Loss: 0.38170403242111206\n",
      "Epoch 36: Train Loss: 0.3859390914440155, Validation Loss: 0.3859390914440155\n",
      "Epoch 37: Train Loss: 0.455501526594162, Validation Loss: 0.455501526594162\n",
      "Epoch 38: Train Loss: 0.4935624599456787, Validation Loss: 0.4935624599456787\n",
      "Epoch 39: Train Loss: 0.49523472785949707, Validation Loss: 0.49523472785949707\n",
      "Epoch 40: Train Loss: 0.5283611416816711, Validation Loss: 0.5283611416816711\n",
      "Epoch 41: Train Loss: 0.6610612273216248, Validation Loss: 0.6610612273216248\n",
      "Epoch 42: Train Loss: 0.4932861626148224, Validation Loss: 0.4932861626148224\n",
      "Epoch 43: Train Loss: 0.37139418721199036, Validation Loss: 0.37139418721199036\n",
      "Epoch 44: Train Loss: 0.4802260100841522, Validation Loss: 0.4802260100841522\n",
      "Epoch 45: Train Loss: 0.5331928133964539, Validation Loss: 0.5331928133964539\n",
      "Epoch 46: Train Loss: 0.4693443179130554, Validation Loss: 0.4693443179130554\n",
      "Epoch 47: Train Loss: 0.4558717608451843, Validation Loss: 0.4558717608451843\n",
      "Epoch 48: Train Loss: 0.45542341470718384, Validation Loss: 0.45542341470718384\n",
      "Epoch 49: Train Loss: 0.4558992385864258, Validation Loss: 0.4558992385864258\n",
      "Epoch 50: Train Loss: 0.714007556438446, Validation Loss: 0.714007556438446\n",
      "Epoch 51: Train Loss: 0.4790930151939392, Validation Loss: 0.4790930151939392\n",
      "Epoch 52: Train Loss: 0.5062959790229797, Validation Loss: 0.5062959790229797\n",
      "Epoch 53: Train Loss: 0.6282390356063843, Validation Loss: 0.6282390356063843\n",
      "Epoch 54: Train Loss: 0.45790305733680725, Validation Loss: 0.45790305733680725\n",
      "Epoch 55: Train Loss: 0.3897072374820709, Validation Loss: 0.3897072374820709\n",
      "Epoch 56: Train Loss: 0.46690747141838074, Validation Loss: 0.46690747141838074\n",
      "Epoch 57: Train Loss: 0.5329770445823669, Validation Loss: 0.5329770445823669\n",
      "Epoch 58: Train Loss: 0.5414315462112427, Validation Loss: 0.5414315462112427\n",
      "Epoch 59: Train Loss: 0.533217191696167, Validation Loss: 0.533217191696167\n",
      "Epoch 60: Train Loss: 0.48204711079597473, Validation Loss: 0.48204711079597473\n",
      "Epoch 61: Train Loss: 0.6842954754829407, Validation Loss: 0.6842954754829407\n",
      "Epoch 62: Train Loss: 0.46955356001853943, Validation Loss: 0.46955356001853943\n",
      "Epoch 63: Train Loss: 0.7496289610862732, Validation Loss: 0.7496289610862732\n",
      "Epoch 64: Train Loss: 0.5154302716255188, Validation Loss: 0.5154302716255188\n",
      "Epoch 65: Train Loss: 0.5624769330024719, Validation Loss: 0.5624769330024719\n",
      "Epoch 66: Train Loss: 0.8120591640472412, Validation Loss: 0.8120591640472412\n",
      "Epoch 67: Train Loss: 0.7239733338356018, Validation Loss: 0.7239733338356018\n",
      "Epoch 68: Train Loss: 0.6096110343933105, Validation Loss: 0.6096110343933105\n",
      "Epoch 69: Train Loss: 0.5815417766571045, Validation Loss: 0.5815417766571045\n",
      "Epoch 70: Train Loss: 0.49804818630218506, Validation Loss: 0.49804818630218506\n",
      "Epoch 71: Train Loss: 0.8064435720443726, Validation Loss: 0.8064435720443726\n",
      "Epoch 72: Train Loss: 0.3925720453262329, Validation Loss: 0.3925720453262329\n",
      "Epoch 73: Train Loss: 0.3859446346759796, Validation Loss: 0.3859446346759796\n",
      "Epoch 74: Train Loss: 0.4579738676548004, Validation Loss: 0.4579738676548004\n",
      "Epoch 75: Train Loss: 0.4147252142429352, Validation Loss: 0.4147252142429352\n",
      "Epoch 76: Train Loss: 0.41414424777030945, Validation Loss: 0.41414424777030945\n",
      "Epoch 77: Train Loss: 0.43585991859436035, Validation Loss: 0.43585991859436035\n",
      "Epoch 78: Train Loss: 0.4657140076160431, Validation Loss: 0.4657140076160431\n",
      "Epoch 79: Train Loss: 0.47689786553382874, Validation Loss: 0.47689786553382874\n",
      "Epoch 80: Train Loss: 0.6210107207298279, Validation Loss: 0.6210107207298279\n",
      "Epoch 81: Train Loss: 0.42968612909317017, Validation Loss: 0.42968612909317017\n",
      "Epoch 82: Train Loss: 0.4772990643978119, Validation Loss: 0.4772990643978119\n",
      "Early stopping at epoch 83\n",
      "Fold 2\n",
      "Epoch 0: Train Loss: 0.6860224604606628, Validation Loss: 0.6860224604606628\n",
      "Epoch 1: Train Loss: 0.679347038269043, Validation Loss: 0.679347038269043\n",
      "Epoch 2: Train Loss: 0.6735711097717285, Validation Loss: 0.6735711097717285\n",
      "Epoch 3: Train Loss: 0.661706268787384, Validation Loss: 0.661706268787384\n",
      "Epoch 4: Train Loss: 0.6506905555725098, Validation Loss: 0.6506905555725098\n",
      "Epoch 5: Train Loss: 0.6407186985015869, Validation Loss: 0.6407186985015869\n",
      "Epoch 6: Train Loss: 0.6300042271614075, Validation Loss: 0.6300042271614075\n",
      "Epoch 7: Train Loss: 0.6195517778396606, Validation Loss: 0.6195517778396606\n",
      "Epoch 8: Train Loss: 0.6092022061347961, Validation Loss: 0.6092022061347961\n",
      "Epoch 9: Train Loss: 0.6004015207290649, Validation Loss: 0.6004015207290649\n",
      "Epoch 10: Train Loss: 0.5863183736801147, Validation Loss: 0.5863183736801147\n",
      "Epoch 11: Train Loss: 0.56632399559021, Validation Loss: 0.56632399559021\n",
      "Epoch 12: Train Loss: 0.5695880055427551, Validation Loss: 0.5695880055427551\n",
      "Epoch 13: Train Loss: 0.5617933869361877, Validation Loss: 0.5617933869361877\n",
      "Epoch 14: Train Loss: 0.5463904142379761, Validation Loss: 0.5463904142379761\n",
      "Epoch 15: Train Loss: 0.5404808521270752, Validation Loss: 0.5404808521270752\n",
      "Epoch 16: Train Loss: 0.5281162858009338, Validation Loss: 0.5281162858009338\n",
      "Epoch 17: Train Loss: 0.518129825592041, Validation Loss: 0.518129825592041\n",
      "Epoch 18: Train Loss: 0.5125765204429626, Validation Loss: 0.5125765204429626\n",
      "Epoch 19: Train Loss: 0.5082190036773682, Validation Loss: 0.5082190036773682\n",
      "Epoch 20: Train Loss: 0.4961473047733307, Validation Loss: 0.4961473047733307\n",
      "Epoch 21: Train Loss: 0.44966989755630493, Validation Loss: 0.44966989755630493\n",
      "Epoch 22: Train Loss: 0.4367493987083435, Validation Loss: 0.4367493987083435\n",
      "Epoch 23: Train Loss: 0.6213281154632568, Validation Loss: 0.6213281154632568\n",
      "Epoch 24: Train Loss: 0.5666214227676392, Validation Loss: 0.5666214227676392\n",
      "Epoch 25: Train Loss: 0.4329794943332672, Validation Loss: 0.4329794943332672\n",
      "Epoch 26: Train Loss: 0.42794671654701233, Validation Loss: 0.42794671654701233\n",
      "Epoch 27: Train Loss: 0.4419006109237671, Validation Loss: 0.4419006109237671\n",
      "Epoch 28: Train Loss: 0.4406560957431793, Validation Loss: 0.4406560957431793\n",
      "Epoch 29: Train Loss: 0.4331590235233307, Validation Loss: 0.4331590235233307\n",
      "Epoch 30: Train Loss: 0.46156707406044006, Validation Loss: 0.46156707406044006\n",
      "Epoch 31: Train Loss: 0.5125858783721924, Validation Loss: 0.5125858783721924\n",
      "Epoch 32: Train Loss: 0.5729290843009949, Validation Loss: 0.5729290843009949\n",
      "Epoch 33: Train Loss: 0.7354642748832703, Validation Loss: 0.7354642748832703\n",
      "Epoch 34: Train Loss: 0.4563058912754059, Validation Loss: 0.4563058912754059\n",
      "Epoch 35: Train Loss: 0.5393873453140259, Validation Loss: 0.5393873453140259\n",
      "Epoch 36: Train Loss: 0.44673794507980347, Validation Loss: 0.44673794507980347\n",
      "Epoch 37: Train Loss: 0.45806047320365906, Validation Loss: 0.45806047320365906\n",
      "Epoch 38: Train Loss: 0.46173399686813354, Validation Loss: 0.46173399686813354\n",
      "Epoch 39: Train Loss: 0.4614793360233307, Validation Loss: 0.4614793360233307\n",
      "Epoch 40: Train Loss: 0.5785236358642578, Validation Loss: 0.5785236358642578\n",
      "Epoch 41: Train Loss: 0.48015090823173523, Validation Loss: 0.48015090823173523\n",
      "Epoch 42: Train Loss: 0.6098998188972473, Validation Loss: 0.6098998188972473\n",
      "Epoch 43: Train Loss: 0.6568535566329956, Validation Loss: 0.6568535566329956\n",
      "Epoch 44: Train Loss: 0.5642475485801697, Validation Loss: 0.5642475485801697\n",
      "Epoch 45: Train Loss: 0.5696231126785278, Validation Loss: 0.5696231126785278\n",
      "Epoch 46: Train Loss: 0.5702275037765503, Validation Loss: 0.5702275037765503\n",
      "Epoch 47: Train Loss: 0.568528950214386, Validation Loss: 0.568528950214386\n",
      "Epoch 48: Train Loss: 0.576605498790741, Validation Loss: 0.576605498790741\n",
      "Epoch 49: Train Loss: 0.5789016485214233, Validation Loss: 0.5789016485214233\n",
      "Epoch 50: Train Loss: 0.7113437056541443, Validation Loss: 0.7113437056541443\n",
      "Epoch 51: Train Loss: 0.6739242076873779, Validation Loss: 0.6739242076873779\n",
      "Epoch 52: Train Loss: 0.6473652124404907, Validation Loss: 0.6473652124404907\n",
      "Epoch 53: Train Loss: 0.6701231598854065, Validation Loss: 0.6701231598854065\n",
      "Epoch 54: Train Loss: 0.6844372749328613, Validation Loss: 0.6844372749328613\n",
      "Epoch 55: Train Loss: 0.7022857069969177, Validation Loss: 0.7022857069969177\n",
      "Epoch 56: Train Loss: 0.7117298245429993, Validation Loss: 0.7117298245429993\n",
      "Epoch 57: Train Loss: 0.7442852854728699, Validation Loss: 0.7442852854728699\n",
      "Epoch 58: Train Loss: 0.7356313467025757, Validation Loss: 0.7356313467025757\n",
      "Epoch 59: Train Loss: 0.7346001267433167, Validation Loss: 0.7346001267433167\n",
      "Epoch 60: Train Loss: 0.7944656610488892, Validation Loss: 0.7944656610488892\n",
      "Epoch 61: Train Loss: 0.8469997644424438, Validation Loss: 0.8469997644424438\n",
      "Epoch 62: Train Loss: 0.9923084378242493, Validation Loss: 0.9923084378242493\n",
      "Epoch 63: Train Loss: 0.9674663543701172, Validation Loss: 0.9674663543701172\n",
      "Epoch 64: Train Loss: 0.7805121541023254, Validation Loss: 0.7805121541023254\n",
      "Epoch 65: Train Loss: 0.8158718347549438, Validation Loss: 0.8158718347549438\n",
      "Early stopping at epoch 66\n",
      "Fold 3\n",
      "Epoch 0: Train Loss: 0.6839327216148376, Validation Loss: 0.6839327216148376\n",
      "Epoch 1: Train Loss: 0.6976602077484131, Validation Loss: 0.6976602077484131\n",
      "Epoch 2: Train Loss: 0.6731340885162354, Validation Loss: 0.6731340885162354\n",
      "Epoch 3: Train Loss: 0.6655508279800415, Validation Loss: 0.6655508279800415\n",
      "Epoch 4: Train Loss: 0.6614990830421448, Validation Loss: 0.6614990830421448\n",
      "Epoch 5: Train Loss: 0.6677725315093994, Validation Loss: 0.6677725315093994\n",
      "Epoch 6: Train Loss: 0.6754022240638733, Validation Loss: 0.6754022240638733\n",
      "Epoch 7: Train Loss: 0.6689931154251099, Validation Loss: 0.6689931154251099\n",
      "Epoch 8: Train Loss: 0.662693440914154, Validation Loss: 0.662693440914154\n",
      "Epoch 9: Train Loss: 0.6604101657867432, Validation Loss: 0.6604101657867432\n",
      "Epoch 10: Train Loss: 0.6814586520195007, Validation Loss: 0.6814586520195007\n",
      "Epoch 11: Train Loss: 0.6421657800674438, Validation Loss: 0.6421657800674438\n",
      "Epoch 12: Train Loss: 0.7717313766479492, Validation Loss: 0.7717313766479492\n",
      "Epoch 13: Train Loss: 0.7391307353973389, Validation Loss: 0.7391307353973389\n",
      "Epoch 14: Train Loss: 0.6525906920433044, Validation Loss: 0.6525906920433044\n",
      "Epoch 15: Train Loss: 0.6707964539527893, Validation Loss: 0.6707964539527893\n",
      "Epoch 16: Train Loss: 0.6721480488777161, Validation Loss: 0.6721480488777161\n",
      "Epoch 17: Train Loss: 0.6805194616317749, Validation Loss: 0.6805194616317749\n",
      "Epoch 18: Train Loss: 0.6905184984207153, Validation Loss: 0.6905184984207153\n",
      "Epoch 19: Train Loss: 0.6962973475456238, Validation Loss: 0.6962973475456238\n",
      "Epoch 20: Train Loss: 0.7682082056999207, Validation Loss: 0.7682082056999207\n",
      "Epoch 21: Train Loss: 0.7021399736404419, Validation Loss: 0.7021399736404419\n",
      "Epoch 22: Train Loss: 0.6967173218727112, Validation Loss: 0.6967173218727112\n",
      "Epoch 23: Train Loss: 0.6839743256568909, Validation Loss: 0.6839743256568909\n",
      "Epoch 24: Train Loss: 0.692664384841919, Validation Loss: 0.692664384841919\n",
      "Epoch 25: Train Loss: 0.67615807056427, Validation Loss: 0.67615807056427\n",
      "Epoch 26: Train Loss: 0.656861424446106, Validation Loss: 0.656861424446106\n",
      "Epoch 27: Train Loss: 0.6360138058662415, Validation Loss: 0.6360138058662415\n",
      "Epoch 28: Train Loss: 0.6269009709358215, Validation Loss: 0.6269009709358215\n",
      "Epoch 29: Train Loss: 0.624495267868042, Validation Loss: 0.624495267868042\n",
      "Epoch 30: Train Loss: 0.6228814721107483, Validation Loss: 0.6228814721107483\n",
      "Epoch 31: Train Loss: 0.5977184772491455, Validation Loss: 0.5977184772491455\n",
      "Epoch 32: Train Loss: 0.5697823762893677, Validation Loss: 0.5697823762893677\n",
      "Epoch 33: Train Loss: 0.600151002407074, Validation Loss: 0.600151002407074\n",
      "Epoch 34: Train Loss: 0.5875934958457947, Validation Loss: 0.5875934958457947\n",
      "Epoch 35: Train Loss: 0.5935498476028442, Validation Loss: 0.5935498476028442\n",
      "Epoch 36: Train Loss: 0.6220158338546753, Validation Loss: 0.6220158338546753\n",
      "Epoch 37: Train Loss: 0.5953863859176636, Validation Loss: 0.5953863859176636\n",
      "Epoch 38: Train Loss: 0.5748816132545471, Validation Loss: 0.5748816132545471\n",
      "Epoch 39: Train Loss: 0.5670181512832642, Validation Loss: 0.5670181512832642\n",
      "Epoch 40: Train Loss: 0.5818294882774353, Validation Loss: 0.5818294882774353\n",
      "Epoch 41: Train Loss: 0.7653242945671082, Validation Loss: 0.7653242945671082\n",
      "Epoch 42: Train Loss: 0.5980101227760315, Validation Loss: 0.5980101227760315\n",
      "Epoch 43: Train Loss: 0.5261072516441345, Validation Loss: 0.5261072516441345\n",
      "Epoch 44: Train Loss: 0.6054294109344482, Validation Loss: 0.6054294109344482\n",
      "Epoch 45: Train Loss: 0.5432386994361877, Validation Loss: 0.5432386994361877\n",
      "Epoch 46: Train Loss: 0.47894391417503357, Validation Loss: 0.47894391417503357\n",
      "Epoch 47: Train Loss: 0.4552701413631439, Validation Loss: 0.4552701413631439\n",
      "Epoch 48: Train Loss: 0.4471821188926697, Validation Loss: 0.4471821188926697\n",
      "Epoch 49: Train Loss: 0.4417366683483124, Validation Loss: 0.4417366683483124\n",
      "Epoch 50: Train Loss: 0.5148800611495972, Validation Loss: 0.5148800611495972\n",
      "Epoch 51: Train Loss: 0.43223974108695984, Validation Loss: 0.43223974108695984\n",
      "Epoch 52: Train Loss: 0.5494657754898071, Validation Loss: 0.5494657754898071\n",
      "Epoch 53: Train Loss: 0.44915562868118286, Validation Loss: 0.44915562868118286\n",
      "Epoch 54: Train Loss: 0.4971103072166443, Validation Loss: 0.4971103072166443\n",
      "Epoch 55: Train Loss: 0.6328336000442505, Validation Loss: 0.6328336000442505\n",
      "Epoch 56: Train Loss: 0.5395100116729736, Validation Loss: 0.5395100116729736\n",
      "Epoch 57: Train Loss: 0.47265374660491943, Validation Loss: 0.47265374660491943\n",
      "Epoch 58: Train Loss: 0.4571097493171692, Validation Loss: 0.4571097493171692\n",
      "Epoch 59: Train Loss: 0.4466035068035126, Validation Loss: 0.4466035068035126\n",
      "Epoch 60: Train Loss: 0.5704178214073181, Validation Loss: 0.5704178214073181\n",
      "Epoch 61: Train Loss: 0.4852811098098755, Validation Loss: 0.4852811098098755\n",
      "Epoch 62: Train Loss: 0.5199893116950989, Validation Loss: 0.5199893116950989\n",
      "Epoch 63: Train Loss: 0.5077449083328247, Validation Loss: 0.5077449083328247\n",
      "Epoch 64: Train Loss: 0.47040432691574097, Validation Loss: 0.47040432691574097\n",
      "Epoch 65: Train Loss: 0.45582982897758484, Validation Loss: 0.45582982897758484\n",
      "Epoch 66: Train Loss: 0.634911298751831, Validation Loss: 0.634911298751831\n",
      "Epoch 67: Train Loss: 0.5671943426132202, Validation Loss: 0.5671943426132202\n",
      "Epoch 68: Train Loss: 0.46875306963920593, Validation Loss: 0.46875306963920593\n",
      "Epoch 69: Train Loss: 0.45382818579673767, Validation Loss: 0.45382818579673767\n",
      "Epoch 70: Train Loss: 0.7184982895851135, Validation Loss: 0.7184982895851135\n",
      "Epoch 71: Train Loss: 0.43265217542648315, Validation Loss: 0.43265217542648315\n",
      "Epoch 72: Train Loss: 0.5088679790496826, Validation Loss: 0.5088679790496826\n",
      "Epoch 73: Train Loss: 0.43582993745803833, Validation Loss: 0.43582993745803833\n",
      "Epoch 74: Train Loss: 0.4272368550300598, Validation Loss: 0.4272368550300598\n",
      "Epoch 75: Train Loss: 0.4279707074165344, Validation Loss: 0.4279707074165344\n",
      "Epoch 76: Train Loss: 0.4187096059322357, Validation Loss: 0.4187096059322357\n",
      "Epoch 77: Train Loss: 0.4225376546382904, Validation Loss: 0.4225376546382904\n",
      "Epoch 78: Train Loss: 0.4284323751926422, Validation Loss: 0.4284323751926422\n",
      "Epoch 79: Train Loss: 0.4295583963394165, Validation Loss: 0.4295583963394165\n",
      "Epoch 80: Train Loss: 0.45905226469039917, Validation Loss: 0.45905226469039917\n",
      "Epoch 81: Train Loss: 0.4277472198009491, Validation Loss: 0.4277472198009491\n",
      "Epoch 82: Train Loss: 0.5921146869659424, Validation Loss: 0.5921146869659424\n",
      "Epoch 83: Train Loss: 0.40229588747024536, Validation Loss: 0.40229588747024536\n",
      "Epoch 84: Train Loss: 0.5774053335189819, Validation Loss: 0.5774053335189819\n",
      "Epoch 85: Train Loss: 0.4237588047981262, Validation Loss: 0.4237588047981262\n",
      "Epoch 86: Train Loss: 0.4207592010498047, Validation Loss: 0.4207592010498047\n",
      "Epoch 87: Train Loss: 0.4371693730354309, Validation Loss: 0.4371693730354309\n",
      "Epoch 88: Train Loss: 0.4583248496055603, Validation Loss: 0.4583248496055603\n",
      "Epoch 89: Train Loss: 0.4573177099227905, Validation Loss: 0.4573177099227905\n",
      "Epoch 90: Train Loss: 0.5601327419281006, Validation Loss: 0.5601327419281006\n",
      "Epoch 91: Train Loss: 0.47811317443847656, Validation Loss: 0.47811317443847656\n",
      "Epoch 92: Train Loss: 0.526872992515564, Validation Loss: 0.526872992515564\n",
      "Epoch 93: Train Loss: 0.5488258600234985, Validation Loss: 0.5488258600234985\n",
      "Epoch 94: Train Loss: 0.6124064326286316, Validation Loss: 0.6124064326286316\n",
      "Epoch 95: Train Loss: 0.5066226124763489, Validation Loss: 0.5066226124763489\n",
      "Epoch 96: Train Loss: 0.5058413147926331, Validation Loss: 0.5058413147926331\n",
      "Epoch 97: Train Loss: 0.4861808717250824, Validation Loss: 0.4861808717250824\n",
      "Epoch 98: Train Loss: 0.48234307765960693, Validation Loss: 0.48234307765960693\n",
      "Epoch 99: Train Loss: 0.4810066819190979, Validation Loss: 0.4810066819190979\n",
      "Fold 4\n",
      "Epoch 0: Train Loss: 0.7302178144454956, Validation Loss: 0.7302178144454956\n",
      "Epoch 1: Train Loss: 0.7087960243225098, Validation Loss: 0.7087960243225098\n",
      "Epoch 2: Train Loss: 0.7478426694869995, Validation Loss: 0.7478426694869995\n",
      "Epoch 3: Train Loss: 0.7916551232337952, Validation Loss: 0.7916551232337952\n",
      "Epoch 4: Train Loss: 0.7752513885498047, Validation Loss: 0.7752513885498047\n",
      "Epoch 5: Train Loss: 0.7264728546142578, Validation Loss: 0.7264728546142578\n",
      "Epoch 6: Train Loss: 0.7037712335586548, Validation Loss: 0.7037712335586548\n",
      "Epoch 7: Train Loss: 0.6962497234344482, Validation Loss: 0.6962497234344482\n",
      "Epoch 8: Train Loss: 0.6936771869659424, Validation Loss: 0.6936771869659424\n",
      "Epoch 9: Train Loss: 0.6881973147392273, Validation Loss: 0.6881973147392273\n",
      "Epoch 10: Train Loss: 0.7960752248764038, Validation Loss: 0.7960752248764038\n",
      "Epoch 11: Train Loss: 0.7227829694747925, Validation Loss: 0.7227829694747925\n",
      "Epoch 12: Train Loss: 0.6553265452384949, Validation Loss: 0.6553265452384949\n",
      "Epoch 13: Train Loss: 0.6623504757881165, Validation Loss: 0.6623504757881165\n",
      "Epoch 14: Train Loss: 0.6518295407295227, Validation Loss: 0.6518295407295227\n",
      "Epoch 15: Train Loss: 0.7603214383125305, Validation Loss: 0.7603214383125305\n",
      "Epoch 16: Train Loss: 0.7349277138710022, Validation Loss: 0.7349277138710022\n",
      "Epoch 17: Train Loss: 0.6926746964454651, Validation Loss: 0.6926746964454651\n",
      "Epoch 18: Train Loss: 0.669248104095459, Validation Loss: 0.669248104095459\n",
      "Epoch 19: Train Loss: 0.66893070936203, Validation Loss: 0.66893070936203\n",
      "Epoch 20: Train Loss: 0.6749099493026733, Validation Loss: 0.6749099493026733\n",
      "Epoch 21: Train Loss: 0.6177082657814026, Validation Loss: 0.6177082657814026\n",
      "Epoch 22: Train Loss: 0.8034015893936157, Validation Loss: 0.8034015893936157\n",
      "Epoch 23: Train Loss: 0.630472719669342, Validation Loss: 0.630472719669342\n",
      "Epoch 24: Train Loss: 0.5808449983596802, Validation Loss: 0.5808449983596802\n",
      "Epoch 25: Train Loss: 0.5693257451057434, Validation Loss: 0.5693257451057434\n",
      "Epoch 26: Train Loss: 0.5756866931915283, Validation Loss: 0.5756866931915283\n",
      "Epoch 27: Train Loss: 0.616710364818573, Validation Loss: 0.616710364818573\n",
      "Epoch 28: Train Loss: 0.635412335395813, Validation Loss: 0.635412335395813\n",
      "Epoch 29: Train Loss: 0.6400760412216187, Validation Loss: 0.6400760412216187\n",
      "Epoch 30: Train Loss: 0.580809473991394, Validation Loss: 0.580809473991394\n",
      "Epoch 31: Train Loss: 0.5897238254547119, Validation Loss: 0.5897238254547119\n",
      "Epoch 32: Train Loss: 0.6380223035812378, Validation Loss: 0.6380223035812378\n",
      "Epoch 33: Train Loss: 0.6104318499565125, Validation Loss: 0.6104318499565125\n",
      "Epoch 34: Train Loss: 0.6055009961128235, Validation Loss: 0.6055009961128235\n",
      "Epoch 35: Train Loss: 0.6144094467163086, Validation Loss: 0.6144094467163086\n",
      "Epoch 36: Train Loss: 0.5762486457824707, Validation Loss: 0.5762486457824707\n",
      "Epoch 37: Train Loss: 0.6128267645835876, Validation Loss: 0.6128267645835876\n",
      "Epoch 38: Train Loss: 0.6185483932495117, Validation Loss: 0.6185483932495117\n",
      "Epoch 39: Train Loss: 0.6281620264053345, Validation Loss: 0.6281620264053345\n",
      "Epoch 40: Train Loss: 0.5651196837425232, Validation Loss: 0.5651196837425232\n",
      "Epoch 41: Train Loss: 0.6738120317459106, Validation Loss: 0.6738120317459106\n",
      "Epoch 42: Train Loss: 0.5577893853187561, Validation Loss: 0.5577893853187561\n",
      "Epoch 43: Train Loss: 0.5479950308799744, Validation Loss: 0.5479950308799744\n",
      "Epoch 44: Train Loss: 0.6278362274169922, Validation Loss: 0.6278362274169922\n",
      "Epoch 45: Train Loss: 0.6393110752105713, Validation Loss: 0.6393110752105713\n",
      "Epoch 46: Train Loss: 0.5573522448539734, Validation Loss: 0.5573522448539734\n",
      "Epoch 47: Train Loss: 0.550394594669342, Validation Loss: 0.550394594669342\n",
      "Epoch 48: Train Loss: 0.5503464341163635, Validation Loss: 0.5503464341163635\n",
      "Epoch 49: Train Loss: 0.552291214466095, Validation Loss: 0.552291214466095\n",
      "Epoch 50: Train Loss: 0.5796352028846741, Validation Loss: 0.5796352028846741\n",
      "Epoch 51: Train Loss: 0.5892612338066101, Validation Loss: 0.5892612338066101\n",
      "Epoch 52: Train Loss: 0.7065934538841248, Validation Loss: 0.7065934538841248\n",
      "Epoch 53: Train Loss: 0.5752961039543152, Validation Loss: 0.5752961039543152\n",
      "Epoch 54: Train Loss: 0.58709716796875, Validation Loss: 0.58709716796875\n",
      "Epoch 55: Train Loss: 0.5957298278808594, Validation Loss: 0.5957298278808594\n",
      "Epoch 56: Train Loss: 0.5751932859420776, Validation Loss: 0.5751932859420776\n",
      "Epoch 57: Train Loss: 0.5595639944076538, Validation Loss: 0.5595639944076538\n",
      "Epoch 58: Train Loss: 0.5568091869354248, Validation Loss: 0.5568091869354248\n",
      "Epoch 59: Train Loss: 0.5653383135795593, Validation Loss: 0.5653383135795593\n",
      "Epoch 60: Train Loss: 0.5647865533828735, Validation Loss: 0.5647865533828735\n",
      "Epoch 61: Train Loss: 0.5744538903236389, Validation Loss: 0.5744538903236389\n",
      "Epoch 62: Train Loss: 0.6719837784767151, Validation Loss: 0.6719837784767151\n",
      "Epoch 63: Train Loss: 0.865766704082489, Validation Loss: 0.865766704082489\n",
      "Epoch 64: Train Loss: 0.6108432412147522, Validation Loss: 0.6108432412147522\n",
      "Epoch 65: Train Loss: 0.7083181738853455, Validation Loss: 0.7083181738853455\n",
      "Epoch 66: Train Loss: 0.6024461388587952, Validation Loss: 0.6024461388587952\n",
      "Epoch 67: Train Loss: 0.65047687292099, Validation Loss: 0.65047687292099\n",
      "Epoch 68: Train Loss: 0.6809827089309692, Validation Loss: 0.6809827089309692\n",
      "Epoch 69: Train Loss: 0.679147481918335, Validation Loss: 0.679147481918335\n",
      "Epoch 70: Train Loss: 0.5649949908256531, Validation Loss: 0.5649949908256531\n",
      "Epoch 71: Train Loss: 0.5807834267616272, Validation Loss: 0.5807834267616272\n",
      "Epoch 72: Train Loss: 0.5824607014656067, Validation Loss: 0.5824607014656067\n",
      "Epoch 73: Train Loss: 0.5706316232681274, Validation Loss: 0.5706316232681274\n",
      "Epoch 74: Train Loss: 0.593528687953949, Validation Loss: 0.593528687953949\n",
      "Epoch 75: Train Loss: 0.5826548337936401, Validation Loss: 0.5826548337936401\n",
      "Epoch 76: Train Loss: 0.5863006711006165, Validation Loss: 0.5863006711006165\n",
      "Epoch 77: Train Loss: 0.5981988906860352, Validation Loss: 0.5981988906860352\n",
      "Epoch 78: Train Loss: 0.6111123561859131, Validation Loss: 0.6111123561859131\n",
      "Epoch 79: Train Loss: 0.622068464756012, Validation Loss: 0.622068464756012\n",
      "Epoch 80: Train Loss: 0.6218429803848267, Validation Loss: 0.6218429803848267\n",
      "Epoch 81: Train Loss: 0.6536044478416443, Validation Loss: 0.6536044478416443\n",
      "Epoch 82: Train Loss: 0.7102532386779785, Validation Loss: 0.7102532386779785\n",
      "Early stopping at epoch 83\n",
      "Fold 5\n",
      "Epoch 0: Train Loss: 0.6968576908111572, Validation Loss: 0.6968576908111572\n",
      "Epoch 1: Train Loss: 0.7160483002662659, Validation Loss: 0.7160483002662659\n",
      "Epoch 2: Train Loss: 0.7024834156036377, Validation Loss: 0.7024834156036377\n",
      "Epoch 3: Train Loss: 0.7057824730873108, Validation Loss: 0.7057824730873108\n",
      "Epoch 4: Train Loss: 0.7357702255249023, Validation Loss: 0.7357702255249023\n",
      "Epoch 5: Train Loss: 0.7699788212776184, Validation Loss: 0.7699788212776184\n",
      "Epoch 6: Train Loss: 0.7739421129226685, Validation Loss: 0.7739421129226685\n",
      "Epoch 7: Train Loss: 0.7608808875083923, Validation Loss: 0.7608808875083923\n",
      "Epoch 8: Train Loss: 0.7593601942062378, Validation Loss: 0.7593601942062378\n",
      "Epoch 9: Train Loss: 0.7639061212539673, Validation Loss: 0.7639061212539673\n",
      "Epoch 10: Train Loss: 0.7429056763648987, Validation Loss: 0.7429056763648987\n",
      "Epoch 11: Train Loss: 0.7499173879623413, Validation Loss: 0.7499173879623413\n",
      "Epoch 12: Train Loss: 0.7756070494651794, Validation Loss: 0.7756070494651794\n",
      "Epoch 13: Train Loss: 0.7183810472488403, Validation Loss: 0.7183810472488403\n",
      "Epoch 14: Train Loss: 0.72495037317276, Validation Loss: 0.72495037317276\n",
      "Epoch 15: Train Loss: 0.7625712752342224, Validation Loss: 0.7625712752342224\n",
      "Epoch 16: Train Loss: 0.776573896408081, Validation Loss: 0.776573896408081\n",
      "Epoch 17: Train Loss: 0.7841692566871643, Validation Loss: 0.7841692566871643\n",
      "Epoch 18: Train Loss: 0.7889822721481323, Validation Loss: 0.7889822721481323\n",
      "Epoch 19: Train Loss: 0.795558750629425, Validation Loss: 0.795558750629425\n",
      "Epoch 20: Train Loss: 0.7771251201629639, Validation Loss: 0.7771251201629639\n",
      "Epoch 21: Train Loss: 0.8297745585441589, Validation Loss: 0.8297745585441589\n",
      "Epoch 22: Train Loss: 0.7578312754631042, Validation Loss: 0.7578312754631042\n",
      "Epoch 23: Train Loss: 0.8018864989280701, Validation Loss: 0.8018864989280701\n",
      "Epoch 24: Train Loss: 0.781093418598175, Validation Loss: 0.781093418598175\n",
      "Epoch 25: Train Loss: 0.7261059880256653, Validation Loss: 0.7261059880256653\n",
      "Epoch 26: Train Loss: 0.712069034576416, Validation Loss: 0.712069034576416\n",
      "Epoch 27: Train Loss: 0.691922664642334, Validation Loss: 0.691922664642334\n",
      "Epoch 28: Train Loss: 0.7038736343383789, Validation Loss: 0.7038736343383789\n",
      "Epoch 29: Train Loss: 0.7126335501670837, Validation Loss: 0.7126335501670837\n",
      "Epoch 30: Train Loss: 0.8948017954826355, Validation Loss: 0.8948017954826355\n",
      "Epoch 31: Train Loss: 0.7406115531921387, Validation Loss: 0.7406115531921387\n",
      "Epoch 32: Train Loss: 0.6537710428237915, Validation Loss: 0.6537710428237915\n",
      "Epoch 33: Train Loss: 0.9736342430114746, Validation Loss: 0.9736342430114746\n",
      "Epoch 34: Train Loss: 0.7621574997901917, Validation Loss: 0.7621574997901917\n",
      "Epoch 35: Train Loss: 0.7016080021858215, Validation Loss: 0.7016080021858215\n",
      "Epoch 36: Train Loss: 0.8027122020721436, Validation Loss: 0.8027122020721436\n",
      "Epoch 37: Train Loss: 0.9117956161499023, Validation Loss: 0.9117956161499023\n",
      "Epoch 38: Train Loss: 0.9235599637031555, Validation Loss: 0.9235599637031555\n",
      "Epoch 39: Train Loss: 0.9042117595672607, Validation Loss: 0.9042117595672607\n",
      "Epoch 40: Train Loss: 0.6830268502235413, Validation Loss: 0.6830268502235413\n",
      "Epoch 41: Train Loss: 1.0124584436416626, Validation Loss: 1.0124584436416626\n",
      "Epoch 42: Train Loss: 0.9219377040863037, Validation Loss: 0.9219377040863037\n",
      "Epoch 43: Train Loss: 0.6788243651390076, Validation Loss: 0.6788243651390076\n",
      "Epoch 44: Train Loss: 0.7083425521850586, Validation Loss: 0.7083425521850586\n",
      "Epoch 45: Train Loss: 0.9120153188705444, Validation Loss: 0.9120153188705444\n",
      "Epoch 46: Train Loss: 0.9938399791717529, Validation Loss: 0.9938399791717529\n",
      "Epoch 47: Train Loss: 0.8866857886314392, Validation Loss: 0.8866857886314392\n",
      "Epoch 48: Train Loss: 0.8292655348777771, Validation Loss: 0.8292655348777771\n",
      "Epoch 49: Train Loss: 0.8162855505943298, Validation Loss: 0.8162855505943298\n",
      "Epoch 50: Train Loss: 0.6831231117248535, Validation Loss: 0.6831231117248535\n",
      "Epoch 51: Train Loss: 0.8829182982444763, Validation Loss: 0.8829182982444763\n",
      "Epoch 52: Train Loss: 0.8724716901779175, Validation Loss: 0.8724716901779175\n",
      "Epoch 53: Train Loss: 0.754024088382721, Validation Loss: 0.754024088382721\n",
      "Epoch 54: Train Loss: 0.88178950548172, Validation Loss: 0.88178950548172\n",
      "Epoch 55: Train Loss: 0.9773721694946289, Validation Loss: 0.9773721694946289\n",
      "Epoch 56: Train Loss: 0.8622782826423645, Validation Loss: 0.8622782826423645\n",
      "Epoch 57: Train Loss: 0.7756489515304565, Validation Loss: 0.7756489515304565\n",
      "Epoch 58: Train Loss: 0.7748486995697021, Validation Loss: 0.7748486995697021\n",
      "Epoch 59: Train Loss: 0.7868605852127075, Validation Loss: 0.7868605852127075\n",
      "Epoch 60: Train Loss: 0.848503053188324, Validation Loss: 0.848503053188324\n",
      "Epoch 61: Train Loss: 0.702883243560791, Validation Loss: 0.702883243560791\n",
      "Epoch 62: Train Loss: 0.7879846692085266, Validation Loss: 0.7879846692085266\n",
      "Epoch 63: Train Loss: 0.8846420645713806, Validation Loss: 0.8846420645713806\n",
      "Epoch 64: Train Loss: 0.8276959657669067, Validation Loss: 0.8276959657669067\n",
      "Epoch 65: Train Loss: 0.810899555683136, Validation Loss: 0.810899555683136\n",
      "Epoch 66: Train Loss: 0.9038214683532715, Validation Loss: 0.9038214683532715\n",
      "Epoch 67: Train Loss: 0.963398277759552, Validation Loss: 0.963398277759552\n",
      "Epoch 68: Train Loss: 0.9529656171798706, Validation Loss: 0.9529656171798706\n",
      "Epoch 69: Train Loss: 0.9402452111244202, Validation Loss: 0.9402452111244202\n",
      "Epoch 70: Train Loss: 0.767772376537323, Validation Loss: 0.767772376537323\n",
      "Epoch 71: Train Loss: 1.076156735420227, Validation Loss: 1.076156735420227\n",
      "Early stopping at epoch 72\n",
      "Accuracy: 0.6833333333333333,Precision: 0.6617647058823529, Recall: 0.75, F1-score: 0.703125, AUC: 0.6833333333333333\n",
      "Confusion Matrix:\n",
      "[[37 23]\n",
      " [15 45]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "# Define a function to load and pad data\n",
    "def load_data(data_dir, max_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    file_list = os.listdir(data_dir)\n",
    "    for file in file_list:\n",
    "        with open(os.path.join(data_dir, file), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        label = 0 if 'truth' in file else 1\n",
    "        padded_data = np.zeros((65, max_length))\n",
    "        length = min(data.shape[1], max_length)\n",
    "        padded_data[:, :length] = data[:, :length]\n",
    "        X.append(padded_data)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Load dataset and pad the data\n",
    "data_dir = \"C:\\\\Users\\\\User\\\\Documents\\\\Lie detect data\\\\56M_DWTEEGData\"\n",
    "max_length = 1400  # Define maximum length for padding\n",
    "X, y = load_data(data_dir, max_length)\n",
    "\n",
    "# Define dataset class\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "# Define EEGNet model\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(65, 16, kernel_size=63, padding=31)  # Padding computed for 'same'\n",
    "        self.batchnorm1 = nn.BatchNorm1d(16)\n",
    "        self.depthwiseConv1d = nn.Conv1d(16, 32, kernel_size=65, groups=16, padding=32)  # Padding computed for 'same'\n",
    "        self.batchnorm2 = nn.BatchNorm1d(32)\n",
    "        self.activation = nn.ELU()\n",
    "        self.pooling = nn.AvgPool1d(kernel_size=4)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Calculate the number of features after the convolutions and pooling\n",
    "        self._calculate_num_features()\n",
    "        \n",
    "        self.fc = nn.Linear(self.num_features, num_classes)\n",
    "\n",
    "    def _calculate_num_features(self):\n",
    "        with torch.no_grad():\n",
    "            sample_input = torch.zeros(1, 65, 1400)\n",
    "            sample_output = self._forward_features(sample_input)\n",
    "            self.num_features = sample_output.shape[1]\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.depthwiseConv1d(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_and_evaluate(train_loader, val_loader, y_train):\n",
    "    model = EEGNet(num_classes=2).to(device)\n",
    "    \n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1)\n",
    "\n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 20\n",
    "    trigger_times = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(f'Early stopping at epoch {epoch}')\n",
    "                break\n",
    "\n",
    "        print(f'Epoch {epoch}: Train Loss: {loss.item()}, Validation Loss: {val_loss}')\n",
    "\n",
    "    return model\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_idx = 0\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "for train_index, val_index in kf.split(X, y):\n",
    "    print(f'Fold {fold_idx + 1}')\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    # Normalize data\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_train = X_train.reshape(-1, 65, max_length)\n",
    "\n",
    "    X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_val = X_val.reshape(-1, 65, max_length)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = EEGDataset(X_train, y_train)\n",
    "    val_dataset = EEGDataset(X_val, y_val)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = train_and_evaluate(train_loader, val_loader, y_train)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    fold_idx += 1\n",
    "\n",
    "\n",
    "# Calculate additional metrics\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "auc = roc_auc_score(all_labels, all_predictions)\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy},Precision: {precision}, Recall: {recall}, F1-score: {f1}, AUC: {auc}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66654d63-c450-4d9f-a3e3-63701fd1d41b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
