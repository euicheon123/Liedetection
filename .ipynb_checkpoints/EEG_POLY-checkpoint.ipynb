{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1159f92-96e7-4f79-9cd1-ec348c0a4b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG data...\n",
      "EEG File: augmented_lie_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_10.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_11.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_12.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_13.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_14.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_15.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_16.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_17.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_19.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_2.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_20.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_21.pkl, Shape: (17, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_22.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_23.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_24.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_25.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_26.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_27.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_28.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_29.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_3.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_30.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_31.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_33.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_34.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_4.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_5.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_6.pkl, Shape: (26, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_7.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_8.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_9.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_10.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_11.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_12.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_13.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_14.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_15.pkl, Shape: (4, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_16.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_17.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_19.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_2.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_20.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_21.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_22.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_23.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_24.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_25.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_26.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_27.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_28.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_29.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_3.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_30.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_31.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_33.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_34.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_36.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_37.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_38.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_39.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_4.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_40.pkl, Shape: (30, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_41.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_42.pkl, Shape: (18, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_43.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_44.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_45.pkl, Shape: (14, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_46.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_47.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_48.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_49.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_5.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_50.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_51.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_52.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_53.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_54.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_55.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_6.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_7.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_8.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_9.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "Loaded from EEG C:\\Users\\User\\Documents\\Lie detect data\\AugmentedEEGData: 333 lie samples, 602 truth samples\n",
      "Loading Poly data...\n",
      "Poly File: poly_lie_1.pkl, Shape: (4, 2963), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_10.pkl, Shape: (4, 3171), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_11.pkl, Shape: (4, 2917), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_12.pkl, Shape: (4, 2991), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_13.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_14.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_15.pkl, Shape: (4, 2929), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_16.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_17.pkl, Shape: (4, 3234), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_18.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_19.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_2.pkl, Shape: (4, 2895), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_20.pkl, Shape: (4, 3291), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_21.pkl, Shape: (4, 3658), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_22.pkl, Shape: (4, 3375), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_23.pkl, Shape: (4, 3334), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_24.pkl, Shape: (4, 3263), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_25.pkl, Shape: (4, 3292), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_26.pkl, Shape: (4, 3246), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_27.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_28.pkl, Shape: (4, 3262), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_29.pkl, Shape: (4, 3321), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_3.pkl, Shape: (4, 2941), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_30.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_31.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_32.pkl, Shape: (4, 3142), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_33.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_34.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_35.pkl, Shape: (4, 3179), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_4.pkl, Shape: (4, 2967), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_5.pkl, Shape: (4, 2913), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_6.pkl, Shape: (4, 4229), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_7.pkl, Shape: (4, 3129), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_8.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_9.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_1.pkl, Shape: (4, 2958), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_10.pkl, Shape: (4, 3104), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_11.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_12.pkl, Shape: (4, 3391), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_13.pkl, Shape: (4, 3141), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_14.pkl, Shape: (4, 3271), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_15.pkl, Shape: (4, 2859), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_16.pkl, Shape: (4, 3325), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_17.pkl, Shape: (4, 3383), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_18.pkl, Shape: (4, 3233), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_19.pkl, Shape: (4, 3366), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_2.pkl, Shape: (4, 3112), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_20.pkl, Shape: (4, 3313), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_21.pkl, Shape: (4, 3555), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_22.pkl, Shape: (4, 3346), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_23.pkl, Shape: (4, 3305), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_24.pkl, Shape: (4, 3200), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_25.pkl, Shape: (4, 3213), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_26.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_27.pkl, Shape: (4, 3188), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_28.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_29.pkl, Shape: (4, 3242), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_3.pkl, Shape: (4, 3016), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_30.pkl, Shape: (4, 3258), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_31.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_32.pkl, Shape: (4, 3175), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_33.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_34.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_35.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_36.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_37.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_38.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_39.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_4.pkl, Shape: (4, 3058), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_40.pkl, Shape: (4, 4475), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_41.pkl, Shape: (4, 3162), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_42.pkl, Shape: (4, 3704), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_43.pkl, Shape: (4, 3333), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_44.pkl, Shape: (4, 3396), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_45.pkl, Shape: (4, 3450), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_46.pkl, Shape: (4, 3537), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_47.pkl, Shape: (4, 3363), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_48.pkl, Shape: (4, 3250), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_49.pkl, Shape: (4, 3279), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_5.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_50.pkl, Shape: (4, 3508), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_51.pkl, Shape: (4, 3358), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_52.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_53.pkl, Shape: (4, 3379), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_54.pkl, Shape: (4, 3558), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_55.pkl, Shape: (4, 3392), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_6.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_7.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_8.pkl, Shape: (4, 3096), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_9.pkl, Shape: (4, 3225), Type: <class 'numpy.ndarray'>\n",
      "Loaded from Poly C:\\Users\\User\\Documents\\Lie detect data\\CombinedPolyData: 35 lie samples, 55 truth samples\n",
      "EEG Class distribution: {0: 333, 1: 602}\n",
      "Poly Class distribution: {0: 35, 1: 55}\n",
      "EEG data shape: (935, 65, 125)\n",
      "Poly data shape: (90, 4, 4475)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "\n",
    "# Constants\n",
    "EEG_DATA_DIR = r'C:\\Users\\User\\Documents\\Lie detect data\\AugmentedEEGData'\n",
    "POLY_DATA_DIR = r'C:\\Users\\User\\Documents\\Lie detect data\\CombinedPolyData'\n",
    "K_FOLDS = 5  # Number of folds for cross-validation\n",
    "\n",
    "def pad_sequence(sequence, target_length):\n",
    "    \"\"\"Pad the sequence to the target length.\"\"\"\n",
    "    pad_length = target_length - sequence.shape[1]\n",
    "    if pad_length > 0:\n",
    "        return np.pad(sequence, ((0, 0), (0, pad_length)), mode='constant')\n",
    "    else:\n",
    "        return sequence[:, :target_length]\n",
    "\n",
    "def load_eeg_data(data_dir):\n",
    "    X, y = [], []\n",
    "    lie_count, truth_count = 0, 0\n",
    "    file_sample_counts = []\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        if file_name.endswith('.pkl'):\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            try:\n",
    "                data = pd.read_pickle(file_path)\n",
    "                print(f\"EEG File: {file_name}, Shape: {data.shape}, Type: {type(data)}\")\n",
    "                label = 0 if 'lie' in file_name.lower() else 1\n",
    "                X.extend(data)\n",
    "                y.extend([label] * data.shape[0])\n",
    "                file_sample_counts.append(data.shape[0])\n",
    "                if label == 0:\n",
    "                    lie_count += data.shape[0]\n",
    "                else:\n",
    "                    truth_count += data.shape[0]\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading EEG file {file_name}: {str(e)}\")\n",
    "    print(f\"Loaded from EEG {data_dir}: {lie_count} lie samples, {truth_count} truth samples\")\n",
    "    return np.array(X), np.array(y), file_sample_counts\n",
    "\n",
    "def load_poly_data(data_dir):\n",
    "    X, y = [], []\n",
    "    lie_count, truth_count = 0, 0\n",
    "    max_length = 0\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        if file_name.endswith('.pkl'):\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            try:\n",
    "                data = pd.read_pickle(file_path)\n",
    "                print(f\"Poly File: {file_name}, Shape: {data.shape}, Type: {type(data)}\")\n",
    "                max_length = max(max_length, data.shape[1])\n",
    "                label = 0 if 'lie' in file_name.lower() else 1\n",
    "                X.append(data)\n",
    "                y.append(label)\n",
    "                if label == 0:\n",
    "                    lie_count += 1\n",
    "                else:\n",
    "                    truth_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading Poly file {file_name}: {str(e)}\")\n",
    "    print(f\"Loaded from Poly {data_dir}: {lie_count} lie samples, {truth_count} truth samples\")\n",
    "    \n",
    "    # Pad all poly samples to the maximum length\n",
    "    X_padded = np.array([pad_sequence(x, max_length) for x in X])\n",
    "    return X_padded, np.array(y)\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, eeg_X, eeg_y, poly_X, poly_y, file_sample_counts):\n",
    "        self.eeg_X = torch.tensor(eeg_X, dtype=torch.float32)\n",
    "        self.eeg_y = torch.tensor(eeg_y, dtype=torch.long)\n",
    "        self.poly_X = torch.tensor(poly_X, dtype=torch.float32)\n",
    "        self.poly_y = torch.tensor(poly_y, dtype=torch.long)\n",
    "        \n",
    "        # Create a mapping from EEG sample index to Poly file index\n",
    "        self.eeg_to_poly_map = []\n",
    "        poly_index = 0\n",
    "        for count in file_sample_counts:\n",
    "            self.eeg_to_poly_map.extend([poly_index] * count)\n",
    "            poly_index += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eeg_X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg_sample = self.eeg_X[idx]\n",
    "        eeg_label = self.eeg_y[idx]\n",
    "        poly_idx = self.eeg_to_poly_map[idx]\n",
    "        poly_sample = self.poly_X[poly_idx]\n",
    "        poly_label = self.poly_y[poly_idx]\n",
    "        \n",
    "        return eeg_sample, eeg_label, poly_sample, poly_label\n",
    "\n",
    "def create_file_based_splits(file_sample_counts, n_splits=5):\n",
    "    file_indices = np.arange(len(file_sample_counts))\n",
    "    group_kfold = GroupKFold(n_splits=n_splits)\n",
    "    return list(group_kfold.split(X=file_indices, groups=file_indices))\n",
    "\n",
    "# Load data\n",
    "print(\"Loading EEG data...\")\n",
    "eeg_X, eeg_y, file_sample_counts = load_eeg_data(EEG_DATA_DIR)\n",
    "print(\"Loading Poly data...\")\n",
    "poly_X, poly_y = load_poly_data(POLY_DATA_DIR)\n",
    "\n",
    "# Check for class imbalance\n",
    "unique, counts = np.unique(eeg_y, return_counts=True)\n",
    "print(\"EEG Class distribution:\", dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(poly_y, return_counts=True)\n",
    "print(\"Poly Class distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "# Print dataset size and shapes\n",
    "print(\"EEG data shape:\", eeg_X.shape)\n",
    "print(\"Poly data shape:\", poly_X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807dc975-266c-4193-ac4b-3c69be28d126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG data...\n",
      "EEG File: augmented_lie_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_10.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_11.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_12.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_13.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_14.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_15.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_16.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_17.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_19.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_2.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_20.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_21.pkl, Shape: (17, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_22.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_23.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_24.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_25.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_26.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_27.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_28.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_29.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_3.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_30.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_31.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_33.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_34.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_4.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_5.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_6.pkl, Shape: (26, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_7.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_8.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_9.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_10.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_11.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_12.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_13.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_14.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_15.pkl, Shape: (4, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_16.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_17.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_19.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_2.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_20.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_21.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_22.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_23.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_24.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_25.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_26.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_27.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_28.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_29.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_3.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_30.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_31.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_33.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_34.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_36.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_37.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_38.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_39.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_4.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_40.pkl, Shape: (30, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_41.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_42.pkl, Shape: (18, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_43.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_44.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_45.pkl, Shape: (14, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_46.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_47.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_48.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_49.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_5.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_50.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_51.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_52.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_53.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_54.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_55.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_6.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_7.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_8.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_9.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "Loaded from EEG C:\\Users\\User\\Documents\\Lie detect data\\AugmentedEEGData: 333 lie samples, 602 truth samples\n",
      "Loading Poly data...\n",
      "Poly File: poly_lie_1.pkl, Shape: (4, 2963), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_10.pkl, Shape: (4, 3171), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_11.pkl, Shape: (4, 2917), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_12.pkl, Shape: (4, 2991), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_13.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_14.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_15.pkl, Shape: (4, 2929), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_16.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_17.pkl, Shape: (4, 3234), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_18.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_19.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_2.pkl, Shape: (4, 2895), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_20.pkl, Shape: (4, 3291), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_21.pkl, Shape: (4, 3658), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_22.pkl, Shape: (4, 3375), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_23.pkl, Shape: (4, 3334), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_24.pkl, Shape: (4, 3263), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_25.pkl, Shape: (4, 3292), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_26.pkl, Shape: (4, 3246), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_27.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_28.pkl, Shape: (4, 3262), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_29.pkl, Shape: (4, 3321), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_3.pkl, Shape: (4, 2941), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_30.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_31.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_32.pkl, Shape: (4, 3142), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_33.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_34.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_35.pkl, Shape: (4, 3179), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_4.pkl, Shape: (4, 2967), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_5.pkl, Shape: (4, 2913), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_6.pkl, Shape: (4, 4229), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_7.pkl, Shape: (4, 3129), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_8.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_9.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_1.pkl, Shape: (4, 2958), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_10.pkl, Shape: (4, 3104), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_11.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_12.pkl, Shape: (4, 3391), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_13.pkl, Shape: (4, 3141), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_14.pkl, Shape: (4, 3271), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_15.pkl, Shape: (4, 2859), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_16.pkl, Shape: (4, 3325), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_17.pkl, Shape: (4, 3383), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_18.pkl, Shape: (4, 3233), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_19.pkl, Shape: (4, 3366), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_2.pkl, Shape: (4, 3112), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_20.pkl, Shape: (4, 3313), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_21.pkl, Shape: (4, 3555), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_22.pkl, Shape: (4, 3346), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_23.pkl, Shape: (4, 3305), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_24.pkl, Shape: (4, 3200), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_25.pkl, Shape: (4, 3213), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_26.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_27.pkl, Shape: (4, 3188), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_28.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_29.pkl, Shape: (4, 3242), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_3.pkl, Shape: (4, 3016), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_30.pkl, Shape: (4, 3258), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_31.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_32.pkl, Shape: (4, 3175), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_33.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_34.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_35.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_36.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_37.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_38.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_39.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_4.pkl, Shape: (4, 3058), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_40.pkl, Shape: (4, 4475), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_41.pkl, Shape: (4, 3162), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_42.pkl, Shape: (4, 3704), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_43.pkl, Shape: (4, 3333), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_44.pkl, Shape: (4, 3396), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_45.pkl, Shape: (4, 3450), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_46.pkl, Shape: (4, 3537), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_47.pkl, Shape: (4, 3363), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_48.pkl, Shape: (4, 3250), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_49.pkl, Shape: (4, 3279), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_5.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_50.pkl, Shape: (4, 3508), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_51.pkl, Shape: (4, 3358), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_52.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_53.pkl, Shape: (4, 3379), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_54.pkl, Shape: (4, 3558), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_55.pkl, Shape: (4, 3392), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_6.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_7.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_8.pkl, Shape: (4, 3096), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_9.pkl, Shape: (4, 3225), Type: <class 'numpy.ndarray'>\n",
      "Loaded from Poly C:\\Users\\User\\Documents\\Lie detect data\\CombinedPolyData: 35 lie samples, 55 truth samples\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Epoch 1/50, Loss: 0.47679947316646576\n",
      "Validation Loss: 0.6211811304092407, Validation Accuracy: 0.574585635359116\n",
      "Precision: 0.678082191780822, Recall: 0.7674418604651163, F1-score: 0.72\n",
      "Model saved to ensemble_model_fold_0.pth\n",
      "Epoch 2/50, Loss: 0.280049204826355\n",
      "Validation Loss: 0.7531237602233887, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.75, Recall: 0.7674418604651163, F1-score: 0.7586206896551724\n",
      "Epoch 3/50, Loss: 0.21135875582695007\n",
      "Validation Loss: 0.916774183511734, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.7578125, Recall: 0.751937984496124, F1-score: 0.754863813229572\n",
      "Epoch 4/50, Loss: 0.1749643087387085\n",
      "Validation Loss: 1.0470775365829468, Validation Accuracy: 0.6629834254143646\n",
      "Precision: 0.765625, Recall: 0.7596899224806202, F1-score: 0.7626459143968871\n",
      "Epoch 5/50, Loss: 0.14852174744009972\n",
      "Validation Loss: 1.2008742094039917, Validation Accuracy: 0.6906077348066298\n",
      "Precision: 0.8173913043478261, Recall: 0.7286821705426356, F1-score: 0.7704918032786885\n",
      "Epoch 6/50, Loss: 0.127019169429938\n",
      "Validation Loss: 1.291835904121399, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8378378378378378, Recall: 0.7209302325581395, F1-score: 0.775\n",
      "Epoch 7/50, Loss: 0.11265224466721217\n",
      "Validation Loss: 1.3461026549339294, Validation Accuracy: 0.6906077348066298\n",
      "Precision: 0.8348623853211009, Recall: 0.7054263565891473, F1-score: 0.7647058823529411\n",
      "Epoch 8/50, Loss: 0.10171664009491603\n",
      "Validation Loss: 1.483969807624817, Validation Accuracy: 0.6906077348066298\n",
      "Precision: 0.8348623853211009, Recall: 0.7054263565891473, F1-score: 0.7647058823529411\n",
      "Epoch 9/50, Loss: 0.09257503598928452\n",
      "Validation Loss: 1.5780552625656128, Validation Accuracy: 0.6850828729281768\n",
      "Precision: 0.8333333333333334, Recall: 0.6976744186046512, F1-score: 0.759493670886076\n",
      "Epoch 10/50, Loss: 0.08423192799091339\n",
      "Validation Loss: 1.5698710083961487, Validation Accuracy: 0.6850828729281768\n",
      "Precision: 0.8333333333333334, Recall: 0.6976744186046512, F1-score: 0.759493670886076\n",
      "Epoch 11/50, Loss: 0.07544725015759468\n",
      "Validation Loss: 1.608048915863037, Validation Accuracy: 0.6850828729281768\n",
      "Precision: 0.8333333333333334, Recall: 0.6976744186046512, F1-score: 0.759493670886076\n",
      "Epoch 12/50, Loss: 0.06806425129373868\n",
      "Validation Loss: 1.6698704361915588, Validation Accuracy: 0.6850828729281768\n",
      "Precision: 0.8333333333333334, Recall: 0.6976744186046512, F1-score: 0.759493670886076\n",
      "Epoch 13/50, Loss: 0.06450730934739113\n",
      "Validation Loss: 1.7011525630950928, Validation Accuracy: 0.6850828729281768\n",
      "Precision: 0.8333333333333334, Recall: 0.6976744186046512, F1-score: 0.759493670886076\n",
      "Epoch 14/50, Loss: 0.05865222277740637\n",
      "Validation Loss: 1.7479350566864014, Validation Accuracy: 0.6850828729281768\n",
      "Precision: 0.8333333333333334, Recall: 0.6976744186046512, F1-score: 0.759493670886076\n",
      "Epoch 15/50, Loss: 0.055375286688407264\n",
      "Validation Loss: 1.8163996934890747, Validation Accuracy: 0.6850828729281768\n",
      "Precision: 0.8333333333333334, Recall: 0.6976744186046512, F1-score: 0.759493670886076\n",
      "Epoch 16/50, Loss: 0.05225205856064955\n",
      "Validation Loss: 1.8110401034355164, Validation Accuracy: 0.6906077348066298\n",
      "Precision: 0.8348623853211009, Recall: 0.7054263565891473, F1-score: 0.7647058823529411\n",
      "Epoch 17/50, Loss: 0.05022055438409249\n",
      "Validation Loss: 1.8381054401397705, Validation Accuracy: 0.6906077348066298\n",
      "Precision: 0.8348623853211009, Recall: 0.7054263565891473, F1-score: 0.7647058823529411\n",
      "Epoch 18/50, Loss: 0.04591473160932461\n",
      "Validation Loss: 1.8249133825302124, Validation Accuracy: 0.6961325966850829\n",
      "Precision: 0.8363636363636363, Recall: 0.7131782945736435, F1-score: 0.7698744769874477\n",
      "Epoch 19/50, Loss: 0.04385462527473768\n",
      "Validation Loss: 1.8563342690467834, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8378378378378378, Recall: 0.7209302325581395, F1-score: 0.775\n",
      "Epoch 20/50, Loss: 0.041771228735645614\n",
      "Validation Loss: 1.9165090918540955, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8378378378378378, Recall: 0.7209302325581395, F1-score: 0.775\n",
      "Epoch 21/50, Loss: 0.04128455929458141\n",
      "Validation Loss: 1.9266322255134583, Validation Accuracy: 0.7237569060773481\n",
      "Precision: 0.8434782608695652, Recall: 0.751937984496124, F1-score: 0.7950819672131147\n",
      "Epoch 22/50, Loss: 0.03827144857496023\n",
      "Validation Loss: 1.9239346385002136, Validation Accuracy: 0.7292817679558011\n",
      "Precision: 0.8448275862068966, Recall: 0.7596899224806202, F1-score: 0.8\n",
      "Epoch 23/50, Loss: 0.035754584396878876\n",
      "Validation Loss: 1.9322646260261536, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 24/50, Loss: 0.03367124435802301\n",
      "Validation Loss: 1.9688205122947693, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 25/50, Loss: 0.032562448643147945\n",
      "Validation Loss: 1.9914222359657288, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 26/50, Loss: 0.03205716020117203\n",
      "Validation Loss: 2.0275213718414307, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 27/50, Loss: 0.029880424961447716\n",
      "Validation Loss: 2.0303447246551514, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 28/50, Loss: 0.02920555571715037\n",
      "Validation Loss: 2.0845065116882324, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 29/50, Loss: 0.02739846023420493\n",
      "Validation Loss: 2.1209404468536377, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 30/50, Loss: 0.02653492319708069\n",
      "Validation Loss: 2.1237303614616394, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 31/50, Loss: 0.024836095981299877\n",
      "Validation Loss: 2.1855940222740173, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 32/50, Loss: 0.024363372707739472\n",
      "Validation Loss: 2.2266976833343506, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 33/50, Loss: 0.023764049168676138\n",
      "Validation Loss: 2.2396804690361023, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 34/50, Loss: 0.02188374164203803\n",
      "Validation Loss: 2.218733787536621, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 35/50, Loss: 0.021141053022195894\n",
      "Validation Loss: 2.24464750289917, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 36/50, Loss: 0.02141814383988579\n",
      "Validation Loss: 2.2855220437049866, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 37/50, Loss: 0.02027854012946288\n",
      "Validation Loss: 2.3240469098091125, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 38/50, Loss: 0.01848398878549536\n",
      "Validation Loss: 2.3425360918045044, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 39/50, Loss: 0.01901943391809861\n",
      "Validation Loss: 2.387671947479248, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 40/50, Loss: 0.018266610025117796\n",
      "Validation Loss: 2.382110357284546, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 41/50, Loss: 0.017535261965046327\n",
      "Validation Loss: 2.381419062614441, Validation Accuracy: 0.7292817679558011\n",
      "Precision: 0.8389830508474576, Recall: 0.7674418604651163, F1-score: 0.8016194331983806\n",
      "Epoch 42/50, Loss: 0.01684025814756751\n",
      "Validation Loss: 2.421773076057434, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 43/50, Loss: 0.016073967330157757\n",
      "Validation Loss: 2.4626224040985107, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 44/50, Loss: 0.015980463785429794\n",
      "Validation Loss: 2.473928689956665, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 45/50, Loss: 0.01561095534513394\n",
      "Validation Loss: 2.454410672187805, Validation Accuracy: 0.7292817679558011\n",
      "Precision: 0.8389830508474576, Recall: 0.7674418604651163, F1-score: 0.8016194331983806\n",
      "Epoch 46/50, Loss: 0.015020005560169617\n",
      "Validation Loss: 2.4700194597244263, Validation Accuracy: 0.7292817679558011\n",
      "Precision: 0.8389830508474576, Recall: 0.7674418604651163, F1-score: 0.8016194331983806\n",
      "Epoch 47/50, Loss: 0.013945959353198608\n",
      "Validation Loss: 2.5338765382766724, Validation Accuracy: 0.7292817679558011\n",
      "Precision: 0.8389830508474576, Recall: 0.7674418604651163, F1-score: 0.8016194331983806\n",
      "Epoch 48/50, Loss: 0.013828450037787357\n",
      "Validation Loss: 2.5994482040405273, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 49/50, Loss: 0.013099837970609466\n",
      "Validation Loss: 2.577971935272217, Validation Accuracy: 0.7292817679558011\n",
      "Precision: 0.8389830508474576, Recall: 0.7674418604651163, F1-score: 0.8016194331983806\n",
      "Epoch 50/50, Loss: 0.013243218185380101\n",
      "Validation Loss: 2.5723079442977905, Validation Accuracy: 0.7292817679558011\n",
      "Precision: 0.8389830508474576, Recall: 0.7674418604651163, F1-score: 0.8016194331983806\n",
      "Validation Loss: 0.6211811304092407, Validation Accuracy: 0.574585635359116\n",
      "Precision: 0.678082191780822, Recall: 0.7674418604651163, F1-score: 0.72\n",
      "Confusion Matrix:\n",
      "[[ 5 47]\n",
      " [30 99]]\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch 1/50, Loss: 0.44574475785096485\n",
      "Validation Loss: 0.5668278336524963, Validation Accuracy: 0.6457142857142857\n",
      "Precision: 0.6530612244897959, Recall: 0.897196261682243, F1-score: 0.7559055118110236\n",
      "Model saved to ensemble_model_fold_1.pth\n",
      "Epoch 2/50, Loss: 0.23826241741577783\n",
      "Validation Loss: 0.556314691901207, Validation Accuracy: 0.8228571428571428\n",
      "Precision: 0.8333333333333334, Recall: 0.8878504672897196, F1-score: 0.8597285067873304\n",
      "Model saved to ensemble_model_fold_1.pth\n",
      "Epoch 3/50, Loss: 0.17472799867391586\n",
      "Validation Loss: 0.5626063942909241, Validation Accuracy: 0.76\n",
      "Precision: 0.7642276422764228, Recall: 0.8785046728971962, F1-score: 0.8173913043478261\n",
      "Epoch 4/50, Loss: 0.13572586327791214\n",
      "Validation Loss: 0.5825132131576538, Validation Accuracy: 0.8228571428571428\n",
      "Precision: 0.8392857142857143, Recall: 0.8785046728971962, F1-score: 0.8584474885844748\n",
      "Epoch 5/50, Loss: 0.10512724022070567\n",
      "Validation Loss: 0.6489741653203964, Validation Accuracy: 0.8514285714285714\n",
      "Precision: 0.8785046728971962, Recall: 0.8785046728971962, F1-score: 0.8785046728971962\n",
      "Epoch 6/50, Loss: 0.08591759701569875\n",
      "Validation Loss: 0.7093050181865692, Validation Accuracy: 0.8114285714285714\n",
      "Precision: 0.8303571428571429, Recall: 0.8691588785046729, F1-score: 0.8493150684931506\n",
      "Epoch 7/50, Loss: 0.0733587338278691\n",
      "Validation Loss: 0.7684353142976761, Validation Accuracy: 0.8057142857142857\n",
      "Precision: 0.8288288288288288, Recall: 0.8598130841121495, F1-score: 0.8440366972477065\n",
      "Epoch 8/50, Loss: 0.0620512409756581\n",
      "Validation Loss: 0.8169273287057877, Validation Accuracy: 0.8114285714285714\n",
      "Precision: 0.8425925925925926, Recall: 0.8504672897196262, F1-score: 0.8465116279069768\n",
      "Epoch 9/50, Loss: 0.05585187176863352\n",
      "Validation Loss: 0.8454545736312866, Validation Accuracy: 0.8342857142857143\n",
      "Precision: 0.875, Recall: 0.8504672897196262, F1-score: 0.8625592417061612\n",
      "Epoch 10/50, Loss: 0.049637939470509686\n",
      "Validation Loss: 0.876105546951294, Validation Accuracy: 0.8342857142857143\n",
      "Precision: 0.875, Recall: 0.8504672897196262, F1-score: 0.8625592417061612\n",
      "Epoch 11/50, Loss: 0.04443602574368318\n",
      "Validation Loss: 0.8947317600250244, Validation Accuracy: 0.8285714285714286\n",
      "Precision: 0.8666666666666667, Recall: 0.8504672897196262, F1-score: 0.8584905660377359\n",
      "Epoch 12/50, Loss: 0.042985291530688606\n",
      "Validation Loss: 0.9032001197338104, Validation Accuracy: 0.8171428571428572\n",
      "Precision: 0.8504672897196262, Recall: 0.8504672897196262, F1-score: 0.8504672897196262\n",
      "Epoch 13/50, Loss: 0.038823167172571026\n",
      "Validation Loss: 0.9127020090818405, Validation Accuracy: 0.7885714285714286\n",
      "Precision: 0.8125, Recall: 0.8504672897196262, F1-score: 0.8310502283105022\n",
      "Epoch 14/50, Loss: 0.03710252232849598\n",
      "Validation Loss: 0.929028183221817, Validation Accuracy: 0.8057142857142857\n",
      "Precision: 0.8411214953271028, Recall: 0.8411214953271028, F1-score: 0.8411214953271028\n",
      "Epoch 15/50, Loss: 0.03425580014785131\n",
      "Validation Loss: 0.9466491937637329, Validation Accuracy: 0.8114285714285714\n",
      "Precision: 0.8490566037735849, Recall: 0.8411214953271028, F1-score: 0.8450704225352113\n",
      "Epoch 16/50, Loss: 0.03253755904734135\n",
      "Validation Loss: 0.9674260467290878, Validation Accuracy: 0.8\n",
      "Precision: 0.8333333333333334, Recall: 0.8411214953271028, F1-score: 0.8372093023255814\n",
      "Epoch 17/50, Loss: 0.029737429382900398\n",
      "Validation Loss: 0.9837800115346909, Validation Accuracy: 0.8\n",
      "Precision: 0.8333333333333334, Recall: 0.8411214953271028, F1-score: 0.8372093023255814\n",
      "Epoch 18/50, Loss: 0.027830743230879307\n",
      "Validation Loss: 1.0002273917198181, Validation Accuracy: 0.8\n",
      "Precision: 0.8333333333333334, Recall: 0.8411214953271028, F1-score: 0.8372093023255814\n",
      "Epoch 19/50, Loss: 0.02683334642400344\n",
      "Validation Loss: 1.0205165892839432, Validation Accuracy: 0.7885714285714286\n",
      "Precision: 0.8181818181818182, Recall: 0.8411214953271028, F1-score: 0.8294930875576036\n",
      "Epoch 20/50, Loss: 0.02486943919211626\n",
      "Validation Loss: 1.046285703778267, Validation Accuracy: 0.7885714285714286\n",
      "Precision: 0.8181818181818182, Recall: 0.8411214953271028, F1-score: 0.8294930875576036\n",
      "Epoch 21/50, Loss: 0.023789026774466038\n",
      "Validation Loss: 1.063756912946701, Validation Accuracy: 0.7771428571428571\n",
      "Precision: 0.8035714285714286, Recall: 0.8411214953271028, F1-score: 0.821917808219178\n",
      "Epoch 22/50, Loss: 0.02234468950579564\n",
      "Validation Loss: 1.0805903673171997, Validation Accuracy: 0.7771428571428571\n",
      "Precision: 0.8035714285714286, Recall: 0.8411214953271028, F1-score: 0.821917808219178\n",
      "Epoch 23/50, Loss: 0.02190438409646352\n",
      "Validation Loss: 1.094981923699379, Validation Accuracy: 0.7885714285714286\n",
      "Precision: 0.8181818181818182, Recall: 0.8411214953271028, F1-score: 0.8294930875576036\n",
      "Epoch 24/50, Loss: 0.020480919474114973\n",
      "Validation Loss: 1.1154735088348389, Validation Accuracy: 0.7714285714285715\n",
      "Precision: 0.7964601769911505, Recall: 0.8411214953271028, F1-score: 0.8181818181818182\n",
      "Epoch 25/50, Loss: 0.019480890749643247\n",
      "Validation Loss: 1.1239304095506668, Validation Accuracy: 0.7714285714285715\n",
      "Precision: 0.7964601769911505, Recall: 0.8411214953271028, F1-score: 0.8181818181818182\n",
      "Epoch 26/50, Loss: 0.018196215853095055\n",
      "Validation Loss: 1.1392558813095093, Validation Accuracy: 0.7828571428571428\n",
      "Precision: 0.8108108108108109, Recall: 0.8411214953271028, F1-score: 0.8256880733944955\n",
      "Epoch 27/50, Loss: 0.01784039878596862\n",
      "Validation Loss: 1.155163735151291, Validation Accuracy: 0.76\n",
      "Precision: 0.782608695652174, Recall: 0.8411214953271028, F1-score: 0.8108108108108109\n",
      "Epoch 28/50, Loss: 0.017125137072677415\n",
      "Validation Loss: 1.1652860939502716, Validation Accuracy: 0.76\n",
      "Precision: 0.782608695652174, Recall: 0.8411214953271028, F1-score: 0.8108108108108109\n",
      "Epoch 29/50, Loss: 0.016060559234271448\n",
      "Validation Loss: 1.1853783130645752, Validation Accuracy: 0.7542857142857143\n",
      "Precision: 0.7758620689655172, Recall: 0.8411214953271028, F1-score: 0.8071748878923767\n",
      "Epoch 30/50, Loss: 0.015515609489132961\n",
      "Validation Loss: 1.196483626961708, Validation Accuracy: 0.7714285714285715\n",
      "Precision: 0.7964601769911505, Recall: 0.8411214953271028, F1-score: 0.8181818181818182\n",
      "Epoch 31/50, Loss: 0.015218501134465138\n",
      "Validation Loss: 1.2261767983436584, Validation Accuracy: 0.7542857142857143\n",
      "Precision: 0.7758620689655172, Recall: 0.8411214953271028, F1-score: 0.8071748878923767\n",
      "Epoch 32/50, Loss: 0.014368017902597785\n",
      "Validation Loss: 1.2484275996685028, Validation Accuracy: 0.7542857142857143\n",
      "Precision: 0.7807017543859649, Recall: 0.8317757009345794, F1-score: 0.8054298642533937\n",
      "Epoch 33/50, Loss: 0.013167022727429867\n",
      "Validation Loss: 1.2711834907531738, Validation Accuracy: 0.7542857142857143\n",
      "Precision: 0.7758620689655172, Recall: 0.8411214953271028, F1-score: 0.8071748878923767\n",
      "Epoch 34/50, Loss: 0.012999592038492361\n",
      "Validation Loss: 1.2946977615356445, Validation Accuracy: 0.7542857142857143\n",
      "Precision: 0.7758620689655172, Recall: 0.8411214953271028, F1-score: 0.8071748878923767\n",
      "Epoch 35/50, Loss: 0.012995970590660969\n",
      "Validation Loss: 1.3059082925319672, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 36/50, Loss: 0.012175170704722404\n",
      "Validation Loss: 1.3276126384735107, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 37/50, Loss: 0.01140979421325028\n",
      "Validation Loss: 1.3408806025981903, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 38/50, Loss: 0.010607830326383313\n",
      "Validation Loss: 1.3554438054561615, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 39/50, Loss: 0.010374441432456175\n",
      "Validation Loss: 1.3737651109695435, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 40/50, Loss: 0.010295750185226401\n",
      "Validation Loss: 1.3939715027809143, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 41/50, Loss: 0.009578546431536475\n",
      "Validation Loss: 1.409020721912384, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 42/50, Loss: 0.009076693405707678\n",
      "Validation Loss: 1.4249857664108276, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 43/50, Loss: 0.008633624451855818\n",
      "Validation Loss: 1.441760629415512, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 44/50, Loss: 0.008728293857226769\n",
      "Validation Loss: 1.451989233493805, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 45/50, Loss: 0.008355824742466211\n",
      "Validation Loss: 1.4667602181434631, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 46/50, Loss: 0.007963288885851702\n",
      "Validation Loss: 1.4910300970077515, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 47/50, Loss: 0.007785396728043755\n",
      "Validation Loss: 1.50795578956604, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 48/50, Loss: 0.007455523281047742\n",
      "Validation Loss: 1.5261386036872864, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 49/50, Loss: 0.007414394756779075\n",
      "Validation Loss: 1.5369570553302765, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Epoch 50/50, Loss: 0.00687173439655453\n",
      "Validation Loss: 1.552680343389511, Validation Accuracy: 0.7485714285714286\n",
      "Precision: 0.7739130434782608, Recall: 0.8317757009345794, F1-score: 0.8018018018018018\n",
      "Validation Loss: 0.556314691901207, Validation Accuracy: 0.8228571428571428\n",
      "Precision: 0.8333333333333334, Recall: 0.8878504672897196, F1-score: 0.8597285067873304\n",
      "Confusion Matrix:\n",
      "[[49 19]\n",
      " [12 95]]\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch 1/50, Loss: 0.3946918820341428\n",
      "Validation Loss: 0.5506575554609299, Validation Accuracy: 0.6720430107526881\n",
      "Precision: 0.7848101265822784, Recall: 0.5849056603773585, F1-score: 0.6702702702702703\n",
      "Model saved to ensemble_model_fold_2.pth\n",
      "Epoch 2/50, Loss: 0.19168221950531006\n",
      "Validation Loss: 0.5359441041946411, Validation Accuracy: 0.6559139784946236\n",
      "Precision: 0.7441860465116279, Recall: 0.6037735849056604, F1-score: 0.6666666666666666\n",
      "Model saved to ensemble_model_fold_2.pth\n",
      "Epoch 3/50, Loss: 0.10763716821869214\n",
      "Validation Loss: 0.5773351192474365, Validation Accuracy: 0.6720430107526881\n",
      "Precision: 0.7419354838709677, Recall: 0.6509433962264151, F1-score: 0.6934673366834171\n",
      "Epoch 4/50, Loss: 0.07212030949691932\n",
      "Validation Loss: 0.6716761142015457, Validation Accuracy: 0.6505376344086021\n",
      "Precision: 0.7157894736842105, Recall: 0.6415094339622641, F1-score: 0.6766169154228856\n",
      "Epoch 5/50, Loss: 0.05047414576013883\n",
      "Validation Loss: 0.7716560363769531, Validation Accuracy: 0.6290322580645161\n",
      "Precision: 0.6907216494845361, Recall: 0.6320754716981132, F1-score: 0.6600985221674877\n",
      "Epoch 6/50, Loss: 0.04121118442465862\n",
      "Validation Loss: 0.845361977815628, Validation Accuracy: 0.6397849462365591\n",
      "Precision: 0.696969696969697, Recall: 0.6509433962264151, F1-score: 0.6731707317073171\n",
      "Epoch 7/50, Loss: 0.034837222347656883\n",
      "Validation Loss: 0.9043374210596085, Validation Accuracy: 0.6559139784946236\n",
      "Precision: 0.7019230769230769, Recall: 0.6886792452830188, F1-score: 0.6952380952380952\n",
      "Epoch 8/50, Loss: 0.03212228169043859\n",
      "Validation Loss: 0.9593680649995804, Validation Accuracy: 0.6720430107526881\n",
      "Precision: 0.7102803738317757, Recall: 0.7169811320754716, F1-score: 0.7136150234741784\n",
      "Epoch 9/50, Loss: 0.02842309543242057\n",
      "Validation Loss: 1.0114163756370544, Validation Accuracy: 0.6666666666666666\n",
      "Precision: 0.7075471698113207, Recall: 0.7075471698113207, F1-score: 0.7075471698113207\n",
      "Epoch 10/50, Loss: 0.025254202851404745\n",
      "Validation Loss: 1.062422975897789, Validation Accuracy: 0.6666666666666666\n",
      "Precision: 0.7075471698113207, Recall: 0.7075471698113207, F1-score: 0.7075471698113207\n",
      "Epoch 11/50, Loss: 0.02414633271594842\n",
      "Validation Loss: 1.10444837808609, Validation Accuracy: 0.6666666666666666\n",
      "Precision: 0.7075471698113207, Recall: 0.7075471698113207, F1-score: 0.7075471698113207\n",
      "Epoch 12/50, Loss: 0.023735205953319866\n",
      "Validation Loss: 1.1445020586252213, Validation Accuracy: 0.6666666666666666\n",
      "Precision: 0.7115384615384616, Recall: 0.6981132075471698, F1-score: 0.7047619047619048\n",
      "Epoch 13/50, Loss: 0.021489545082052548\n",
      "Validation Loss: 1.177956998348236, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.719626168224299, Recall: 0.7264150943396226, F1-score: 0.7230046948356808\n",
      "Epoch 14/50, Loss: 0.019843639029810827\n",
      "Validation Loss: 1.209995836019516, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.719626168224299, Recall: 0.7264150943396226, F1-score: 0.7230046948356808\n",
      "Epoch 15/50, Loss: 0.018953959768017132\n",
      "Validation Loss: 1.2473081946372986, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.719626168224299, Recall: 0.7264150943396226, F1-score: 0.7230046948356808\n",
      "Epoch 16/50, Loss: 0.018185229351123173\n",
      "Validation Loss: 1.2798859924077988, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.719626168224299, Recall: 0.7264150943396226, F1-score: 0.7230046948356808\n",
      "Epoch 17/50, Loss: 0.017055940969536703\n",
      "Validation Loss: 1.314062163233757, Validation Accuracy: 0.6774193548387096\n",
      "Precision: 0.7169811320754716, Recall: 0.7169811320754716, F1-score: 0.7169811320754716\n",
      "Epoch 18/50, Loss: 0.01691098449130853\n",
      "Validation Loss: 1.347961664199829, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.719626168224299, Recall: 0.7264150943396226, F1-score: 0.7230046948356808\n",
      "Epoch 19/50, Loss: 0.01651557721197605\n",
      "Validation Loss: 1.3798369616270065, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 20/50, Loss: 0.014266803783054153\n",
      "Validation Loss: 1.416782021522522, Validation Accuracy: 0.6774193548387096\n",
      "Precision: 0.7169811320754716, Recall: 0.7169811320754716, F1-score: 0.7169811320754716\n",
      "Epoch 21/50, Loss: 0.013792248209938407\n",
      "Validation Loss: 1.4503147602081299, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 22/50, Loss: 0.013072866946458817\n",
      "Validation Loss: 1.479721114039421, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 23/50, Loss: 0.012631407706066966\n",
      "Validation Loss: 1.5155062973499298, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 24/50, Loss: 0.01201373889731864\n",
      "Validation Loss: 1.54039666056633, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 25/50, Loss: 0.011112998317306241\n",
      "Validation Loss: 1.5677439868450165, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 26/50, Loss: 0.010714042310913404\n",
      "Validation Loss: 1.5983450710773468, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 27/50, Loss: 0.010222216990465919\n",
      "Validation Loss: 1.6301524639129639, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 28/50, Loss: 0.009634872355187932\n",
      "Validation Loss: 1.653733640909195, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 29/50, Loss: 0.009785450218866268\n",
      "Validation Loss: 1.6744020134210587, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 30/50, Loss: 0.008848672344659766\n",
      "Validation Loss: 1.6987451761960983, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 31/50, Loss: 0.008406192219505707\n",
      "Validation Loss: 1.7208570688962936, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 32/50, Loss: 0.008252275525592268\n",
      "Validation Loss: 1.7455858886241913, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 33/50, Loss: 0.007670721660057704\n",
      "Validation Loss: 1.7739247232675552, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 34/50, Loss: 0.007729403170136114\n",
      "Validation Loss: 1.7976116687059402, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 35/50, Loss: 0.007311374647542834\n",
      "Validation Loss: 1.8245431631803513, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 36/50, Loss: 0.007130870362743735\n",
      "Validation Loss: 1.8456800282001495, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 37/50, Loss: 0.006869491500159104\n",
      "Validation Loss: 1.8647594153881073, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 38/50, Loss: 0.00660059810616076\n",
      "Validation Loss: 1.88619863986969, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 39/50, Loss: 0.0062956123147159815\n",
      "Validation Loss: 1.905364379286766, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 40/50, Loss: 0.006224151235073805\n",
      "Validation Loss: 1.9210190773010254, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 41/50, Loss: 0.005628195824101567\n",
      "Validation Loss: 1.9433275610208511, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 42/50, Loss: 0.0053723394715537625\n",
      "Validation Loss: 1.967989832162857, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 43/50, Loss: 0.005465806229040027\n",
      "Validation Loss: 1.9893590807914734, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 44/50, Loss: 0.005344213296969731\n",
      "Validation Loss: 2.005222827196121, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 45/50, Loss: 0.0046107179174820585\n",
      "Validation Loss: 2.0174560546875, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 46/50, Loss: 0.004760396744435032\n",
      "Validation Loss: 2.0412533581256866, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 47/50, Loss: 0.004513595156216373\n",
      "Validation Loss: 2.0488838851451874, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 48/50, Loss: 0.004587180990104874\n",
      "Validation Loss: 2.0713284015655518, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 49/50, Loss: 0.004330962120244901\n",
      "Validation Loss: 2.089249223470688, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 50/50, Loss: 0.004051127315809329\n",
      "Validation Loss: 2.1092985570430756, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Validation Loss: 0.5359441041946411, Validation Accuracy: 0.6559139784946236\n",
      "Precision: 0.7441860465116279, Recall: 0.6037735849056604, F1-score: 0.6666666666666666\n",
      "Confusion Matrix:\n",
      "[[58 22]\n",
      " [42 64]]\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch 1/50, Loss: 0.5166085958480835\n",
      "Validation Loss: 0.7489482164382935, Validation Accuracy: 0.5380710659898477\n",
      "Precision: 1.0, Recall: 0.3724137931034483, F1-score: 0.542713567839196\n",
      "Model saved to ensemble_model_fold_3.pth\n",
      "Epoch 2/50, Loss: 0.26878654956817627\n",
      "Validation Loss: 0.845306783914566, Validation Accuracy: 0.6243654822335025\n",
      "Precision: 1.0, Recall: 0.4896551724137931, F1-score: 0.6574074074074074\n",
      "Epoch 3/50, Loss: 0.18703030546506247\n",
      "Validation Loss: 0.8961230516433716, Validation Accuracy: 0.6852791878172588\n",
      "Precision: 1.0, Recall: 0.5724137931034483, F1-score: 0.7280701754385965\n",
      "Epoch 4/50, Loss: 0.13722227265437445\n",
      "Validation Loss: 0.9243360757827759, Validation Accuracy: 0.700507614213198\n",
      "Precision: 0.9886363636363636, Recall: 0.6, F1-score: 0.7467811158798283\n",
      "Epoch 5/50, Loss: 0.10464016969005267\n",
      "Validation Loss: 0.9517889320850372, Validation Accuracy: 0.7157360406091371\n",
      "Precision: 0.978494623655914, Recall: 0.6275862068965518, F1-score: 0.7647058823529411\n",
      "Epoch 6/50, Loss: 0.08171527584393819\n",
      "Validation Loss: 0.9835313409566879, Validation Accuracy: 0.7157360406091371\n",
      "Precision: 0.978494623655914, Recall: 0.6275862068965518, F1-score: 0.7647058823529411\n",
      "Epoch 7/50, Loss: 0.06694855044285457\n",
      "Validation Loss: 0.9875021129846573, Validation Accuracy: 0.7208121827411168\n",
      "Precision: 0.9787234042553191, Recall: 0.6344827586206897, F1-score: 0.7698744769874477\n",
      "Epoch 8/50, Loss: 0.05757083867986997\n",
      "Validation Loss: 0.9681788384914398, Validation Accuracy: 0.7208121827411168\n",
      "Precision: 0.9787234042553191, Recall: 0.6344827586206897, F1-score: 0.7698744769874477\n",
      "Epoch 9/50, Loss: 0.05183239529530207\n",
      "Validation Loss: 0.9332059770822525, Validation Accuracy: 0.7309644670050761\n",
      "Precision: 0.9791666666666666, Recall: 0.6482758620689655, F1-score: 0.7800829875518672\n",
      "Epoch 10/50, Loss: 0.04365206820269426\n",
      "Validation Loss: 0.9074106514453888, Validation Accuracy: 0.7969543147208121\n",
      "Precision: 0.981651376146789, Recall: 0.7379310344827587, F1-score: 0.84251968503937\n",
      "Epoch 11/50, Loss: 0.03879450944562753\n",
      "Validation Loss: 0.9075980335474014, Validation Accuracy: 0.8477157360406091\n",
      "Precision: 0.9831932773109243, Recall: 0.8068965517241379, F1-score: 0.8863636363636364\n",
      "Epoch 12/50, Loss: 0.03426622164746126\n",
      "Validation Loss: 0.9121747761964798, Validation Accuracy: 0.8527918781725888\n",
      "Precision: 0.9833333333333333, Recall: 0.8137931034482758, F1-score: 0.8905660377358491\n",
      "Epoch 13/50, Loss: 0.030920990121861298\n",
      "Validation Loss: 0.9221510589122772, Validation Accuracy: 0.868020304568528\n",
      "Precision: 0.983739837398374, Recall: 0.8344827586206897, F1-score: 0.9029850746268657\n",
      "Epoch 14/50, Loss: 0.027630406121412914\n",
      "Validation Loss: 0.9272637963294983, Validation Accuracy: 0.8629441624365483\n",
      "Precision: 0.9836065573770492, Recall: 0.8275862068965517, F1-score: 0.898876404494382\n",
      "Epoch 15/50, Loss: 0.02447721331069867\n",
      "Validation Loss: 0.9341692477464676, Validation Accuracy: 0.8629441624365483\n",
      "Precision: 0.9836065573770492, Recall: 0.8275862068965517, F1-score: 0.898876404494382\n",
      "Epoch 16/50, Loss: 0.02427016074458758\n",
      "Validation Loss: 0.9480676054954529, Validation Accuracy: 0.8629441624365483\n",
      "Precision: 0.9836065573770492, Recall: 0.8275862068965517, F1-score: 0.898876404494382\n",
      "Epoch 17/50, Loss: 0.02133937707791726\n",
      "Validation Loss: 0.9489853084087372, Validation Accuracy: 0.8629441624365483\n",
      "Precision: 0.9836065573770492, Recall: 0.8275862068965517, F1-score: 0.898876404494382\n",
      "Epoch 18/50, Loss: 0.019374688776830833\n",
      "Validation Loss: 0.9644211381673813, Validation Accuracy: 0.8629441624365483\n",
      "Precision: 0.9836065573770492, Recall: 0.8275862068965517, F1-score: 0.898876404494382\n",
      "Epoch 19/50, Loss: 0.017817750107496977\n",
      "Validation Loss: 0.9763707220554352, Validation Accuracy: 0.8629441624365483\n",
      "Precision: 0.9836065573770492, Recall: 0.8275862068965517, F1-score: 0.898876404494382\n",
      "Epoch 20/50, Loss: 0.016895682861407597\n",
      "Validation Loss: 0.9922789335250854, Validation Accuracy: 0.8578680203045685\n",
      "Precision: 0.9834710743801653, Recall: 0.8206896551724138, F1-score: 0.8947368421052632\n",
      "Epoch 21/50, Loss: 0.015414692927151918\n",
      "Validation Loss: 1.0030132085084915, Validation Accuracy: 0.8578680203045685\n",
      "Precision: 0.9834710743801653, Recall: 0.8206896551724138, F1-score: 0.8947368421052632\n",
      "Epoch 22/50, Loss: 0.014310893913110098\n",
      "Validation Loss: 1.0187275558710098, Validation Accuracy: 0.8426395939086294\n",
      "Precision: 0.9830508474576272, Recall: 0.8, F1-score: 0.8821292775665399\n",
      "Epoch 23/50, Loss: 0.013094482632974783\n",
      "Validation Loss: 1.0358491241931915, Validation Accuracy: 0.8324873096446701\n",
      "Precision: 0.9827586206896551, Recall: 0.7862068965517242, F1-score: 0.8735632183908046\n",
      "Epoch 24/50, Loss: 0.012985292201240858\n",
      "Validation Loss: 1.0500279366970062, Validation Accuracy: 0.8324873096446701\n",
      "Precision: 0.9827586206896551, Recall: 0.7862068965517242, F1-score: 0.8735632183908046\n",
      "Epoch 25/50, Loss: 0.01188994369780024\n",
      "Validation Loss: 1.0652721375226974, Validation Accuracy: 0.817258883248731\n",
      "Precision: 0.9823008849557522, Recall: 0.7655172413793103, F1-score: 0.8604651162790697\n",
      "Epoch 26/50, Loss: 0.011273876608659824\n",
      "Validation Loss: 1.0842592269182205, Validation Accuracy: 0.8121827411167513\n",
      "Precision: 0.9821428571428571, Recall: 0.7586206896551724, F1-score: 0.8560311284046692\n",
      "Epoch 27/50, Loss: 0.010743191465735435\n",
      "Validation Loss: 1.0984459519386292, Validation Accuracy: 0.7969543147208121\n",
      "Precision: 0.981651376146789, Recall: 0.7379310344827587, F1-score: 0.84251968503937\n",
      "Epoch 28/50, Loss: 0.009851290611550212\n",
      "Validation Loss: 1.1105253100395203, Validation Accuracy: 0.7969543147208121\n",
      "Precision: 0.981651376146789, Recall: 0.7379310344827587, F1-score: 0.84251968503937\n",
      "Epoch 29/50, Loss: 0.009200971263150374\n",
      "Validation Loss: 1.1262074261903763, Validation Accuracy: 0.7918781725888325\n",
      "Precision: 0.9814814814814815, Recall: 0.7310344827586207, F1-score: 0.8379446640316206\n",
      "Epoch 30/50, Loss: 0.008680084176982442\n",
      "Validation Loss: 1.1397705674171448, Validation Accuracy: 0.7918781725888325\n",
      "Precision: 0.9814814814814815, Recall: 0.7310344827586207, F1-score: 0.8379446640316206\n",
      "Epoch 31/50, Loss: 0.008236782431292037\n",
      "Validation Loss: 1.1587764620780945, Validation Accuracy: 0.7969543147208121\n",
      "Precision: 0.981651376146789, Recall: 0.7379310344827587, F1-score: 0.84251968503937\n",
      "Epoch 32/50, Loss: 0.007640452900280555\n",
      "Validation Loss: 1.1760949194431305, Validation Accuracy: 0.7969543147208121\n",
      "Precision: 0.981651376146789, Recall: 0.7379310344827587, F1-score: 0.84251968503937\n",
      "Epoch 33/50, Loss: 0.007443123497068882\n",
      "Validation Loss: 1.1914680898189545, Validation Accuracy: 0.7868020304568528\n",
      "Precision: 0.9813084112149533, Recall: 0.7241379310344828, F1-score: 0.8333333333333334\n",
      "Epoch 34/50, Loss: 0.007166008232161403\n",
      "Validation Loss: 1.2047550082206726, Validation Accuracy: 0.7817258883248731\n",
      "Precision: 0.9811320754716981, Recall: 0.7172413793103448, F1-score: 0.8286852589641435\n",
      "Epoch 35/50, Loss: 0.006795773437867562\n",
      "Validation Loss: 1.2161568105220795, Validation Accuracy: 0.7817258883248731\n",
      "Precision: 0.9811320754716981, Recall: 0.7172413793103448, F1-score: 0.8286852589641435\n",
      "Epoch 36/50, Loss: 0.006523952431355913\n",
      "Validation Loss: 1.2273336201906204, Validation Accuracy: 0.7766497461928934\n",
      "Precision: 0.9809523809523809, Recall: 0.7103448275862069, F1-score: 0.824\n",
      "Epoch 37/50, Loss: 0.006215645854050915\n",
      "Validation Loss: 1.236244335770607, Validation Accuracy: 0.7766497461928934\n",
      "Precision: 0.9809523809523809, Recall: 0.7103448275862069, F1-score: 0.824\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 51), padding='same')\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.depthwiseConv2d = nn.Conv2d(16, 32, (65, 1), groups=16, padding='same')\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.activation = nn.ELU()\n",
    "        self.pooling = nn.AvgPool2d((1, 4))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(32 * 65 * 31, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.depthwiseConv2d(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class PolygraphNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(PolygraphNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 51), padding='same')\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.depthwiseConv2d = nn.Conv2d(16, 32, (4, 1), groups=16, padding='same')\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.activation = nn.ELU()\n",
    "        self.pooling = nn.AvgPool2d((1, 4))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(32 * 4 * 1118, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.depthwiseConv2d(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, eeg_model, poly_model):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.eeg_model = eeg_model\n",
    "        self.poly_model = poly_model\n",
    "        self.fc = nn.Linear(4, 2)\n",
    "\n",
    "    def forward(self, eeg_input, poly_input):\n",
    "        eeg_output = self.eeg_model(eeg_input)\n",
    "        poly_output = self.poly_model(poly_input)\n",
    "        combined_output = torch.cat((eeg_output, poly_output), dim=1)\n",
    "        output = self.fc(combined_output)\n",
    "        return output\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    all_labels, all_predictions = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for eeg_X_batch, eeg_y_batch, poly_X_batch, poly_y_batch in data_loader:\n",
    "            eeg_X_batch, poly_X_batch = eeg_X_batch.to(device), poly_X_batch.to(device)\n",
    "            labels = eeg_y_batch.to(device)  # Use EEG labels (they should be the same as Poly labels)\n",
    "            \n",
    "            outputs = model(eeg_X_batch, poly_X_batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(all_labels, all_predictions, average='binary', zero_division=1)\n",
    "    recall = recall_score(all_labels, all_predictions, average='binary', zero_division=1)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='binary', zero_division=1)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions, labels=[0, 1])\n",
    "\n",
    "    return total_loss / len(data_loader), accuracy, precision, recall, f1, conf_matrix\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, save_path):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for eeg_X_batch, eeg_y_batch, poly_X_batch, poly_y_batch in train_loader:\n",
    "            eeg_X_batch, poly_X_batch = eeg_X_batch.to(device), poly_X_batch.to(device)\n",
    "            labels = eeg_y_batch.to(device)  # Use EEG labels (they should be the same as Poly labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(eeg_X_batch, poly_X_batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss}')\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy, val_precision, val_recall, val_f1, val_conf_matrix = evaluate_model(model, val_loader, criterion, device)\n",
    "        print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "        print(f'Precision: {val_precision}, Recall: {val_recall}, F1-score: {val_f1}')\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'val_accuracy': val_accuracy,\n",
    "                'val_precision': val_precision,\n",
    "                'val_recall': val_recall,\n",
    "                'val_f1': val_f1,\n",
    "            }, save_path)\n",
    "            print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "# Load data\n",
    "print(\"Loading EEG data...\")\n",
    "eeg_X, eeg_y, file_sample_counts = load_eeg_data(EEG_DATA_DIR)\n",
    "print(\"Loading Poly data...\")\n",
    "poly_X, poly_y = load_poly_data(POLY_DATA_DIR)\n",
    "\n",
    "# Create splits based on file indices\n",
    "splits = create_file_based_splits(file_sample_counts, n_splits=5)\n",
    "\n",
    "for fold, (train_file_indices, val_file_indices) in enumerate(splits):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Split data based on file indices\n",
    "    train_sample_counts = [file_sample_counts[i] for i in train_file_indices]\n",
    "    val_sample_counts = [file_sample_counts[i] for i in val_file_indices]\n",
    "    \n",
    "    train_eeg_indices = np.concatenate([np.arange(sum(file_sample_counts[:i]), \n",
    "                                                  sum(file_sample_counts[:i+1])) \n",
    "                                        for i in train_file_indices])\n",
    "    val_eeg_indices = np.concatenate([np.arange(sum(file_sample_counts[:i]), \n",
    "                                                sum(file_sample_counts[:i+1])) \n",
    "                                      for i in val_file_indices])\n",
    "\n",
    "    # Split EEG data\n",
    "    train_eeg_X, train_eeg_y = eeg_X[train_eeg_indices], eeg_y[train_eeg_indices]\n",
    "    val_eeg_X, val_eeg_y = eeg_X[val_eeg_indices], eeg_y[val_eeg_indices]\n",
    "\n",
    "    # Split Poly data\n",
    "    train_poly_X, train_poly_y = poly_X[train_file_indices], poly_y[train_file_indices]\n",
    "    val_poly_X, val_poly_y = poly_X[val_file_indices], poly_y[val_file_indices]\n",
    "\n",
    "    # Normalize data for this fold\n",
    "    eeg_scaler = StandardScaler()\n",
    "    poly_scaler = StandardScaler()\n",
    "\n",
    "\n",
    "    train_eeg_X_2d = train_eeg_X.reshape(-1, train_eeg_X.shape[-1])  \n",
    "    train_eeg_X_2d_scaled = eeg_scaler.fit_transform(train_eeg_X_2d)\n",
    "    train_eeg_X_scaled = train_eeg_X_2d_scaled.reshape(train_eeg_X.shape)\n",
    "    \n",
    "    # Reshape and transform validation data\n",
    "    val_eeg_X_2d = val_eeg_X.reshape(-1, val_eeg_X.shape[-1])\n",
    "    val_eeg_X_2d_scaled = eeg_scaler.transform(val_eeg_X_2d)\n",
    "    val_eeg_X_scaled = val_eeg_X_2d_scaled.reshape(val_eeg_X.shape)\n",
    "    \n",
    "    train_poly_X_2d = train_poly_X.reshape(-1, train_poly_X.shape[-1])\n",
    "    train_poly_X_2d_scaled = poly_scaler.fit_transform(train_poly_X_2d)\n",
    "    train_poly_X_scaled = train_poly_X_2d_scaled.reshape(train_poly_X.shape)\n",
    "    \n",
    "    val_poly_X_2d = val_poly_X.reshape(-1, val_poly_X.shape[-1])\n",
    "    val_poly_X_2d_scaled = poly_scaler.transform(val_poly_X_2d)\n",
    "    val_poly_X_scaled = val_poly_X_2d_scaled.reshape(val_poly_X.shape)\n",
    "\n",
    "    # Create datasets for this fold\n",
    "    train_dataset = CombinedDataset(train_eeg_X_scaled, train_eeg_y, train_poly_X_scaled, train_poly_y, train_sample_counts)\n",
    "    val_dataset = CombinedDataset(val_eeg_X_scaled, val_eeg_y, val_poly_X_scaled, val_poly_y, val_sample_counts)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    # Initialize models\n",
    "    eeg_model = EEGNet(num_classes=2).to(device)\n",
    "    poly_model = PolygraphNet(num_classes=2).to(device)\n",
    "    ensemble_model = EnsembleModel(eeg_model, poly_model).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    ensemble_optimizer = optim.Adam(ensemble_model.parameters(), lr=0.0001)\n",
    "\n",
    "    # Train and evaluate model (rest of your code remains the same)\n",
    "    ...\n",
    "    # Train the model and save it\n",
    "    save_path = f'ensemble_model_fold_{fold}.pth'\n",
    "    best_model_path = train_model(ensemble_model, train_loader, val_loader, criterion, ensemble_optimizer, num_epochs, device, save_path)\n",
    "\n",
    "    # Load the best model and evaluate on validation set\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    ensemble_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    val_loss, val_accuracy, val_precision, val_recall, val_f1, val_conf_matrix = evaluate_model(ensemble_model, val_loader, criterion, device)\n",
    "    \n",
    "    print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "    print(f'Precision: {val_precision}, Recall: {val_recall}, F1-score: {val_f1}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(val_conf_matrix)\n",
    "    \n",
    "    results.append({\n",
    "        'fold': fold,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    })\n",
    "\n",
    "# Print average results\n",
    "avg_accuracy = np.mean([r['val_accuracy'] for r in results])\n",
    "avg_precision = np.mean([r['val_precision'] for r in results])\n",
    "avg_recall = np.mean([r['val_recall'] for r in results])\n",
    "avg_f1 = np.mean([r['val_f1'] for r in results])\n",
    "\n",
    "print(\"\\nAverage results across all folds:\")\n",
    "print(f\"Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Precision: {avg_precision:.4f}\")\n",
    "print(f\"Recall: {avg_recall:.4f}\")\n",
    "print(f\"F1-score: {avg_f1:.4f}\")\n",
    "\n",
    "# Save the final model (you can choose to save the model from the best fold instead)\n",
    "final_model_path = 'final_ensemble_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': ensemble_model.state_dict(),\n",
    "    'avg_accuracy': avg_accuracy,\n",
    "    'avg_precision': avg_precision,\n",
    "    'avg_recall': avg_recall,\n",
    "    'avg_f1': avg_f1,\n",
    "}, final_model_path)\n",
    "print(f\"Final model saved to {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911294f-a9f1-4b9a-a912-afea5f59c972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af669253-0646-4a15-88de-6e4de56c97bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
