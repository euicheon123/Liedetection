{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1159f92-96e7-4f79-9cd1-ec348c0a4b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG data...\n",
      "EEG File: augmented_lie_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_10.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_11.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_12.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_13.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_14.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_15.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_16.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_17.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_19.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_2.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_20.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_21.pkl, Shape: (17, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_22.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_23.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_24.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_25.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_26.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_27.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_28.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_29.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_3.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_30.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_31.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_33.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_34.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_4.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_5.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_6.pkl, Shape: (26, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_7.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_8.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_9.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_10.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_11.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_12.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_13.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_14.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_15.pkl, Shape: (4, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_16.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_17.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_19.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_2.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_20.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_21.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_22.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_23.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_24.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_25.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_26.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_27.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_28.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_29.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_3.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_30.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_31.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_33.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_34.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_36.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_37.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_38.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_39.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_4.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_40.pkl, Shape: (30, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_41.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_42.pkl, Shape: (18, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_43.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_44.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_45.pkl, Shape: (14, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_46.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_47.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_48.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_49.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_5.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_50.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_51.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_52.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_53.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_54.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_55.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_6.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_7.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_8.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_9.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "Loaded from EEG C:\\Users\\User\\Documents\\Lie detect data\\AugmentedEEGData: 333 lie samples, 602 truth samples\n",
      "Loading Poly data...\n",
      "Poly File: poly_lie_1.pkl, Shape: (4, 2963), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_10.pkl, Shape: (4, 3171), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_11.pkl, Shape: (4, 2917), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_12.pkl, Shape: (4, 2991), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_13.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_14.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_15.pkl, Shape: (4, 2929), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_16.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_17.pkl, Shape: (4, 3234), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_18.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_19.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_2.pkl, Shape: (4, 2895), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_20.pkl, Shape: (4, 3291), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_21.pkl, Shape: (4, 3658), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_22.pkl, Shape: (4, 3375), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_23.pkl, Shape: (4, 3334), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_24.pkl, Shape: (4, 3263), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_25.pkl, Shape: (4, 3292), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_26.pkl, Shape: (4, 3246), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_27.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_28.pkl, Shape: (4, 3262), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_29.pkl, Shape: (4, 3321), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_3.pkl, Shape: (4, 2941), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_30.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_31.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_32.pkl, Shape: (4, 3142), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_33.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_34.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_35.pkl, Shape: (4, 3179), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_4.pkl, Shape: (4, 2967), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_5.pkl, Shape: (4, 2913), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_6.pkl, Shape: (4, 4229), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_7.pkl, Shape: (4, 3129), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_8.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_9.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_1.pkl, Shape: (4, 2958), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_10.pkl, Shape: (4, 3104), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_11.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_12.pkl, Shape: (4, 3391), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_13.pkl, Shape: (4, 3141), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_14.pkl, Shape: (4, 3271), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_15.pkl, Shape: (4, 2859), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_16.pkl, Shape: (4, 3325), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_17.pkl, Shape: (4, 3383), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_18.pkl, Shape: (4, 3233), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_19.pkl, Shape: (4, 3366), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_2.pkl, Shape: (4, 3112), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_20.pkl, Shape: (4, 3313), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_21.pkl, Shape: (4, 3555), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_22.pkl, Shape: (4, 3346), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_23.pkl, Shape: (4, 3305), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_24.pkl, Shape: (4, 3200), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_25.pkl, Shape: (4, 3213), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_26.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_27.pkl, Shape: (4, 3188), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_28.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_29.pkl, Shape: (4, 3242), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_3.pkl, Shape: (4, 3016), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_30.pkl, Shape: (4, 3258), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_31.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_32.pkl, Shape: (4, 3175), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_33.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_34.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_35.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_36.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_37.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_38.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_39.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_4.pkl, Shape: (4, 3058), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_40.pkl, Shape: (4, 4475), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_41.pkl, Shape: (4, 3162), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_42.pkl, Shape: (4, 3704), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_43.pkl, Shape: (4, 3333), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_44.pkl, Shape: (4, 3396), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_45.pkl, Shape: (4, 3450), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_46.pkl, Shape: (4, 3537), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_47.pkl, Shape: (4, 3363), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_48.pkl, Shape: (4, 3250), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_49.pkl, Shape: (4, 3279), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_5.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_50.pkl, Shape: (4, 3508), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_51.pkl, Shape: (4, 3358), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_52.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_53.pkl, Shape: (4, 3379), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_54.pkl, Shape: (4, 3558), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_55.pkl, Shape: (4, 3392), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_6.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_7.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_8.pkl, Shape: (4, 3096), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_9.pkl, Shape: (4, 3225), Type: <class 'numpy.ndarray'>\n",
      "Loaded from Poly C:\\Users\\User\\Documents\\Lie detect data\\CombinedPolyData: 35 lie samples, 55 truth samples\n",
      "EEG Class distribution: {0: 333, 1: 602}\n",
      "Poly Class distribution: {0: 35, 1: 55}\n",
      "EEG data shape: (935, 65, 125)\n",
      "Poly data shape: (90, 4, 4475)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "\n",
    "# Constants\n",
    "EEG_DATA_DIR = r'C:\\Users\\User\\Documents\\Lie detect data\\AugmentedEEGData'\n",
    "POLY_DATA_DIR = r'C:\\Users\\User\\Documents\\Lie detect data\\CombinedPolyData'\n",
    "K_FOLDS = 5  # Number of folds for cross-validation\n",
    "\n",
    "def pad_sequence(sequence, target_length):\n",
    "    \"\"\"Pad the sequence to the target length.\"\"\"\n",
    "    pad_length = target_length - sequence.shape[1]\n",
    "    if pad_length > 0:\n",
    "        return np.pad(sequence, ((0, 0), (0, pad_length)), mode='constant')\n",
    "    else:\n",
    "        return sequence[:, :target_length]\n",
    "\n",
    "def load_eeg_data(data_dir):\n",
    "    X, y = [], []\n",
    "    lie_count, truth_count = 0, 0\n",
    "    file_sample_counts = []\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        if file_name.endswith('.pkl'):\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            try:\n",
    "                data = pd.read_pickle(file_path)\n",
    "                print(f\"EEG File: {file_name}, Shape: {data.shape}, Type: {type(data)}\")\n",
    "                label = 0 if 'lie' in file_name.lower() else 1\n",
    "                X.extend(data)\n",
    "                y.extend([label] * data.shape[0])\n",
    "                file_sample_counts.append(data.shape[0])\n",
    "                if label == 0:\n",
    "                    lie_count += data.shape[0]\n",
    "                else:\n",
    "                    truth_count += data.shape[0]\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading EEG file {file_name}: {str(e)}\")\n",
    "    print(f\"Loaded from EEG {data_dir}: {lie_count} lie samples, {truth_count} truth samples\")\n",
    "    return np.array(X), np.array(y), file_sample_counts\n",
    "\n",
    "def load_poly_data(data_dir):\n",
    "    X, y = [], []\n",
    "    lie_count, truth_count = 0, 0\n",
    "    max_length = 0\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        if file_name.endswith('.pkl'):\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            try:\n",
    "                data = pd.read_pickle(file_path)\n",
    "                print(f\"Poly File: {file_name}, Shape: {data.shape}, Type: {type(data)}\")\n",
    "                max_length = max(max_length, data.shape[1])\n",
    "                label = 0 if 'lie' in file_name.lower() else 1\n",
    "                X.append(data)\n",
    "                y.append(label)\n",
    "                if label == 0:\n",
    "                    lie_count += 1\n",
    "                else:\n",
    "                    truth_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading Poly file {file_name}: {str(e)}\")\n",
    "    print(f\"Loaded from Poly {data_dir}: {lie_count} lie samples, {truth_count} truth samples\")\n",
    "    \n",
    "    # Pad all poly samples to the maximum length\n",
    "    X_padded = np.array([pad_sequence(x, max_length) for x in X])\n",
    "    return X_padded, np.array(y)\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, eeg_X, eeg_y, poly_X, poly_y, file_sample_counts):\n",
    "        self.eeg_X = torch.tensor(eeg_X, dtype=torch.float32)\n",
    "        self.eeg_y = torch.tensor(eeg_y, dtype=torch.long)\n",
    "        self.poly_X = torch.tensor(poly_X, dtype=torch.float32)\n",
    "        self.poly_y = torch.tensor(poly_y, dtype=torch.long)\n",
    "        \n",
    "        # Create a mapping from EEG sample index to Poly file index\n",
    "        self.eeg_to_poly_map = []\n",
    "        poly_index = 0\n",
    "        for count in file_sample_counts:\n",
    "            self.eeg_to_poly_map.extend([poly_index] * count)\n",
    "            poly_index += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eeg_X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg_sample = self.eeg_X[idx]\n",
    "        eeg_label = self.eeg_y[idx]\n",
    "        poly_idx = self.eeg_to_poly_map[idx]\n",
    "        poly_sample = self.poly_X[poly_idx]\n",
    "        poly_label = self.poly_y[poly_idx]\n",
    "        \n",
    "        return eeg_sample, eeg_label, poly_sample, poly_label\n",
    "\n",
    "def create_file_based_splits(file_sample_counts, n_splits=5):\n",
    "    file_indices = np.arange(len(file_sample_counts))\n",
    "    group_kfold = GroupKFold(n_splits=n_splits)\n",
    "    return list(group_kfold.split(X=file_indices, groups=file_indices))\n",
    "\n",
    "# Load data\n",
    "print(\"Loading EEG data...\")\n",
    "eeg_X, eeg_y, file_sample_counts = load_eeg_data(EEG_DATA_DIR)\n",
    "print(\"Loading Poly data...\")\n",
    "poly_X, poly_y = load_poly_data(POLY_DATA_DIR)\n",
    "\n",
    "# Check for class imbalance\n",
    "unique, counts = np.unique(eeg_y, return_counts=True)\n",
    "print(\"EEG Class distribution:\", dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(poly_y, return_counts=True)\n",
    "print(\"Poly Class distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "# Print dataset size and shapes\n",
    "print(\"EEG data shape:\", eeg_X.shape)\n",
    "print(\"Poly data shape:\", poly_X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "807dc975-266c-4193-ac4b-3c69be28d126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG data...\n",
      "EEG File: augmented_lie_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_10.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_11.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_12.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_13.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_14.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_15.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_16.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_17.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_19.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_2.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_20.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_21.pkl, Shape: (17, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_22.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_23.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_24.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_25.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_26.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_27.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_28.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_29.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_3.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_30.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_31.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_33.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_34.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_4.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_5.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_6.pkl, Shape: (26, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_7.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_8.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_9.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_10.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_11.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_12.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_13.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_14.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_15.pkl, Shape: (4, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_16.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_17.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_19.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_2.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_20.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_21.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_22.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_23.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_24.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_25.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_26.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_27.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_28.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_29.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_3.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_30.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_31.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_33.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_34.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_36.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_37.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_38.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_39.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_4.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_40.pkl, Shape: (30, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_41.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_42.pkl, Shape: (18, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_43.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_44.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_45.pkl, Shape: (14, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_46.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_47.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_48.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_49.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_5.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_50.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_51.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_52.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_53.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_54.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_55.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_6.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_7.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_8.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_9.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "Loaded from EEG C:\\Users\\User\\Documents\\Lie detect data\\AugmentedEEGData: 333 lie samples, 602 truth samples\n",
      "Loading Poly data...\n",
      "Poly File: poly_lie_1.pkl, Shape: (4, 2963), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_10.pkl, Shape: (4, 3171), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_11.pkl, Shape: (4, 2917), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_12.pkl, Shape: (4, 2991), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_13.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_14.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_15.pkl, Shape: (4, 2929), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_16.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_17.pkl, Shape: (4, 3234), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_18.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_19.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_2.pkl, Shape: (4, 2895), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_20.pkl, Shape: (4, 3291), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_21.pkl, Shape: (4, 3658), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_22.pkl, Shape: (4, 3375), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_23.pkl, Shape: (4, 3334), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_24.pkl, Shape: (4, 3263), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_25.pkl, Shape: (4, 3292), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_26.pkl, Shape: (4, 3246), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_27.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_28.pkl, Shape: (4, 3262), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_29.pkl, Shape: (4, 3321), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_3.pkl, Shape: (4, 2941), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_30.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_31.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_32.pkl, Shape: (4, 3142), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_33.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_34.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_35.pkl, Shape: (4, 3179), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_4.pkl, Shape: (4, 2967), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_5.pkl, Shape: (4, 2913), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_6.pkl, Shape: (4, 4229), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_7.pkl, Shape: (4, 3129), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_8.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_9.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_1.pkl, Shape: (4, 2958), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_10.pkl, Shape: (4, 3104), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_11.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_12.pkl, Shape: (4, 3391), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_13.pkl, Shape: (4, 3141), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_14.pkl, Shape: (4, 3271), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_15.pkl, Shape: (4, 2859), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_16.pkl, Shape: (4, 3325), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_17.pkl, Shape: (4, 3383), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_18.pkl, Shape: (4, 3233), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_19.pkl, Shape: (4, 3366), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_2.pkl, Shape: (4, 3112), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_20.pkl, Shape: (4, 3313), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_21.pkl, Shape: (4, 3555), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_22.pkl, Shape: (4, 3346), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_23.pkl, Shape: (4, 3305), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_24.pkl, Shape: (4, 3200), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_25.pkl, Shape: (4, 3213), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_26.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_27.pkl, Shape: (4, 3188), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_28.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_29.pkl, Shape: (4, 3242), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_3.pkl, Shape: (4, 3016), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_30.pkl, Shape: (4, 3258), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_31.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_32.pkl, Shape: (4, 3175), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_33.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_34.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_35.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_36.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_37.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_38.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_39.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_4.pkl, Shape: (4, 3058), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_40.pkl, Shape: (4, 4475), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_41.pkl, Shape: (4, 3162), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_42.pkl, Shape: (4, 3704), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_43.pkl, Shape: (4, 3333), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_44.pkl, Shape: (4, 3396), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_45.pkl, Shape: (4, 3450), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_46.pkl, Shape: (4, 3537), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_47.pkl, Shape: (4, 3363), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_48.pkl, Shape: (4, 3250), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_49.pkl, Shape: (4, 3279), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_5.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_50.pkl, Shape: (4, 3508), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_51.pkl, Shape: (4, 3358), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_52.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_53.pkl, Shape: (4, 3379), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_54.pkl, Shape: (4, 3558), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_55.pkl, Shape: (4, 3392), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_6.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_7.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_8.pkl, Shape: (4, 3096), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_9.pkl, Shape: (4, 3225), Type: <class 'numpy.ndarray'>\n",
      "Loaded from Poly C:\\Users\\User\\Documents\\Lie detect data\\CombinedPolyData: 35 lie samples, 55 truth samples\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Epoch 1/100, Loss: 0.18473309049538025\n",
      "Validation Loss: 1.633555621529619, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Model saved to ensemble_model_fold_0.pth\n",
      "Epoch 2/100, Loss: 0.02368796964098389\n",
      "Validation Loss: 1.77977226767689, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 3/100, Loss: 0.00999623407794085\n",
      "Validation Loss: 1.8150633540935814, Validation Accuracy: 0.6408839779005525\n",
      "Precision: 0.7424242424242424, Recall: 0.7596899224806202, F1-score: 0.7509578544061303\n",
      "Epoch 4/100, Loss: 0.004910874218088186\n",
      "Validation Loss: 2.0883456451507905, Validation Accuracy: 0.6187845303867403\n",
      "Precision: 0.734375, Recall: 0.7286821705426356, F1-score: 0.7315175097276264\n",
      "Epoch 5/100, Loss: 0.002544617005090307\n",
      "Validation Loss: 2.3789175824106983, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 6/100, Loss: 0.0020383767861555193\n",
      "Validation Loss: 2.49368467181921, Validation Accuracy: 0.6408839779005525\n",
      "Precision: 0.7424242424242424, Recall: 0.7596899224806202, F1-score: 0.7509578544061303\n",
      "Epoch 7/100, Loss: 0.001765324018682198\n",
      "Validation Loss: 2.467855977321354, Validation Accuracy: 0.6408839779005525\n",
      "Precision: 0.7424242424242424, Recall: 0.7596899224806202, F1-score: 0.7509578544061303\n",
      "Epoch 8/100, Loss: 0.0013632588285569607\n",
      "Validation Loss: 2.649210190788532, Validation Accuracy: 0.6408839779005525\n",
      "Precision: 0.7424242424242424, Recall: 0.7596899224806202, F1-score: 0.7509578544061303\n",
      "Epoch 9/100, Loss: 0.0008251261010627786\n",
      "Validation Loss: 2.758154753712006, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 10/100, Loss: 0.0006498900311271427\n",
      "Validation Loss: 2.9915414514640966, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 11/100, Loss: 0.000628507531549379\n",
      "Validation Loss: 2.9689462591777556, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 12/100, Loss: 0.00047333589327536174\n",
      "Validation Loss: 3.051546560910841, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 13/100, Loss: 0.00035361331077865543\n",
      "Validation Loss: 3.1297193711410123, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 14/100, Loss: 0.00043027644286060723\n",
      "Validation Loss: 3.1813484162072805, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 15/100, Loss: 0.0003878858378811856\n",
      "Validation Loss: 3.147560402615151, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 16/100, Loss: 0.00031432505352313456\n",
      "Validation Loss: 3.1823513109314567, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 17/100, Loss: 0.0002812837198386357\n",
      "Validation Loss: 3.2309741014420674, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 18/100, Loss: 0.00031737724051102606\n",
      "Validation Loss: 3.3290825077565387, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 19/100, Loss: 0.00029318031516822884\n",
      "Validation Loss: 3.3957160471957955, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 20/100, Loss: 0.00020223924980200536\n",
      "Validation Loss: 3.461212706301012, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 21/100, Loss: 0.00023516601940324713\n",
      "Validation Loss: 3.37379202664791, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 22/100, Loss: 0.00017758579987988318\n",
      "Validation Loss: 3.5950055158803784, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 23/100, Loss: 0.00017196706653521687\n",
      "Validation Loss: 3.631882695335662, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 24/100, Loss: 0.00014389821031575897\n",
      "Validation Loss: 3.584829176426865, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 25/100, Loss: 0.00010723166083910958\n",
      "Validation Loss: 3.4931249750661664, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 26/100, Loss: 0.00013524914944203678\n",
      "Validation Loss: 3.644463751518439, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 27/100, Loss: 8.614387483400303e-05\n",
      "Validation Loss: 3.6882675579496813, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 28/100, Loss: 0.00011067316448058288\n",
      "Validation Loss: 3.6822036818921333, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 29/100, Loss: 0.00012612322296826997\n",
      "Validation Loss: 3.7564857982021445, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 30/100, Loss: 0.0001151861119979003\n",
      "Validation Loss: 3.6818392332206713, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 31/100, Loss: 9.19096728466684e-05\n",
      "Validation Loss: 3.789107199239273, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 32/100, Loss: 8.212004612081121e-05\n",
      "Validation Loss: 3.7591441099405833, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 33/100, Loss: 8.861665092278297e-05\n",
      "Validation Loss: 3.687485466953755, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.75, Recall: 0.7674418604651163, F1-score: 0.7586206896551724\n",
      "Epoch 34/100, Loss: 6.35820343669972e-05\n",
      "Validation Loss: 3.7977745273237815, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 35/100, Loss: 9.717378903436232e-05\n",
      "Validation Loss: 3.68631636807307, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 36/100, Loss: 6.746009040625722e-05\n",
      "Validation Loss: 3.7858265946585257, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 37/100, Loss: 7.343360099791123e-05\n",
      "Validation Loss: 3.7656083183634714, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 38/100, Loss: 5.849556900254053e-05\n",
      "Validation Loss: 3.7669661473870897, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 39/100, Loss: 5.2440028317353914e-05\n",
      "Validation Loss: 3.7930412294420726, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 40/100, Loss: 4.966846866712634e-05\n",
      "Validation Loss: 3.9900208144802796, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 41/100, Loss: 7.26079420919253e-05\n",
      "Validation Loss: 3.8940032157988753, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 42/100, Loss: 6.12849567005469e-05\n",
      "Validation Loss: 3.7850290598289575, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Epoch 43/100, Loss: 4.592824006029635e-05\n",
      "Validation Loss: 3.8392704182867115, Validation Accuracy: 0.6629834254143646\n",
      "Precision: 0.7615384615384615, Recall: 0.7674418604651163, F1-score: 0.7644787644787645\n",
      "Epoch 44/100, Loss: 4.858337699905254e-05\n",
      "Validation Loss: 3.822842507181728, Validation Accuracy: 0.6740331491712708\n",
      "Precision: 0.7734375, Recall: 0.7674418604651163, F1-score: 0.7704280155642024\n",
      "Epoch 45/100, Loss: 3.772070438875138e-05\n",
      "Validation Loss: 3.905929941344463, Validation Accuracy: 0.6629834254143646\n",
      "Precision: 0.7615384615384615, Recall: 0.7674418604651163, F1-score: 0.7644787644787645\n",
      "Epoch 46/100, Loss: 4.674786900219866e-05\n",
      "Validation Loss: 3.9084308970462494, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.75, Recall: 0.7674418604651163, F1-score: 0.7586206896551724\n",
      "Epoch 47/100, Loss: 5.602016794152102e-05\n",
      "Validation Loss: 3.9017169656872284, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.75, Recall: 0.7674418604651163, F1-score: 0.7586206896551724\n",
      "Epoch 48/100, Loss: 3.816279996726735e-05\n",
      "Validation Loss: 3.8887022799366, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.75, Recall: 0.7674418604651163, F1-score: 0.7586206896551724\n",
      "Epoch 49/100, Loss: 4.34132641657925e-05\n",
      "Validation Loss: 3.996244304192563, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.75, Recall: 0.7674418604651163, F1-score: 0.7586206896551724\n",
      "Epoch 50/100, Loss: 3.250790588064471e-05\n",
      "Validation Loss: 3.9869854250888843, Validation Accuracy: 0.6629834254143646\n",
      "Precision: 0.7615384615384615, Recall: 0.7674418604651163, F1-score: 0.7644787644787645\n",
      "Epoch 51/100, Loss: 3.780037599199204e-05\n",
      "Validation Loss: 4.103632336572143, Validation Accuracy: 0.6740331491712708\n",
      "Precision: 0.7734375, Recall: 0.7674418604651163, F1-score: 0.7704280155642024\n",
      "Epoch 52/100, Loss: 3.47231688095917e-05\n",
      "Validation Loss: 3.9834910515055526, Validation Accuracy: 0.6740331491712708\n",
      "Precision: 0.7734375, Recall: 0.7674418604651163, F1-score: 0.7704280155642024\n",
      "Epoch 53/100, Loss: 3.133534498545032e-05\n",
      "Validation Loss: 3.9582845837697582, Validation Accuracy: 0.6740331491712708\n",
      "Precision: 0.7734375, Recall: 0.7674418604651163, F1-score: 0.7704280155642024\n",
      "Epoch 54/100, Loss: 4.793341768305481e-05\n",
      "Validation Loss: 4.067707101662866, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.75, Recall: 0.7674418604651163, F1-score: 0.7586206896551724\n",
      "Epoch 55/100, Loss: 3.738656973458395e-05\n",
      "Validation Loss: 4.066486525477861, Validation Accuracy: 0.6850828729281768\n",
      "Precision: 0.7857142857142857, Recall: 0.7674418604651163, F1-score: 0.7764705882352941\n",
      "Epoch 56/100, Loss: 2.964328920522045e-05\n",
      "Validation Loss: 3.9955846941884374, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 57/100, Loss: 2.827036980571999e-05\n",
      "Validation Loss: 4.0301519053221755, Validation Accuracy: 0.6961325966850829\n",
      "Precision: 0.7983870967741935, Recall: 0.7674418604651163, F1-score: 0.782608695652174\n",
      "Epoch 58/100, Loss: 2.9675147579529455e-05\n",
      "Validation Loss: 4.088371170839916, Validation Accuracy: 0.6795580110497238\n",
      "Precision: 0.7795275590551181, Recall: 0.7674418604651163, F1-score: 0.7734375\n",
      "Epoch 59/100, Loss: 2.1354650603673992e-05\n",
      "Validation Loss: 4.058771638650796, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8048780487804879, Recall: 0.7674418604651163, F1-score: 0.7857142857142857\n",
      "Epoch 60/100, Loss: 3.838479871139574e-05\n",
      "Validation Loss: 3.9943489805688537, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 61/100, Loss: 2.353183115152054e-05\n",
      "Validation Loss: 4.179280863737707, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8048780487804879, Recall: 0.7674418604651163, F1-score: 0.7857142857142857\n",
      "Epoch 62/100, Loss: 2.687353126873404e-05\n",
      "Validation Loss: 4.070099065558073, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8048780487804879, Recall: 0.7674418604651163, F1-score: 0.7857142857142857\n",
      "Epoch 63/100, Loss: 1.98706023155637e-05\n",
      "Validation Loss: 4.263048581240582, Validation Accuracy: 0.6906077348066298\n",
      "Precision: 0.792, Recall: 0.7674418604651163, F1-score: 0.7795275590551181\n",
      "Epoch 64/100, Loss: 2.1992481078333032e-05\n",
      "Validation Loss: 4.106886359741718, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 65/100, Loss: 2.2126963182600434e-05\n",
      "Validation Loss: 4.108927480958907, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8048780487804879, Recall: 0.7674418604651163, F1-score: 0.7857142857142857\n",
      "Epoch 66/100, Loss: 2.035187888083101e-05\n",
      "Validation Loss: 4.208626886087586, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 67/100, Loss: 2.780900170999227e-05\n",
      "Validation Loss: 4.251760652334876, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8048780487804879, Recall: 0.7674418604651163, F1-score: 0.7857142857142857\n",
      "Epoch 68/100, Loss: 2.1862296480416415e-05\n",
      "Validation Loss: 4.220885036214895, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8048780487804879, Recall: 0.7674418604651163, F1-score: 0.7857142857142857\n",
      "Epoch 69/100, Loss: 2.4827658738975817e-05\n",
      "Validation Loss: 4.161074837191943, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 70/100, Loss: 2.0381588080671993e-05\n",
      "Validation Loss: 4.313957295300497, Validation Accuracy: 0.6906077348066298\n",
      "Precision: 0.792, Recall: 0.7674418604651163, F1-score: 0.7795275590551181\n",
      "Epoch 71/100, Loss: 1.6863003149107197e-05\n",
      "Validation Loss: 4.213334580177616, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 72/100, Loss: 2.3241697531280654e-05\n",
      "Validation Loss: 4.353703981758978, Validation Accuracy: 0.6740331491712708\n",
      "Precision: 0.7734375, Recall: 0.7674418604651163, F1-score: 0.7704280155642024\n",
      "Epoch 73/100, Loss: 2.2208208262005275e-05\n",
      "Validation Loss: 4.276581245946242, Validation Accuracy: 0.6906077348066298\n",
      "Precision: 0.792, Recall: 0.7674418604651163, F1-score: 0.7795275590551181\n",
      "Epoch 74/100, Loss: 1.592807739333087e-05\n",
      "Validation Loss: 4.260936949104992, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8048780487804879, Recall: 0.7674418604651163, F1-score: 0.7857142857142857\n",
      "Epoch 75/100, Loss: 1.7624143713608948e-05\n",
      "Validation Loss: 4.271960703500857, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 76/100, Loss: 1.2363451683465124e-05\n",
      "Validation Loss: 4.2839802561308415, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 77/100, Loss: 1.4328472689821107e-05\n",
      "Validation Loss: 4.285957229643827, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 78/100, Loss: 1.622488448541996e-05\n",
      "Validation Loss: 4.351417374383648, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 79/100, Loss: 2.0707091046290316e-05\n",
      "Validation Loss: 4.378135373039792, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 80/100, Loss: 1.3592322313608443e-05\n",
      "Validation Loss: 4.34825934472974, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 81/100, Loss: 1.2549698958252975e-05\n",
      "Validation Loss: 4.28243729530368, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 82/100, Loss: 1.187314007111695e-05\n",
      "Validation Loss: 4.499708111364574, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 83/100, Loss: 2.3242693851936263e-05\n",
      "Validation Loss: 4.359278951971646, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 84/100, Loss: 1.8451946925660916e-05\n",
      "Validation Loss: 4.28880531734588, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 85/100, Loss: 1.3461416739820228e-05\n",
      "Validation Loss: 4.324099327521253, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 86/100, Loss: 1.0399350368099173e-05\n",
      "Validation Loss: 4.329614266721667, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 87/100, Loss: 1.0880782597884794e-05\n",
      "Validation Loss: 4.301422433740906, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 88/100, Loss: 8.136029800690872e-06\n",
      "Validation Loss: 4.454655794327361, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 89/100, Loss: 1.0417359405323623e-05\n",
      "Validation Loss: 4.452050305034693, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 90/100, Loss: 8.545889687165223e-06\n",
      "Validation Loss: 4.361469251131591, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 91/100, Loss: 1.6191162077442794e-05\n",
      "Validation Loss: 4.352732534163806, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 92/100, Loss: 8.1895296150473e-06\n",
      "Validation Loss: 4.578292620183977, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 93/100, Loss: 1.1194522225347706e-05\n",
      "Validation Loss: 4.287744845072059, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 94/100, Loss: 1.821356112448787e-05\n",
      "Validation Loss: 4.3356523296994665, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 95/100, Loss: 9.764236691485925e-06\n",
      "Validation Loss: 4.444469582804838, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 96/100, Loss: 8.595879472513465e-06\n",
      "Validation Loss: 4.476855254062684, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 97/100, Loss: 8.037868740965829e-06\n",
      "Validation Loss: 4.5031047841342415, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 98/100, Loss: 8.926767089671253e-06\n",
      "Validation Loss: 4.409078592398146, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 99/100, Loss: 1.3534748277995353e-05\n",
      "Validation Loss: 4.5241491112537915, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 100/100, Loss: 9.60149872793655e-06\n",
      "Validation Loss: 4.571516460904604, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Validation Loss: 1.633555621529619, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.7443609022556391, Recall: 0.7674418604651163, F1-score: 0.7557251908396947\n",
      "Confusion Matrix:\n",
      "[[18 34]\n",
      " [30 99]]\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch 1/100, Loss: 0.37065733317285776\n",
      "Validation Loss: 1.831215417633454, Validation Accuracy: 0.6857142857142857\n",
      "Precision: 0.6911764705882353, Recall: 0.8785046728971962, F1-score: 0.7736625514403292\n",
      "Model saved to ensemble_model_fold_1.pth\n",
      "Epoch 2/100, Loss: 0.046992470539407805\n",
      "Validation Loss: 2.096521665652593, Validation Accuracy: 0.7828571428571428\n",
      "Precision: 0.7948717948717948, Recall: 0.8691588785046729, F1-score: 0.8303571428571429\n",
      "Epoch 3/100, Loss: 0.03214771347605468\n",
      "Validation Loss: 2.277744693060716, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.75, Recall: 0.8411214953271028, F1-score: 0.7929515418502202\n",
      "Epoch 4/100, Loss: 0.006341247239712781\n",
      "Validation Loss: 2.3201580196619034, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 5/100, Loss: 0.0045549970994519145\n",
      "Validation Loss: 2.4772109736998877, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7521367521367521, Recall: 0.822429906542056, F1-score: 0.7857142857142857\n",
      "Epoch 6/100, Loss: 0.002576344936642272\n",
      "Validation Loss: 2.5582405949632325, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7521367521367521, Recall: 0.822429906542056, F1-score: 0.7857142857142857\n",
      "Epoch 7/100, Loss: 0.0020288826623679292\n",
      "Validation Loss: 2.6686889082193375, Validation Accuracy: 0.7142857142857143\n",
      "Precision: 0.7394957983193278, Recall: 0.822429906542056, F1-score: 0.7787610619469026\n",
      "Epoch 8/100, Loss: 0.001678294002279775\n",
      "Validation Loss: 2.768620051443577, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 9/100, Loss: 0.0010220244977669306\n",
      "Validation Loss: 2.869794949889183, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 10/100, Loss: 0.0008410549788398688\n",
      "Validation Loss: 2.9174147273103395, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 11/100, Loss: 0.0007384913744014435\n",
      "Validation Loss: 2.8952014669775963, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 12/100, Loss: 0.0007841680350490302\n",
      "Validation Loss: 2.9576653242111206, Validation Accuracy: 0.7142857142857143\n",
      "Precision: 0.7394957983193278, Recall: 0.822429906542056, F1-score: 0.7787610619469026\n",
      "Epoch 13/100, Loss: 0.0007827220805817584\n",
      "Validation Loss: 2.979109913110733, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 14/100, Loss: 0.0008215881005071424\n",
      "Validation Loss: 3.512504623581966, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7586206896551724, Recall: 0.822429906542056, F1-score: 0.7892376681614349\n",
      "Epoch 15/100, Loss: 0.0007817454186351824\n",
      "Validation Loss: 3.300457254052162, Validation Accuracy: 0.72\n",
      "Precision: 0.7543859649122807, Recall: 0.8037383177570093, F1-score: 0.7782805429864253\n",
      "Epoch 16/100, Loss: 0.0004594781319156027\n",
      "Validation Loss: 3.3672688230872154, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7586206896551724, Recall: 0.822429906542056, F1-score: 0.7892376681614349\n",
      "Epoch 17/100, Loss: 0.0003585334370654891\n",
      "Validation Loss: 3.3070426980654397, Validation Accuracy: 0.72\n",
      "Precision: 0.7543859649122807, Recall: 0.8037383177570093, F1-score: 0.7782805429864253\n",
      "Epoch 18/100, Loss: 0.00033668052822122263\n",
      "Validation Loss: 3.42041643957297, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7586206896551724, Recall: 0.822429906542056, F1-score: 0.7892376681614349\n",
      "Epoch 19/100, Loss: 0.0003362137376067646\n",
      "Validation Loss: 3.4847002401947975, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 20/100, Loss: 0.00035037839487965056\n",
      "Validation Loss: 3.504122487579783, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 21/100, Loss: 0.0003616580883848049\n",
      "Validation Loss: 3.4625109868745008, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 22/100, Loss: 0.00023159492464704576\n",
      "Validation Loss: 3.5438522063195705, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 23/100, Loss: 0.00018540628608813373\n",
      "Validation Loss: 3.5154825262725353, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 24/100, Loss: 0.00016021306237234967\n",
      "Validation Loss: 3.5364028153320155, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 25/100, Loss: 0.0001585205278615831\n",
      "Validation Loss: 3.594464642306169, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 26/100, Loss: 0.00019874119834639714\n",
      "Validation Loss: 3.5615655444562435, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 27/100, Loss: 0.00020614822642528452\n",
      "Validation Loss: 3.5372837521135807, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 28/100, Loss: 0.0001299470346225462\n",
      "Validation Loss: 3.559159933278958, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 29/100, Loss: 0.00012531344433834116\n",
      "Validation Loss: 3.6501803435385227, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 30/100, Loss: 0.00012001493655589002\n",
      "Validation Loss: 3.5751609777410827, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 31/100, Loss: 0.00012324827578898598\n",
      "Validation Loss: 3.605253248165051, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 32/100, Loss: 0.00011230381774870087\n",
      "Validation Loss: 3.7170382104814053, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 33/100, Loss: 0.00015202825982404042\n",
      "Validation Loss: 3.7807535665730634, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 34/100, Loss: 0.0001113213527711802\n",
      "Validation Loss: 3.829506659259399, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 35/100, Loss: 9.56413150750753e-05\n",
      "Validation Loss: 3.849739156663418, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 36/100, Loss: 0.00010181759938158545\n",
      "Validation Loss: 3.810816107938687, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 37/100, Loss: 9.398587455204203e-05\n",
      "Validation Loss: 3.8440817644198737, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 38/100, Loss: 9.476387236873052e-05\n",
      "Validation Loss: 3.871996401498715, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 39/100, Loss: 7.682334773069972e-05\n",
      "Validation Loss: 3.995353221272429, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 40/100, Loss: 8.155424103506448e-05\n",
      "Validation Loss: 3.959705593685309, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 41/100, Loss: 9.925797134494967e-05\n",
      "Validation Loss: 3.9058361450831094, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 42/100, Loss: 4.9779146886900584e-05\n",
      "Validation Loss: 3.845404883225759, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 43/100, Loss: 6.249585655382361e-05\n",
      "Validation Loss: 3.983153197914362, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 44/100, Loss: 4.75512190689642e-05\n",
      "Validation Loss: 4.008257892603676, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 45/100, Loss: 4.9748001922959396e-05\n",
      "Validation Loss: 3.9322297958036265, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 46/100, Loss: 5.869922805838238e-05\n",
      "Validation Loss: 3.9558331494530043, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 47/100, Loss: 7.499839149952929e-05\n",
      "Validation Loss: 3.9294526322434344, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 48/100, Loss: 4.905672067441932e-05\n",
      "Validation Loss: 3.968483150626222, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 49/100, Loss: 4.788214192785745e-05\n",
      "Validation Loss: 3.9580322206020355, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 50/100, Loss: 4.343708682578532e-05\n",
      "Validation Loss: 3.9523313169678054, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 51/100, Loss: 4.520487405793953e-05\n",
      "Validation Loss: 4.067694554726283, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 52/100, Loss: 4.7034032945703075e-05\n",
      "Validation Loss: 4.058009495337804, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 53/100, Loss: 5.3208650371061594e-05\n",
      "Validation Loss: 4.029624628523986, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 54/100, Loss: 3.7043200781757456e-05\n",
      "Validation Loss: 4.093727829555671, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 55/100, Loss: 2.45389925339623e-05\n",
      "Validation Loss: 3.978362303227186, Validation Accuracy: 0.72\n",
      "Precision: 0.7457627118644068, Recall: 0.822429906542056, F1-score: 0.7822222222222223\n",
      "Epoch 56/100, Loss: 3.939020500768701e-05\n",
      "Validation Loss: 4.097585521638393, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 57/100, Loss: 2.9158179652692223e-05\n",
      "Validation Loss: 4.13319977124532, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 58/100, Loss: 4.6717900043328577e-05\n",
      "Validation Loss: 4.0393833971271915, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 59/100, Loss: 3.7240353047233533e-05\n",
      "Validation Loss: 4.094558796534936, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 60/100, Loss: 2.5679601639794214e-05\n",
      "Validation Loss: 4.164361200605829, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 61/100, Loss: 3.0975933865325565e-05\n",
      "Validation Loss: 4.196495211372773, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 62/100, Loss: 2.945052584379937e-05\n",
      "Validation Loss: 4.131829657281439, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 63/100, Loss: 2.7709415566808577e-05\n",
      "Validation Loss: 4.081102007379134, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7542372881355932, Recall: 0.8317757009345794, F1-score: 0.7911111111111111\n",
      "Epoch 64/100, Loss: 3.442689561975835e-05\n",
      "Validation Loss: 4.151474245513479, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 65/100, Loss: 3.065766509043518e-05\n",
      "Validation Loss: 4.105152318254113, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 66/100, Loss: 3.2348504029518686e-05\n",
      "Validation Loss: 4.243575106064479, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 67/100, Loss: 2.2765475643874804e-05\n",
      "Validation Loss: 4.211093407124281, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 68/100, Loss: 1.627839208140358e-05\n",
      "Validation Loss: 4.1661471063271165, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 69/100, Loss: 2.222936521908044e-05\n",
      "Validation Loss: 4.208159853393833, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 70/100, Loss: 1.5675791956937246e-05\n",
      "Validation Loss: 4.146006662398577, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7542372881355932, Recall: 0.8317757009345794, F1-score: 0.7911111111111111\n",
      "Epoch 71/100, Loss: 1.7861484612543183e-05\n",
      "Validation Loss: 4.1547297242407994, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7542372881355932, Recall: 0.8317757009345794, F1-score: 0.7911111111111111\n",
      "Epoch 72/100, Loss: 1.859352565484566e-05\n",
      "Validation Loss: 4.129508001419405, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7542372881355932, Recall: 0.8317757009345794, F1-score: 0.7911111111111111\n",
      "Epoch 73/100, Loss: 2.5667750276644103e-05\n",
      "Validation Loss: 4.167298677377403, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 74/100, Loss: 2.6914381810646166e-05\n",
      "Validation Loss: 3.8577151584128537, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 75/100, Loss: 2.7746598040797228e-05\n",
      "Validation Loss: 3.9294511392557374, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 76/100, Loss: 2.4731690444923515e-05\n",
      "Validation Loss: 3.9556965360728404, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 77/100, Loss: 1.6181400103694916e-05\n",
      "Validation Loss: 4.033601250421877, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 78/100, Loss: 2.343088765677237e-05\n",
      "Validation Loss: 4.0477347816340625, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 79/100, Loss: 2.714747588091389e-05\n",
      "Validation Loss: 4.0461616710138815, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 80/100, Loss: 1.2531114433519027e-05\n",
      "Validation Loss: 4.052543140792598, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 81/100, Loss: 1.8225635383117833e-05\n",
      "Validation Loss: 3.928227435797453, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 82/100, Loss: 2.2383686480035674e-05\n",
      "Validation Loss: 4.149494258997341, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 83/100, Loss: 1.45690290741148e-05\n",
      "Validation Loss: 4.1146664675325155, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 84/100, Loss: 2.0225382167874766e-05\n",
      "Validation Loss: 4.297041354584508, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 85/100, Loss: 1.4149953373158533e-05\n",
      "Validation Loss: 4.102940979413688, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7542372881355932, Recall: 0.8317757009345794, F1-score: 0.7911111111111111\n",
      "Epoch 86/100, Loss: 1.6624742225227845e-05\n",
      "Validation Loss: 4.2150616033468395, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 87/100, Loss: 1.4932760860138691e-05\n",
      "Validation Loss: 4.109631454882522, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 88/100, Loss: 1.4533437694789578e-05\n",
      "Validation Loss: 4.1471231007017195, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7542372881355932, Recall: 0.8317757009345794, F1-score: 0.7911111111111111\n",
      "Epoch 89/100, Loss: 1.6932431802156127e-05\n",
      "Validation Loss: 4.19438665593043, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 90/100, Loss: 1.3811101740183554e-05\n",
      "Validation Loss: 4.171093257299314, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7542372881355932, Recall: 0.8317757009345794, F1-score: 0.7911111111111111\n",
      "Epoch 91/100, Loss: 1.4048505725838822e-05\n",
      "Validation Loss: 4.1771912431965275, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 92/100, Loss: 1.240553310329536e-05\n",
      "Validation Loss: 4.302395523448165, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 93/100, Loss: 1.459126885450246e-05\n",
      "Validation Loss: 4.330638820072636, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 94/100, Loss: 1.0633784699602225e-05\n",
      "Validation Loss: 4.204003827180713, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7542372881355932, Recall: 0.8317757009345794, F1-score: 0.7911111111111111\n",
      "Epoch 95/100, Loss: 1.6023430937650573e-05\n",
      "Validation Loss: 4.240025186290343, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7542372881355932, Recall: 0.8317757009345794, F1-score: 0.7911111111111111\n",
      "Epoch 96/100, Loss: 9.13750787745471e-06\n",
      "Validation Loss: 4.20484542582805, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 97/100, Loss: 1.065284781394856e-05\n",
      "Validation Loss: 4.219960357062519, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 98/100, Loss: 1.1589680399974137e-05\n",
      "Validation Loss: 4.271915550343692, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 99/100, Loss: 1.3930272937538271e-05\n",
      "Validation Loss: 4.332781238209766, Validation Accuracy: 0.7257142857142858\n",
      "Precision: 0.7478991596638656, Recall: 0.8317757009345794, F1-score: 0.7876106194690266\n",
      "Epoch 100/100, Loss: 7.804491277833373e-06\n",
      "Validation Loss: 4.212203999360402, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7542372881355932, Recall: 0.8317757009345794, F1-score: 0.7911111111111111\n",
      "Validation Loss: 1.831215417633454, Validation Accuracy: 0.6857142857142857\n",
      "Precision: 0.6911764705882353, Recall: 0.8785046728971962, F1-score: 0.7736625514403292\n",
      "Confusion Matrix:\n",
      "[[26 42]\n",
      " [13 94]]\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch 1/100, Loss: 0.3881848837542445\n",
      "Validation Loss: 2.6013858007887998, Validation Accuracy: 0.6774193548387096\n",
      "Precision: 0.6642857142857143, Recall: 0.8773584905660378, F1-score: 0.7560975609756098\n",
      "Model saved to ensemble_model_fold_2.pth\n",
      "Epoch 2/100, Loss: 0.08481755119343386\n",
      "Validation Loss: 3.34221267948548, Validation Accuracy: 0.6612903225806451\n",
      "Precision: 0.7009345794392523, Recall: 0.7075471698113207, F1-score: 0.704225352112676\n",
      "Epoch 3/100, Loss: 0.029714746196987107\n",
      "Validation Loss: 3.7289888535936675, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 4/100, Loss: 0.021386327019778644\n",
      "Validation Loss: 3.6149474680423737, Validation Accuracy: 0.6505376344086021\n",
      "Precision: 0.7029702970297029, Recall: 0.6698113207547169, F1-score: 0.6859903381642513\n",
      "Epoch 5/100, Loss: 0.03345867790055005\n",
      "Validation Loss: 3.3327664410074553, Validation Accuracy: 0.7365591397849462\n",
      "Precision: 0.7355371900826446, Recall: 0.839622641509434, F1-score: 0.7841409691629956\n",
      "Epoch 6/100, Loss: 0.0022011949110568216\n",
      "Validation Loss: 3.472647594908873, Validation Accuracy: 0.7150537634408602\n",
      "Precision: 0.7264957264957265, Recall: 0.8018867924528302, F1-score: 0.7623318385650224\n",
      "Epoch 7/100, Loss: 0.0012892145946921119\n",
      "Validation Loss: 3.583327370385329, Validation Accuracy: 0.6774193548387096\n",
      "Precision: 0.7169811320754716, Recall: 0.7169811320754716, F1-score: 0.7169811320754716\n",
      "Epoch 8/100, Loss: 0.0011636328675497982\n",
      "Validation Loss: 3.7419039979577065, Validation Accuracy: 0.6666666666666666\n",
      "Precision: 0.6896551724137931, Recall: 0.7547169811320755, F1-score: 0.7207207207207207\n",
      "Epoch 9/100, Loss: 0.0010655779264823195\n",
      "Validation Loss: 3.7445481047034264, Validation Accuracy: 0.6505376344086021\n",
      "Precision: 0.7029702970297029, Recall: 0.6698113207547169, F1-score: 0.6859903381642513\n",
      "Epoch 10/100, Loss: 0.00046987941298463437\n",
      "Validation Loss: 3.7467478861411414, Validation Accuracy: 0.6344086021505376\n",
      "Precision: 0.6862745098039216, Recall: 0.660377358490566, F1-score: 0.6730769230769231\n",
      "Epoch 11/100, Loss: 0.000502542006074691\n",
      "Validation Loss: 3.717710760732492, Validation Accuracy: 0.6505376344086021\n",
      "Precision: 0.6990291262135923, Recall: 0.6792452830188679, F1-score: 0.6889952153110048\n",
      "Epoch 12/100, Loss: 0.00032522571351970936\n",
      "Validation Loss: 3.846539539595445, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7142857142857143, Recall: 0.7547169811320755, F1-score: 0.7339449541284404\n",
      "Epoch 13/100, Loss: 0.00033779465316759644\n",
      "Validation Loss: 3.84046088407437, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.7117117117117117, Recall: 0.7452830188679245, F1-score: 0.728110599078341\n",
      "Epoch 14/100, Loss: 0.0003092337760695803\n",
      "Validation Loss: 3.8519932702183723, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7142857142857143, Recall: 0.7547169811320755, F1-score: 0.7339449541284404\n",
      "Epoch 15/100, Loss: 0.0003212531720275062\n",
      "Validation Loss: 3.8135441665848098, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.7117117117117117, Recall: 0.7452830188679245, F1-score: 0.728110599078341\n",
      "Epoch 16/100, Loss: 0.00020667734848226851\n",
      "Validation Loss: 3.8134810626506805, Validation Accuracy: 0.6612903225806451\n",
      "Precision: 0.7009345794392523, Recall: 0.7075471698113207, F1-score: 0.704225352112676\n",
      "Epoch 17/100, Loss: 0.00037669609912427404\n",
      "Validation Loss: 3.8807930101950965, Validation Accuracy: 0.6612903225806451\n",
      "Precision: 0.7087378640776699, Recall: 0.6886792452830188, F1-score: 0.6985645933014354\n",
      "Epoch 18/100, Loss: 0.0001547803597266769\n",
      "Validation Loss: 3.9455585231383643, Validation Accuracy: 0.6774193548387096\n",
      "Precision: 0.7129629629629629, Recall: 0.7264150943396226, F1-score: 0.719626168224299\n",
      "Epoch 19/100, Loss: 0.00015811693623390966\n",
      "Validation Loss: 4.048972929517428, Validation Accuracy: 0.6612903225806451\n",
      "Precision: 0.7047619047619048, Recall: 0.6981132075471698, F1-score: 0.7014218009478673\n",
      "Epoch 20/100, Loss: 0.00018297885200831607\n",
      "Validation Loss: 4.022157112757365, Validation Accuracy: 0.6774193548387096\n",
      "Precision: 0.7129629629629629, Recall: 0.7264150943396226, F1-score: 0.719626168224299\n",
      "Epoch 21/100, Loss: 0.00017937027195102928\n",
      "Validation Loss: 4.008188645044963, Validation Accuracy: 0.6612903225806451\n",
      "Precision: 0.7009345794392523, Recall: 0.7075471698113207, F1-score: 0.704225352112676\n",
      "Epoch 22/100, Loss: 0.00021410712997749215\n",
      "Validation Loss: 4.031581411759059, Validation Accuracy: 0.6559139784946236\n",
      "Precision: 0.7019230769230769, Recall: 0.6886792452830188, F1-score: 0.6952380952380952\n",
      "Epoch 23/100, Loss: 0.00022379000363770274\n",
      "Validation Loss: 4.038898189862569, Validation Accuracy: 0.6612903225806451\n",
      "Precision: 0.7047619047619048, Recall: 0.6981132075471698, F1-score: 0.7014218009478673\n",
      "Epoch 24/100, Loss: 0.00011420707337113829\n",
      "Validation Loss: 4.069816301266353, Validation Accuracy: 0.6559139784946236\n",
      "Precision: 0.7058823529411765, Recall: 0.6792452830188679, F1-score: 0.6923076923076923\n",
      "Epoch 25/100, Loss: 0.00014651109726552627\n",
      "Validation Loss: 4.128834158182144, Validation Accuracy: 0.6720430107526881\n",
      "Precision: 0.7102803738317757, Recall: 0.7169811320754716, F1-score: 0.7136150234741784\n",
      "Epoch 26/100, Loss: 0.00027519959782296155\n",
      "Validation Loss: 4.052942710618178, Validation Accuracy: 0.7150537634408602\n",
      "Precision: 0.7345132743362832, Recall: 0.7830188679245284, F1-score: 0.7579908675799086\n",
      "Epoch 27/100, Loss: 9.829254110134873e-05\n",
      "Validation Loss: 4.113520711660385, Validation Accuracy: 0.7150537634408602\n",
      "Precision: 0.7345132743362832, Recall: 0.7830188679245284, F1-score: 0.7579908675799086\n",
      "Epoch 28/100, Loss: 0.00011618110040719405\n",
      "Validation Loss: 4.193509717782338, Validation Accuracy: 0.7150537634408602\n",
      "Precision: 0.7345132743362832, Recall: 0.7830188679245284, F1-score: 0.7579908675799086\n",
      "Epoch 29/100, Loss: 0.00013796466837353213\n",
      "Validation Loss: 4.135454569011927, Validation Accuracy: 0.7150537634408602\n",
      "Precision: 0.7345132743362832, Recall: 0.7830188679245284, F1-score: 0.7579908675799086\n",
      "Epoch 30/100, Loss: 8.75111014752387e-05\n",
      "Validation Loss: 4.205566840867202, Validation Accuracy: 0.7150537634408602\n",
      "Precision: 0.7345132743362832, Recall: 0.7830188679245284, F1-score: 0.7579908675799086\n",
      "Epoch 31/100, Loss: 8.864582014211919e-05\n",
      "Validation Loss: 4.225394596656163, Validation Accuracy: 0.7150537634408602\n",
      "Precision: 0.7345132743362832, Recall: 0.7830188679245284, F1-score: 0.7579908675799086\n",
      "Epoch 32/100, Loss: 0.00011831304652787367\n",
      "Validation Loss: 4.1808450147509575, Validation Accuracy: 0.7096774193548387\n",
      "Precision: 0.7280701754385965, Recall: 0.7830188679245284, F1-score: 0.7545454545454545\n",
      "Epoch 33/100, Loss: 0.00010739293684972988\n",
      "Validation Loss: 4.1922326895097894, Validation Accuracy: 0.7096774193548387\n",
      "Precision: 0.7280701754385965, Recall: 0.7830188679245284, F1-score: 0.7545454545454545\n",
      "Epoch 34/100, Loss: 0.00011456104270675856\n",
      "Validation Loss: 4.241010569036007, Validation Accuracy: 0.7150537634408602\n",
      "Precision: 0.7345132743362832, Recall: 0.7830188679245284, F1-score: 0.7579908675799086\n",
      "Epoch 35/100, Loss: 6.884084891585947e-05\n",
      "Validation Loss: 4.252049817393224, Validation Accuracy: 0.7150537634408602\n",
      "Precision: 0.7345132743362832, Recall: 0.7830188679245284, F1-score: 0.7579908675799086\n",
      "Epoch 36/100, Loss: 6.96451906681735e-05\n",
      "Validation Loss: 4.2331887657443685, Validation Accuracy: 0.7150537634408602\n",
      "Precision: 0.7345132743362832, Recall: 0.7830188679245284, F1-score: 0.7579908675799086\n",
      "Epoch 37/100, Loss: 7.795229562646e-05\n",
      "Validation Loss: 4.261573418974876, Validation Accuracy: 0.7096774193548387\n",
      "Precision: 0.7280701754385965, Recall: 0.7830188679245284, F1-score: 0.7545454545454545\n",
      "Epoch 38/100, Loss: 5.36234131776799e-05\n",
      "Validation Loss: 4.2579387202858925, Validation Accuracy: 0.7150537634408602\n",
      "Precision: 0.7345132743362832, Recall: 0.7830188679245284, F1-score: 0.7579908675799086\n",
      "Epoch 39/100, Loss: 6.16305307564365e-05\n",
      "Validation Loss: 4.184838142246008, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7297297297297297, Recall: 0.7641509433962265, F1-score: 0.7465437788018433\n",
      "Epoch 40/100, Loss: 5.956702033197795e-05\n",
      "Validation Loss: 4.259127375980218, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7297297297297297, Recall: 0.7641509433962265, F1-score: 0.7465437788018433\n",
      "Epoch 41/100, Loss: 7.206169949114383e-05\n",
      "Validation Loss: 4.243061383565267, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 42/100, Loss: 7.474094376410297e-05\n",
      "Validation Loss: 4.279464454700549, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 43/100, Loss: 6.883210361744811e-05\n",
      "Validation Loss: 4.2415865163008375, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 44/100, Loss: 4.800662648563048e-05\n",
      "Validation Loss: 4.266817269225915, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7297297297297297, Recall: 0.7641509433962265, F1-score: 0.7465437788018433\n",
      "Epoch 45/100, Loss: 4.7811998512633146e-05\n",
      "Validation Loss: 4.240653940786918, Validation Accuracy: 0.7096774193548387\n",
      "Precision: 0.7321428571428571, Recall: 0.7735849056603774, F1-score: 0.7522935779816514\n",
      "Epoch 46/100, Loss: 4.462866306198521e-05\n",
      "Validation Loss: 4.2585527040064335, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7297297297297297, Recall: 0.7641509433962265, F1-score: 0.7465437788018433\n",
      "Epoch 47/100, Loss: 5.318332610926291e-05\n",
      "Validation Loss: 4.30036740253369, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 48/100, Loss: 3.9830343818418136e-05\n",
      "Validation Loss: 4.36812808116277, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 49/100, Loss: 6.418100980691104e-05\n",
      "Validation Loss: 4.4105960590143996, Validation Accuracy: 0.7096774193548387\n",
      "Precision: 0.7321428571428571, Recall: 0.7735849056603774, F1-score: 0.7522935779816514\n",
      "Epoch 50/100, Loss: 4.245239956901514e-05\n",
      "Validation Loss: 4.41210937872529, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 51/100, Loss: 3.809009120203655e-05\n",
      "Validation Loss: 4.339227224389712, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 52/100, Loss: 4.036235035205967e-05\n",
      "Validation Loss: 4.4151460354526835, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 53/100, Loss: 4.2601073734734506e-05\n",
      "Validation Loss: 4.461463664968808, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 54/100, Loss: 5.659918954374158e-05\n",
      "Validation Loss: 4.452866781502962, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 55/100, Loss: 6.163693996086295e-05\n",
      "Validation Loss: 4.51002765695254, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 56/100, Loss: 5.016283452471034e-05\n",
      "Validation Loss: 4.497631835440795, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 57/100, Loss: 3.2571408336086925e-05\n",
      "Validation Loss: 4.5053084418177605, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 58/100, Loss: 3.917561605604192e-05\n",
      "Validation Loss: 4.509381872912248, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 59/100, Loss: 3.67847118122692e-05\n",
      "Validation Loss: 4.600673860559861, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 60/100, Loss: 3.1966870452038165e-05\n",
      "Validation Loss: 4.55836983397603, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 61/100, Loss: 3.3166255443954164e-05\n",
      "Validation Loss: 4.627992733071248, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 62/100, Loss: 2.8434281126976657e-05\n",
      "Validation Loss: 4.518541214366754, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 63/100, Loss: 2.5485892905408036e-05\n",
      "Validation Loss: 4.461281888186932, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 64/100, Loss: 3.0734228221381464e-05\n",
      "Validation Loss: 4.609655197709799, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 65/100, Loss: 2.7223093300203043e-05\n",
      "Validation Loss: 4.643031681577365, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 66/100, Loss: 3.776725759892704e-05\n",
      "Validation Loss: 4.577019489059846, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 67/100, Loss: 3.36558092124406e-05\n",
      "Validation Loss: 4.66614942997694, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 68/100, Loss: 2.5645457576217723e-05\n",
      "Validation Loss: 4.521389710406463, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 69/100, Loss: 4.451873341082546e-05\n",
      "Validation Loss: 4.618032115201156, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 70/100, Loss: 2.514469858757214e-05\n",
      "Validation Loss: 4.6014777819315595, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 71/100, Loss: 3.0411178721934107e-05\n",
      "Validation Loss: 4.640427947044373, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 72/100, Loss: 2.1520826898324685e-05\n",
      "Validation Loss: 4.650379913548629, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 73/100, Loss: 2.6683781882752555e-05\n",
      "Validation Loss: 4.574315384030342, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 74/100, Loss: 1.8212319948437045e-05\n",
      "Validation Loss: 4.68077223499616, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 75/100, Loss: 1.4446488454685399e-05\n",
      "Validation Loss: 4.688056382040183, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 76/100, Loss: 2.900034849299497e-05\n",
      "Validation Loss: 4.599823921918869, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 77/100, Loss: 1.9824904477161454e-05\n",
      "Validation Loss: 4.709910632421573, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 78/100, Loss: 2.416396027153193e-05\n",
      "Validation Loss: 4.672863299647967, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 79/100, Loss: 2.3745253901807928e-05\n",
      "Validation Loss: 4.694632930060227, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 80/100, Loss: 1.604077723390181e-05\n",
      "Validation Loss: 4.581705083449681, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 81/100, Loss: 2.0864629753702957e-05\n",
      "Validation Loss: 4.718611997862657, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 82/100, Loss: 1.236681375379097e-05\n",
      "Validation Loss: 4.718314131100972, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 83/100, Loss: 3.130639744123679e-05\n",
      "Validation Loss: 4.83862080052495, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 84/100, Loss: 1.8532065363766986e-05\n",
      "Validation Loss: 4.715609811246395, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 85/100, Loss: 2.3605117034956418e-05\n",
      "Validation Loss: 4.7155307456851006, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 86/100, Loss: 1.948856840527924e-05\n",
      "Validation Loss: 4.819281868636608, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7247706422018348, Recall: 0.7452830188679245, F1-score: 0.7348837209302326\n",
      "Epoch 87/100, Loss: 1.7429239385080564e-05\n",
      "Validation Loss: 4.78381022810936, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 88/100, Loss: 4.0697829272554977e-05\n",
      "Validation Loss: 4.805143088102341, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 89/100, Loss: 2.2866382915746424e-05\n",
      "Validation Loss: 4.886211487154166, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 90/100, Loss: 2.3492673002796966e-05\n",
      "Validation Loss: 4.819985253115495, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 91/100, Loss: 1.7977574595799222e-05\n",
      "Validation Loss: 4.945010349154472, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 92/100, Loss: 1.0673253188227724e-05\n",
      "Validation Loss: 4.894517419238885, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 93/100, Loss: 1.991020134065972e-05\n",
      "Validation Loss: 4.7783389538526535, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 94/100, Loss: 1.7559175992924263e-05\n",
      "Validation Loss: 4.953516458471616, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 95/100, Loss: 1.2426813227032577e-05\n",
      "Validation Loss: 4.997612461447716, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 96/100, Loss: 1.001944349473168e-05\n",
      "Validation Loss: 4.846783647934596, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 97/100, Loss: 1.6240636580751772e-05\n",
      "Validation Loss: 4.829978781441848, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 98/100, Loss: 1.362965542532161e-05\n",
      "Validation Loss: 4.94594357162714, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Epoch 99/100, Loss: 1.7151142296019845e-05\n",
      "Validation Loss: 4.849402827521165, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.719626168224299, Recall: 0.7264150943396226, F1-score: 0.7230046948356808\n",
      "Epoch 100/100, Loss: 1.6072583852277944e-05\n",
      "Validation Loss: 4.921813281873862, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7222222222222222, Recall: 0.7358490566037735, F1-score: 0.7289719626168224\n",
      "Validation Loss: 2.6013858007887998, Validation Accuracy: 0.6774193548387096\n",
      "Precision: 0.6642857142857143, Recall: 0.8773584905660378, F1-score: 0.7560975609756098\n",
      "Confusion Matrix:\n",
      "[[33 47]\n",
      " [13 93]]\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch 1/100, Loss: 0.24097937225202296\n",
      "Validation Loss: 12.352997015097312, Validation Accuracy: 0.7208121827411168\n",
      "Precision: 0.96875, Recall: 0.6413793103448275, F1-score: 0.7717842323651453\n",
      "Model saved to ensemble_model_fold_3.pth\n",
      "Epoch 2/100, Loss: 0.007880009342140207\n",
      "Validation Loss: 16.445509573519562, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.8532110091743119, Recall: 0.6413793103448275, F1-score: 0.7322834645669292\n",
      "Epoch 3/100, Loss: 0.0033684868855440677\n",
      "Validation Loss: 16.738752329040185, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.8532110091743119, Recall: 0.6413793103448275, F1-score: 0.7322834645669292\n",
      "Epoch 4/100, Loss: 0.0021762633174754833\n",
      "Validation Loss: 19.039783264872053, Validation Accuracy: 0.6903553299492385\n",
      "Precision: 0.9117647058823529, Recall: 0.6413793103448275, F1-score: 0.7530364372469636\n",
      "Epoch 5/100, Loss: 0.001283521415435492\n",
      "Validation Loss: 16.99072567444403, Validation Accuracy: 0.6142131979695431\n",
      "Precision: 0.8876404494382022, Recall: 0.5448275862068965, F1-score: 0.6752136752136753\n",
      "Epoch 6/100, Loss: 0.0008586758397844582\n",
      "Validation Loss: 17.50044282302094, Validation Accuracy: 0.6802030456852792\n",
      "Precision: 0.8942307692307693, Recall: 0.6413793103448275, F1-score: 0.7469879518072289\n",
      "Epoch 7/100, Loss: 0.0008038284495341941\n",
      "Validation Loss: 17.64293229724613, Validation Accuracy: 0.6802030456852792\n",
      "Precision: 0.8942307692307693, Recall: 0.6413793103448275, F1-score: 0.7469879518072289\n",
      "Epoch 8/100, Loss: 0.008437302703593256\n",
      "Validation Loss: 15.027993031794072, Validation Accuracy: 0.5989847715736041\n",
      "Precision: 0.8586956521739131, Recall: 0.5448275862068965, F1-score: 0.6666666666666666\n",
      "Epoch 9/100, Loss: 0.008468710685974656\n",
      "Validation Loss: 13.980990305656244, Validation Accuracy: 0.5583756345177665\n",
      "Precision: 0.8020833333333334, Recall: 0.5310344827586206, F1-score: 0.6390041493775933\n",
      "Epoch 10/100, Loss: 0.012009632037612997\n",
      "Validation Loss: 9.43770546367575, Validation Accuracy: 0.5532994923857868\n",
      "Precision: 0.7522123893805309, Recall: 0.5862068965517241, F1-score: 0.6589147286821705\n",
      "Model saved to ensemble_model_fold_3.pth\n",
      "Epoch 11/100, Loss: 0.028384747637270873\n",
      "Validation Loss: 6.414728164672852, Validation Accuracy: 0.4873096446700508\n",
      "Precision: 0.72, Recall: 0.496551724137931, F1-score: 0.5877551020408164\n",
      "Model saved to ensemble_model_fold_3.pth\n",
      "Epoch 12/100, Loss: 0.0018146540320837328\n",
      "Validation Loss: 7.700023685182844, Validation Accuracy: 0.47715736040609136\n",
      "Precision: 0.7142857142857143, Recall: 0.4827586206896552, F1-score: 0.5761316872427984\n",
      "Epoch 13/100, Loss: 0.0010060968977541052\n",
      "Validation Loss: 8.735414573124476, Validation Accuracy: 0.4720812182741117\n",
      "Precision: 0.711340206185567, Recall: 0.47586206896551725, F1-score: 0.5702479338842975\n",
      "Epoch 14/100, Loss: 0.0003083334410428999\n",
      "Validation Loss: 8.919630629675728, Validation Accuracy: 0.4720812182741117\n",
      "Precision: 0.711340206185567, Recall: 0.47586206896551725, F1-score: 0.5702479338842975\n",
      "Epoch 15/100, Loss: 0.00042102582090800905\n",
      "Validation Loss: 8.992539984839302, Validation Accuracy: 0.4720812182741117\n",
      "Precision: 0.711340206185567, Recall: 0.47586206896551725, F1-score: 0.5702479338842975\n",
      "Epoch 16/100, Loss: 0.00019779894218648528\n",
      "Validation Loss: 9.258844716208321, Validation Accuracy: 0.47715736040609136\n",
      "Precision: 0.7142857142857143, Recall: 0.4827586206896552, F1-score: 0.5761316872427984\n",
      "Epoch 17/100, Loss: 0.00018338485313051933\n",
      "Validation Loss: 9.420400312968663, Validation Accuracy: 0.4720812182741117\n",
      "Precision: 0.711340206185567, Recall: 0.47586206896551725, F1-score: 0.5702479338842975\n",
      "Epoch 18/100, Loss: 0.0001645772360348019\n",
      "Validation Loss: 9.501667056764875, Validation Accuracy: 0.4720812182741117\n",
      "Precision: 0.711340206185567, Recall: 0.47586206896551725, F1-score: 0.5702479338842975\n",
      "Epoch 19/100, Loss: 0.00012008450547303558\n",
      "Validation Loss: 9.439013413020543, Validation Accuracy: 0.4720812182741117\n",
      "Precision: 0.711340206185567, Recall: 0.47586206896551725, F1-score: 0.5702479338842975\n",
      "Epoch 20/100, Loss: 0.0001141796751653601\n",
      "Validation Loss: 9.440803050994873, Validation Accuracy: 0.4720812182741117\n",
      "Precision: 0.711340206185567, Recall: 0.47586206896551725, F1-score: 0.5702479338842975\n",
      "Epoch 21/100, Loss: 0.00012211072862555739\n",
      "Validation Loss: 9.11361929348537, Validation Accuracy: 0.467005076142132\n",
      "Precision: 0.7083333333333334, Recall: 0.4689655172413793, F1-score: 0.5643153526970954\n",
      "Epoch 22/100, Loss: 0.0001174024180509529\n",
      "Validation Loss: 9.607232809066772, Validation Accuracy: 0.4720812182741117\n",
      "Precision: 0.711340206185567, Recall: 0.47586206896551725, F1-score: 0.5702479338842975\n",
      "Epoch 23/100, Loss: 0.009109755874760594\n",
      "Validation Loss: 12.626120431082589, Validation Accuracy: 0.45685279187817257\n",
      "Precision: 0.7021276595744681, Recall: 0.45517241379310347, F1-score: 0.5523012552301255\n",
      "Epoch 24/100, Loss: 0.04434121574907598\n",
      "Validation Loss: 25.58647960850171, Validation Accuracy: 0.5482233502538071\n",
      "Precision: 0.868421052631579, Recall: 0.45517241379310347, F1-score: 0.5972850678733032\n",
      "Epoch 25/100, Loss: 0.008580671756665955\n",
      "Validation Loss: 29.98206369791712, Validation Accuracy: 0.5482233502538071\n",
      "Precision: 0.8589743589743589, Recall: 0.46206896551724136, F1-score: 0.600896860986547\n",
      "Epoch 26/100, Loss: 0.0004455356279701543\n",
      "Validation Loss: 29.687198355793953, Validation Accuracy: 0.6040609137055838\n",
      "Precision: 0.8526315789473684, Recall: 0.5586206896551724, F1-score: 0.675\n",
      "Epoch 27/100, Loss: 8.706288682451084e-05\n",
      "Validation Loss: 29.20686779703413, Validation Accuracy: 0.5989847715736041\n",
      "Precision: 0.84375, Recall: 0.5586206896551724, F1-score: 0.6721991701244814\n",
      "Epoch 28/100, Loss: 0.00011287382255886769\n",
      "Validation Loss: 30.475444095475332, Validation Accuracy: 0.5989847715736041\n",
      "Precision: 0.84375, Recall: 0.5586206896551724, F1-score: 0.6721991701244814\n",
      "Epoch 29/100, Loss: 0.00010801919436668565\n",
      "Validation Loss: 29.986477641122683, Validation Accuracy: 0.5989847715736041\n",
      "Precision: 0.84375, Recall: 0.5586206896551724, F1-score: 0.6721991701244814\n",
      "Epoch 30/100, Loss: 6.875015092570418e-05\n",
      "Validation Loss: 30.87699078662055, Validation Accuracy: 0.5939086294416244\n",
      "Precision: 0.8350515463917526, Recall: 0.5586206896551724, F1-score: 0.6694214876033058\n",
      "Epoch 31/100, Loss: 5.713337155081414e-05\n",
      "Validation Loss: 29.856018545372145, Validation Accuracy: 0.5989847715736041\n",
      "Precision: 0.84375, Recall: 0.5586206896551724, F1-score: 0.6721991701244814\n",
      "Epoch 32/100, Loss: 4.0570781341860616e-05\n",
      "Validation Loss: 30.402592054435186, Validation Accuracy: 0.5989847715736041\n",
      "Precision: 0.84375, Recall: 0.5586206896551724, F1-score: 0.6721991701244814\n",
      "Epoch 33/100, Loss: 4.9121085832363555e-05\n",
      "Validation Loss: 28.400605438011034, Validation Accuracy: 0.6091370558375635\n",
      "Precision: 0.8617021276595744, Recall: 0.5586206896551724, F1-score: 0.6778242677824268\n",
      "Epoch 34/100, Loss: 4.203018873738529e-05\n",
      "Validation Loss: 29.359417359743798, Validation Accuracy: 0.6040609137055838\n",
      "Precision: 0.8526315789473684, Recall: 0.5586206896551724, F1-score: 0.675\n",
      "Epoch 35/100, Loss: 7.771966642167172e-05\n",
      "Validation Loss: 29.431132872189796, Validation Accuracy: 0.5989847715736041\n",
      "Precision: 0.84375, Recall: 0.5586206896551724, F1-score: 0.6721991701244814\n",
      "Epoch 36/100, Loss: 4.3288720291911886e-05\n",
      "Validation Loss: 29.83884718162673, Validation Accuracy: 0.5989847715736041\n",
      "Precision: 0.84375, Recall: 0.5586206896551724, F1-score: 0.6721991701244814\n",
      "Epoch 37/100, Loss: 3.7961978275546926e-05\n",
      "Validation Loss: 28.768508272511617, Validation Accuracy: 0.6040609137055838\n",
      "Precision: 0.8526315789473684, Recall: 0.5586206896551724, F1-score: 0.675\n",
      "Epoch 38/100, Loss: 6.30330225040628e-05\n",
      "Validation Loss: 30.332073130777903, Validation Accuracy: 0.5939086294416244\n",
      "Precision: 0.8350515463917526, Recall: 0.5586206896551724, F1-score: 0.6694214876033058\n",
      "Epoch 39/100, Loss: 2.3547243351629277e-05\n",
      "Validation Loss: 30.582674916301453, Validation Accuracy: 0.5939086294416244\n",
      "Precision: 0.8350515463917526, Recall: 0.5586206896551724, F1-score: 0.6694214876033058\n",
      "Epoch 40/100, Loss: 4.0513647813137745e-05\n",
      "Validation Loss: 29.949000307491847, Validation Accuracy: 0.5939086294416244\n",
      "Precision: 0.8350515463917526, Recall: 0.5586206896551724, F1-score: 0.6694214876033058\n",
      "Epoch 41/100, Loss: 3.67837643201104e-05\n",
      "Validation Loss: 26.301132227693284, Validation Accuracy: 0.583756345177665\n",
      "Precision: 0.8539325842696629, Recall: 0.5241379310344828, F1-score: 0.6495726495726496\n",
      "Epoch 42/100, Loss: 2.714474235195515e-05\n",
      "Validation Loss: 29.328184370483672, Validation Accuracy: 0.5989847715736041\n",
      "Precision: 0.84375, Recall: 0.5586206896551724, F1-score: 0.6721991701244814\n",
      "Epoch 43/100, Loss: 2.9029924566733218e-05\n",
      "Validation Loss: 31.160069125039236, Validation Accuracy: 0.5939086294416244\n",
      "Precision: 0.8350515463917526, Recall: 0.5586206896551724, F1-score: 0.6694214876033058\n",
      "Epoch 44/100, Loss: 3.64657151548838e-05\n",
      "Validation Loss: 28.159388099397933, Validation Accuracy: 0.6040609137055838\n",
      "Precision: 0.8526315789473684, Recall: 0.5586206896551724, F1-score: 0.675\n",
      "Epoch 45/100, Loss: 3.2770610014646685e-05\n",
      "Validation Loss: 30.970496173415864, Validation Accuracy: 0.5939086294416244\n",
      "Precision: 0.8350515463917526, Recall: 0.5586206896551724, F1-score: 0.6694214876033058\n",
      "Epoch 46/100, Loss: 3.5232973741491e-05\n",
      "Validation Loss: 30.05790969942297, Validation Accuracy: 0.5939086294416244\n",
      "Precision: 0.8350515463917526, Recall: 0.5586206896551724, F1-score: 0.6694214876033058\n",
      "Epoch 47/100, Loss: 0.0013796133367260193\n",
      "Validation Loss: 30.66411372593471, Validation Accuracy: 0.5279187817258884\n",
      "Precision: 0.825, Recall: 0.45517241379310347, F1-score: 0.5866666666666667\n",
      "Epoch 48/100, Loss: 0.297546174289657\n",
      "Validation Loss: 33.53471271480833, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 49/100, Loss: 0.2183966818783271\n",
      "Validation Loss: 29.043778283255442, Validation Accuracy: 0.583756345177665\n",
      "Precision: 0.8461538461538461, Recall: 0.5310344827586206, F1-score: 0.652542372881356\n",
      "Epoch 50/100, Loss: 0.008404247715304791\n",
      "Validation Loss: 26.461841412952968, Validation Accuracy: 0.5380710659898477\n",
      "Precision: 0.7454545454545455, Recall: 0.5655172413793104, F1-score: 0.6431372549019608\n",
      "Epoch 51/100, Loss: 0.00021091762053752441\n",
      "Validation Loss: 24.55925226211548, Validation Accuracy: 0.5126903553299492\n",
      "Precision: 0.7333333333333333, Recall: 0.5310344827586206, F1-score: 0.616\n",
      "Epoch 52/100, Loss: 0.00013187091911011825\n",
      "Validation Loss: 25.149612018040248, Validation Accuracy: 0.5126903553299492\n",
      "Precision: 0.7333333333333333, Recall: 0.5310344827586206, F1-score: 0.616\n",
      "Epoch 53/100, Loss: 8.463330986785422e-05\n",
      "Validation Loss: 26.437768731798446, Validation Accuracy: 0.5329949238578681\n",
      "Precision: 0.7523809523809524, Recall: 0.5448275862068965, F1-score: 0.632\n",
      "Epoch 54/100, Loss: 6.137755615516956e-05\n",
      "Validation Loss: 26.507426738739014, Validation Accuracy: 0.5228426395939086\n",
      "Precision: 0.7383177570093458, Recall: 0.5448275862068965, F1-score: 0.626984126984127\n",
      "Epoch 55/100, Loss: 0.00017475527942896937\n",
      "Validation Loss: 25.88226761136736, Validation Accuracy: 0.5431472081218274\n",
      "Precision: 0.7669902912621359, Recall: 0.5448275862068965, F1-score: 0.6370967741935484\n",
      "Epoch 56/100, Loss: 8.931963297224381e-05\n",
      "Validation Loss: 26.54825414930071, Validation Accuracy: 0.5279187817258884\n",
      "Precision: 0.7452830188679245, Recall: 0.5448275862068965, F1-score: 0.6294820717131474\n",
      "Epoch 57/100, Loss: 4.536018640166617e-05\n",
      "Validation Loss: 26.90959542138236, Validation Accuracy: 0.5177664974619289\n",
      "Precision: 0.7358490566037735, Recall: 0.5379310344827586, F1-score: 0.6215139442231076\n",
      "Epoch 58/100, Loss: 2.813899031887483e-05\n",
      "Validation Loss: 25.617037228175572, Validation Accuracy: 0.5279187817258884\n",
      "Precision: 0.75, Recall: 0.5379310344827586, F1-score: 0.6265060240963856\n",
      "Epoch 59/100, Loss: 5.083057117379516e-05\n",
      "Validation Loss: 26.259169919150217, Validation Accuracy: 0.5279187817258884\n",
      "Precision: 0.75, Recall: 0.5379310344827586, F1-score: 0.6265060240963856\n",
      "Epoch 60/100, Loss: 5.295277171057933e-05\n",
      "Validation Loss: 23.86444217818124, Validation Accuracy: 0.5786802030456852\n",
      "Precision: 0.8229166666666666, Recall: 0.5448275862068965, F1-score: 0.6556016597510373\n",
      "Epoch 61/100, Loss: 7.409440518320783e-05\n",
      "Validation Loss: 26.376482486724854, Validation Accuracy: 0.5380710659898477\n",
      "Precision: 0.7547169811320755, Recall: 0.5517241379310345, F1-score: 0.6374501992031872\n",
      "Epoch 62/100, Loss: 3.8601704028806694e-05\n",
      "Validation Loss: 26.12016419001988, Validation Accuracy: 0.5431472081218274\n",
      "Precision: 0.7669902912621359, Recall: 0.5448275862068965, F1-score: 0.6370967741935484\n",
      "Epoch 63/100, Loss: 5.1886980275028804e-05\n",
      "Validation Loss: 25.99182449068342, Validation Accuracy: 0.5583756345177665\n",
      "Precision: 0.79, Recall: 0.5448275862068965, F1-score: 0.6448979591836734\n",
      "Epoch 64/100, Loss: 3.67926702701619e-05\n",
      "Validation Loss: 26.715860434940883, Validation Accuracy: 0.5329949238578681\n",
      "Precision: 0.7523809523809524, Recall: 0.5448275862068965, F1-score: 0.632\n",
      "Epoch 65/100, Loss: 5.270715314746136e-05\n",
      "Validation Loss: 26.055370262690953, Validation Accuracy: 0.5583756345177665\n",
      "Precision: 0.79, Recall: 0.5448275862068965, F1-score: 0.6448979591836734\n",
      "Epoch 66/100, Loss: 3.984042819619541e-05\n",
      "Validation Loss: 26.491617270878383, Validation Accuracy: 0.5279187817258884\n",
      "Precision: 0.7452830188679245, Recall: 0.5448275862068965, F1-score: 0.6294820717131474\n",
      "Epoch 67/100, Loss: 2.6701156179124535e-05\n",
      "Validation Loss: 26.86924627849034, Validation Accuracy: 0.5380710659898477\n",
      "Precision: 0.7596153846153846, Recall: 0.5448275862068965, F1-score: 0.6345381526104418\n",
      "Epoch 68/100, Loss: 5.204553483887745e-05\n",
      "Validation Loss: 26.65759835924421, Validation Accuracy: 0.5329949238578681\n",
      "Precision: 0.7523809523809524, Recall: 0.5448275862068965, F1-score: 0.632\n",
      "Epoch 69/100, Loss: 0.00998052221276069\n",
      "Validation Loss: 30.713515383856638, Validation Accuracy: 0.5786802030456852\n",
      "Precision: 0.8369565217391305, Recall: 0.5310344827586206, F1-score: 0.6497890295358649\n",
      "Epoch 70/100, Loss: 0.037410083874698685\n",
      "Validation Loss: 42.08563439335142, Validation Accuracy: 0.649746192893401\n",
      "Precision: 0.9318181818181818, Recall: 0.5655172413793104, F1-score: 0.703862660944206\n",
      "Epoch 71/100, Loss: 0.0027256256044362694\n",
      "Validation Loss: 40.87820226805551, Validation Accuracy: 0.6294416243654822\n",
      "Precision: 0.8913043478260869, Recall: 0.5655172413793104, F1-score: 0.6919831223628692\n",
      "Epoch 72/100, Loss: 4.293489388459045e-05\n",
      "Validation Loss: 37.95701963560922, Validation Accuracy: 0.6294416243654822\n",
      "Precision: 0.8913043478260869, Recall: 0.5655172413793104, F1-score: 0.6919831223628692\n",
      "Epoch 73/100, Loss: 2.5111792260270233e-05\n",
      "Validation Loss: 41.00299438408443, Validation Accuracy: 0.6294416243654822\n",
      "Precision: 0.8913043478260869, Recall: 0.5655172413793104, F1-score: 0.6919831223628692\n",
      "Epoch 74/100, Loss: 1.9379484386128354e-05\n",
      "Validation Loss: 38.42567328044346, Validation Accuracy: 0.6294416243654822\n",
      "Precision: 0.8913043478260869, Recall: 0.5655172413793104, F1-score: 0.6919831223628692\n",
      "Epoch 75/100, Loss: 5.378589103539425e-05\n",
      "Validation Loss: 40.42388238225664, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 76/100, Loss: 1.5675242712176463e-05\n",
      "Validation Loss: 39.633065053394866, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 77/100, Loss: 1.9624225851629557e-05\n",
      "Validation Loss: 40.611598065921235, Validation Accuracy: 0.6294416243654822\n",
      "Precision: 0.8913043478260869, Recall: 0.5655172413793104, F1-score: 0.6919831223628692\n",
      "Epoch 78/100, Loss: 1.5068526748327852e-05\n",
      "Validation Loss: 38.55120284216745, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 79/100, Loss: 3.2866256253390645e-05\n",
      "Validation Loss: 40.644929834774565, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 80/100, Loss: 8.338342011293687e-05\n",
      "Validation Loss: 40.0664336681366, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 81/100, Loss: 7.105812539228336e-06\n",
      "Validation Loss: 38.45813378265926, Validation Accuracy: 0.6395939086294417\n",
      "Precision: 0.9111111111111111, Recall: 0.5655172413793104, F1-score: 0.6978723404255319\n",
      "Epoch 82/100, Loss: 1.7168886595882633e-05\n",
      "Validation Loss: 40.16808957712991, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 83/100, Loss: 2.923191639576476e-05\n",
      "Validation Loss: 40.93567698342459, Validation Accuracy: 0.6395939086294417\n",
      "Precision: 0.9111111111111111, Recall: 0.5655172413793104, F1-score: 0.6978723404255319\n",
      "Epoch 84/100, Loss: 1.2807762950484136e-05\n",
      "Validation Loss: 40.47339516026633, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 85/100, Loss: 2.3854506872172943e-05\n",
      "Validation Loss: 40.3467811856951, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 86/100, Loss: 9.376575588332381e-06\n",
      "Validation Loss: 41.88167418752398, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 87/100, Loss: 1.0388860987244527e-05\n",
      "Validation Loss: 41.36855098179409, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 88/100, Loss: 7.691729592473884e-06\n",
      "Validation Loss: 41.637412905693054, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 89/100, Loss: 1.819430374126278e-05\n",
      "Validation Loss: 41.077113015311106, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 90/100, Loss: 9.117511120861529e-06\n",
      "Validation Loss: 42.30138313770294, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 91/100, Loss: 2.349982312106295e-05\n",
      "Validation Loss: 38.75456614153726, Validation Accuracy: 0.6395939086294417\n",
      "Precision: 0.9111111111111111, Recall: 0.5655172413793104, F1-score: 0.6978723404255319\n",
      "Epoch 92/100, Loss: 3.5737121796552973e-06\n",
      "Validation Loss: 40.45477155276707, Validation Accuracy: 0.6395939086294417\n",
      "Precision: 0.9111111111111111, Recall: 0.5655172413793104, F1-score: 0.6978723404255319\n",
      "Epoch 93/100, Loss: 8.295058534798136e-06\n",
      "Validation Loss: 39.05745167391641, Validation Accuracy: 0.6395939086294417\n",
      "Precision: 0.9111111111111111, Recall: 0.5655172413793104, F1-score: 0.6978723404255319\n",
      "Epoch 94/100, Loss: 3.1234965891709563e-06\n",
      "Validation Loss: 38.159852044922964, Validation Accuracy: 0.6395939086294417\n",
      "Precision: 0.9111111111111111, Recall: 0.5655172413793104, F1-score: 0.6978723404255319\n",
      "Epoch 95/100, Loss: 5.963604287099559e-06\n",
      "Validation Loss: 38.35151272160666, Validation Accuracy: 0.6395939086294417\n",
      "Precision: 0.9111111111111111, Recall: 0.5655172413793104, F1-score: 0.6978723404255319\n",
      "Epoch 96/100, Loss: 6.545181582773285e-06\n",
      "Validation Loss: 39.642903975078035, Validation Accuracy: 0.6395939086294417\n",
      "Precision: 0.9111111111111111, Recall: 0.5655172413793104, F1-score: 0.6978723404255319\n",
      "Epoch 97/100, Loss: 1.1023369264913837e-05\n",
      "Validation Loss: 38.564263582229614, Validation Accuracy: 0.6395939086294417\n",
      "Precision: 0.9111111111111111, Recall: 0.5655172413793104, F1-score: 0.6978723404255319\n",
      "Epoch 98/100, Loss: 7.443249235813039e-06\n",
      "Validation Loss: 40.81531577450888, Validation Accuracy: 0.6395939086294417\n",
      "Precision: 0.9111111111111111, Recall: 0.5655172413793104, F1-score: 0.6978723404255319\n",
      "Epoch 99/100, Loss: 6.950826666148509e-06\n",
      "Validation Loss: 40.360182421548025, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.9010989010989011, Recall: 0.5655172413793104, F1-score: 0.6949152542372882\n",
      "Epoch 100/100, Loss: 8.032216232541542e-06\n",
      "Validation Loss: 41.0027289220265, Validation Accuracy: 0.6395939086294417\n",
      "Precision: 0.9111111111111111, Recall: 0.5655172413793104, F1-score: 0.6978723404255319\n",
      "Validation Loss: 6.414728164672852, Validation Accuracy: 0.4873096446700508\n",
      "Precision: 0.72, Recall: 0.496551724137931, F1-score: 0.5877551020408164\n",
      "Confusion Matrix:\n",
      "[[24 28]\n",
      " [73 72]]\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch 1/100, Loss: 0.42511175892529235\n",
      "Validation Loss: 3.5111286006472904, Validation Accuracy: 0.6887755102040817\n",
      "Precision: 0.7076923076923077, Recall: 0.8, F1-score: 0.7510204081632653\n",
      "Model saved to ensemble_model_fold_4.pth\n",
      "Epoch 2/100, Loss: 0.03509592692191443\n",
      "Validation Loss: 5.730847518721873, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 3/100, Loss: 0.005991544179323682\n",
      "Validation Loss: 4.974357113699049, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 4/100, Loss: 0.07335138326792882\n",
      "Validation Loss: 7.5518690635051025, Validation Accuracy: 0.6938775510204082\n",
      "Precision: 0.6870748299319728, Recall: 0.8782608695652174, F1-score: 0.7709923664122137\n",
      "Epoch 5/100, Loss: 0.017326175054525567\n",
      "Validation Loss: 2.188135231306656, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8793103448275862, Recall: 0.8869565217391304, F1-score: 0.8831168831168831\n",
      "Model saved to ensemble_model_fold_4.pth\n",
      "Epoch 6/100, Loss: 0.003609317996260112\n",
      "Validation Loss: 5.02751839100558, Validation Accuracy: 0.7193877551020408\n",
      "Precision: 0.7083333333333334, Recall: 0.8869565217391304, F1-score: 0.7876447876447876\n",
      "Epoch 7/100, Loss: 0.0021365786318483515\n",
      "Validation Loss: 3.976144720882855, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 8/100, Loss: 0.0011419413817748136\n",
      "Validation Loss: 3.6644766513295832, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 9/100, Loss: 0.0016337466424829472\n",
      "Validation Loss: 3.9594575156863163, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 10/100, Loss: 0.0008617001485333731\n",
      "Validation Loss: 4.393274128593378, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 11/100, Loss: 0.00042243992983988693\n",
      "Validation Loss: 4.7049408640251285, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 12/100, Loss: 0.0005044558398215789\n",
      "Validation Loss: 4.48230546904207, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 13/100, Loss: 0.0007807093792469763\n",
      "Validation Loss: 4.369276878889187, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 14/100, Loss: 0.0005632334293723673\n",
      "Validation Loss: 4.828548412202459, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 15/100, Loss: 0.07317842811397195\n",
      "Validation Loss: 3.1740029112822534, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8793103448275862, Recall: 0.8869565217391304, F1-score: 0.8831168831168831\n",
      "Epoch 16/100, Loss: 0.4057237711764022\n",
      "Validation Loss: 3.065930830580125, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 17/100, Loss: 0.49125963291832403\n",
      "Validation Loss: 6.156354380505426, Validation Accuracy: 0.7908163265306123\n",
      "Precision: 0.8775510204081632, Recall: 0.7478260869565218, F1-score: 0.8075117370892019\n",
      "Epoch 18/100, Loss: 0.1371682110661349\n",
      "Validation Loss: 6.439553362982614, Validation Accuracy: 0.8112244897959183\n",
      "Precision: 0.8823529411764706, Recall: 0.782608695652174, F1-score: 0.8294930875576036\n",
      "Epoch 19/100, Loss: 0.031662273555540445\n",
      "Validation Loss: 7.016461582588294, Validation Accuracy: 0.8469387755102041\n",
      "Precision: 0.8632478632478633, Recall: 0.8782608695652174, F1-score: 0.8706896551724138\n",
      "Epoch 20/100, Loss: 0.018098441148148514\n",
      "Validation Loss: 7.088249500042626, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8793103448275862, Recall: 0.8869565217391304, F1-score: 0.8831168831168831\n",
      "Epoch 21/100, Loss: 0.003942526199882224\n",
      "Validation Loss: 7.0450328904470165, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 22/100, Loss: 0.0004802799074782686\n",
      "Validation Loss: 6.8351003497622775, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 23/100, Loss: 0.0014595793193146929\n",
      "Validation Loss: 7.102852823474677, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 24/100, Loss: 0.0006270226116565544\n",
      "Validation Loss: 6.295387212558125, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 25/100, Loss: 0.012375685335982054\n",
      "Validation Loss: 7.359881585280943, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 26/100, Loss: 0.06863165741404957\n",
      "Validation Loss: 8.47910312109473, Validation Accuracy: 0.8469387755102041\n",
      "Precision: 0.8828828828828829, Recall: 0.8521739130434782, F1-score: 0.8672566371681416\n",
      "Epoch 27/100, Loss: 0.02487107140096138\n",
      "Validation Loss: 8.163806516902696, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8796296296296297, Recall: 0.8260869565217391, F1-score: 0.852017937219731\n",
      "Epoch 28/100, Loss: 0.07237269992088653\n",
      "Validation Loss: 7.6913374406583115, Validation Accuracy: 0.8112244897959183\n",
      "Precision: 0.8095238095238095, Recall: 0.8869565217391304, F1-score: 0.8464730290456431\n",
      "Epoch 29/100, Loss: 0.038259775332838676\n",
      "Validation Loss: 7.445244999093201, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 30/100, Loss: 0.006104528049470777\n",
      "Validation Loss: 8.015179889624587, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 31/100, Loss: 0.03976133376823713\n",
      "Validation Loss: 7.9119518463068585, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 32/100, Loss: 0.007917846149871602\n",
      "Validation Loss: 7.543227641340179, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 33/100, Loss: 0.01868230123383959\n",
      "Validation Loss: 7.330463991349201, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 34/100, Loss: 0.003243215437750487\n",
      "Validation Loss: 8.041750191042995, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 35/100, Loss: 0.0063115717851071436\n",
      "Validation Loss: 8.216987301182144, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 36/100, Loss: 0.000491650858811384\n",
      "Validation Loss: 7.983672773577772, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 37/100, Loss: 0.001829158708036932\n",
      "Validation Loss: 7.375436183065176, Validation Accuracy: 0.8469387755102041\n",
      "Precision: 0.8899082568807339, Recall: 0.8434782608695652, F1-score: 0.8660714285714286\n",
      "Epoch 38/100, Loss: 0.00039600828597866067\n",
      "Validation Loss: 7.542878957797906, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8928571428571429, Recall: 0.8695652173913043, F1-score: 0.8810572687224669\n",
      "Epoch 39/100, Loss: 0.0008200546975478303\n",
      "Validation Loss: 7.628302053548396, Validation Accuracy: 0.8571428571428571\n",
      "Precision: 0.8918918918918919, Recall: 0.8608695652173913, F1-score: 0.8761061946902655\n",
      "Epoch 40/100, Loss: 0.0001169108662726348\n",
      "Validation Loss: 7.162951034626791, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8867924528301887, Recall: 0.8173913043478261, F1-score: 0.8506787330316742\n",
      "Epoch 41/100, Loss: 0.0005956357777566016\n",
      "Validation Loss: 7.82902950085346, Validation Accuracy: 0.8724489795918368\n",
      "Precision: 0.8947368421052632, Recall: 0.8869565217391304, F1-score: 0.8908296943231441\n",
      "Epoch 42/100, Loss: 0.0017781491525346398\n",
      "Validation Loss: 8.084239970476899, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8938053097345132, Recall: 0.8782608695652174, F1-score: 0.8859649122807017\n",
      "Epoch 43/100, Loss: 0.00016820428149039168\n",
      "Validation Loss: 7.5619916298559735, Validation Accuracy: 0.8571428571428571\n",
      "Precision: 0.8918918918918919, Recall: 0.8608695652173913, F1-score: 0.8761061946902655\n",
      "Epoch 44/100, Loss: 0.0006363707789539541\n",
      "Validation Loss: 7.831713593332097, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8928571428571429, Recall: 0.8695652173913043, F1-score: 0.8810572687224669\n",
      "Epoch 45/100, Loss: 0.0008001129587061062\n",
      "Validation Loss: 7.637292876839638, Validation Accuracy: 0.8520408163265306\n",
      "Precision: 0.8909090909090909, Recall: 0.8521739130434782, F1-score: 0.8711111111111111\n",
      "Epoch 46/100, Loss: 0.0003136028225329361\n",
      "Validation Loss: 7.432051495515873, Validation Accuracy: 0.8571428571428571\n",
      "Precision: 0.8918918918918919, Recall: 0.8608695652173913, F1-score: 0.8761061946902655\n",
      "Epoch 47/100, Loss: 0.00012129606416814524\n",
      "Validation Loss: 7.971080075625131, Validation Accuracy: 0.8724489795918368\n",
      "Precision: 0.8947368421052632, Recall: 0.8869565217391304, F1-score: 0.8908296943231441\n",
      "Epoch 48/100, Loss: 0.0008075326777845504\n",
      "Validation Loss: 7.711844971137386, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8857142857142857, Recall: 0.808695652173913, F1-score: 0.8454545454545455\n",
      "Epoch 49/100, Loss: 0.001968912569830968\n",
      "Validation Loss: 7.490726760222709, Validation Accuracy: 0.8571428571428571\n",
      "Precision: 0.8717948717948718, Recall: 0.8869565217391304, F1-score: 0.8793103448275862\n",
      "Epoch 50/100, Loss: 0.00365854669249747\n",
      "Validation Loss: 7.803657602784889, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8928571428571429, Recall: 0.8695652173913043, F1-score: 0.8810572687224669\n",
      "Epoch 51/100, Loss: 0.0015072819955239125\n",
      "Validation Loss: 8.152843601885252, Validation Accuracy: 0.8724489795918368\n",
      "Precision: 0.8947368421052632, Recall: 0.8869565217391304, F1-score: 0.8908296943231441\n",
      "Epoch 52/100, Loss: 4.2269949786251836e-05\n",
      "Validation Loss: 7.6792265599859615, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8928571428571429, Recall: 0.8695652173913043, F1-score: 0.8810572687224669\n",
      "Epoch 53/100, Loss: 0.0001069285298043084\n",
      "Validation Loss: 7.6843900957277835, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8928571428571429, Recall: 0.8695652173913043, F1-score: 0.8810572687224669\n",
      "Epoch 54/100, Loss: 9.752563067414825e-05\n",
      "Validation Loss: 7.8589817673367035, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8938053097345132, Recall: 0.8782608695652174, F1-score: 0.8859649122807017\n",
      "Epoch 55/100, Loss: 6.101832029202966e-05\n",
      "Validation Loss: 7.583844640425272, Validation Accuracy: 0.8571428571428571\n",
      "Precision: 0.8918918918918919, Recall: 0.8608695652173913, F1-score: 0.8761061946902655\n",
      "Epoch 56/100, Loss: 7.885361997613434e-05\n",
      "Validation Loss: 7.828101307419794, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8928571428571429, Recall: 0.8695652173913043, F1-score: 0.8810572687224669\n",
      "Epoch 57/100, Loss: 5.677302443807264e-05\n",
      "Validation Loss: 7.354726575847183, Validation Accuracy: 0.8112244897959183\n",
      "Precision: 0.8823529411764706, Recall: 0.782608695652174, F1-score: 0.8294930875576036\n",
      "Epoch 58/100, Loss: 8.325659702604349e-05\n",
      "Validation Loss: 7.8591473073964675, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8928571428571429, Recall: 0.8695652173913043, F1-score: 0.8810572687224669\n",
      "Epoch 59/100, Loss: 6.292463024570871e-05\n",
      "Validation Loss: 7.436684336513281, Validation Accuracy: 0.8214285714285714\n",
      "Precision: 0.8846153846153846, Recall: 0.8, F1-score: 0.8401826484018264\n",
      "Epoch 60/100, Loss: 0.009866245519563962\n",
      "Validation Loss: 8.287230433097209, Validation Accuracy: 0.8469387755102041\n",
      "Precision: 0.8571428571428571, Recall: 0.8869565217391304, F1-score: 0.8717948717948718\n",
      "Epoch 61/100, Loss: 0.25553476673479675\n",
      "Validation Loss: 9.00237537867021, Validation Accuracy: 0.7857142857142857\n",
      "Precision: 0.8288288288288288, Recall: 0.8, F1-score: 0.8141592920353983\n",
      "Epoch 62/100, Loss: 0.013847116677861907\n",
      "Validation Loss: 8.33393601008824, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 63/100, Loss: 0.0018862044377210192\n",
      "Validation Loss: 7.800580024719238, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 64/100, Loss: 3.237536353712748e-05\n",
      "Validation Loss: 7.655152661459787, Validation Accuracy: 0.8367346938775511\n",
      "Precision: 0.8429752066115702, Recall: 0.8869565217391304, F1-score: 0.864406779661017\n",
      "Epoch 65/100, Loss: 9.877339807747484e-06\n",
      "Validation Loss: 7.503896168300083, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 66/100, Loss: 4.134301257894638e-05\n",
      "Validation Loss: 7.757266453334263, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 67/100, Loss: 2.571549223239396e-05\n",
      "Validation Loss: 7.982927731105259, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 68/100, Loss: 2.225377282209321e-06\n",
      "Validation Loss: 7.912865502493722, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 69/100, Loss: 0.021238136476018344\n",
      "Validation Loss: 7.219907215663365, Validation Accuracy: 0.8163265306122449\n",
      "Precision: 0.8211382113821138, Recall: 0.8782608695652174, F1-score: 0.8487394957983193\n",
      "Epoch 70/100, Loss: 0.05547666042446053\n",
      "Validation Loss: 4.695170164108276, Validation Accuracy: 0.8163265306122449\n",
      "Precision: 0.8623853211009175, Recall: 0.8173913043478261, F1-score: 0.8392857142857143\n",
      "Epoch 71/100, Loss: 0.03577937662252154\n",
      "Validation Loss: 4.7229905128479, Validation Accuracy: 0.7908163265306123\n",
      "Precision: 0.8245614035087719, Recall: 0.8173913043478261, F1-score: 0.8209606986899564\n",
      "Epoch 72/100, Loss: 0.0017063744558899845\n",
      "Validation Loss: 4.666652475084577, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8785046728971962, Recall: 0.8173913043478261, F1-score: 0.8468468468468469\n",
      "Epoch 73/100, Loss: 7.269312582990535e-05\n",
      "Validation Loss: 4.00160592262234, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8785046728971962, Recall: 0.8173913043478261, F1-score: 0.8468468468468469\n",
      "Epoch 74/100, Loss: 0.00015110287538379805\n",
      "Validation Loss: 4.432346139635358, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8785046728971962, Recall: 0.8173913043478261, F1-score: 0.8468468468468469\n",
      "Epoch 75/100, Loss: 0.004268590522104256\n",
      "Validation Loss: 4.513913767678397, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8785046728971962, Recall: 0.8173913043478261, F1-score: 0.8468468468468469\n",
      "Epoch 76/100, Loss: 0.0005557328627144401\n",
      "Validation Loss: 4.9032187802450995, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8785046728971962, Recall: 0.8173913043478261, F1-score: 0.8468468468468469\n",
      "Epoch 77/100, Loss: 3.839545766896416e-05\n",
      "Validation Loss: 4.926299299512591, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8785046728971962, Recall: 0.8173913043478261, F1-score: 0.8468468468468469\n",
      "Epoch 78/100, Loss: 4.481851652129072e-06\n",
      "Validation Loss: 4.7881578377314975, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8785046728971962, Recall: 0.8173913043478261, F1-score: 0.8468468468468469\n",
      "Epoch 79/100, Loss: 7.917615101919276e-06\n",
      "Validation Loss: 4.967226675578526, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8785046728971962, Recall: 0.8173913043478261, F1-score: 0.8468468468468469\n",
      "Epoch 80/100, Loss: 2.7131493256874844e-05\n",
      "Validation Loss: 4.456638710839408, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8785046728971962, Recall: 0.8173913043478261, F1-score: 0.8468468468468469\n",
      "Epoch 81/100, Loss: 4.3123143410178644e-05\n",
      "Validation Loss: 4.855304513658796, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8785046728971962, Recall: 0.8173913043478261, F1-score: 0.8468468468468469\n",
      "Epoch 82/100, Loss: 1.3941385332671974e-05\n",
      "Validation Loss: 5.06981543132237, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8785046728971962, Recall: 0.8173913043478261, F1-score: 0.8468468468468469\n",
      "Epoch 83/100, Loss: 1.8101340452131298e-05\n",
      "Validation Loss: 4.922011000769479, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8785046728971962, Recall: 0.8173913043478261, F1-score: 0.8468468468468469\n",
      "Epoch 84/100, Loss: 0.1310508364902763\n",
      "Validation Loss: 5.539595603942871, Validation Accuracy: 0.8214285714285714\n",
      "Precision: 0.8846153846153846, Recall: 0.8, F1-score: 0.8401826484018264\n",
      "Epoch 85/100, Loss: 0.3231643358834639\n",
      "Validation Loss: 12.786258503262486, Validation Accuracy: 0.7755102040816326\n",
      "Precision: 0.7983193277310925, Recall: 0.8260869565217391, F1-score: 0.811965811965812\n",
      "Epoch 86/100, Loss: 0.012111860309789316\n",
      "Validation Loss: 11.830711319206525, Validation Accuracy: 0.7959183673469388\n",
      "Precision: 0.7906976744186046, Recall: 0.8869565217391304, F1-score: 0.8360655737704918\n",
      "Epoch 87/100, Loss: 0.01380756836405734\n",
      "Validation Loss: 11.488556274852906, Validation Accuracy: 0.8214285714285714\n",
      "Precision: 0.8225806451612904, Recall: 0.8869565217391304, F1-score: 0.8535564853556485\n",
      "Epoch 88/100, Loss: 0.0072505533509847715\n",
      "Validation Loss: 11.596113429004626, Validation Accuracy: 0.8112244897959183\n",
      "Precision: 0.8095238095238095, Recall: 0.8869565217391304, F1-score: 0.8464730290456431\n",
      "Epoch 89/100, Loss: 9.638735343275862e-05\n",
      "Validation Loss: 11.481945745632531, Validation Accuracy: 0.8163265306122449\n",
      "Precision: 0.816, Recall: 0.8869565217391304, F1-score: 0.85\n",
      "Epoch 90/100, Loss: 5.802419400734634e-05\n",
      "Validation Loss: 11.457686441284888, Validation Accuracy: 0.8163265306122449\n",
      "Precision: 0.816, Recall: 0.8869565217391304, F1-score: 0.85\n",
      "Epoch 91/100, Loss: 2.0792625911545775e-05\n",
      "Validation Loss: 11.653650804287711, Validation Accuracy: 0.8163265306122449\n",
      "Precision: 0.816, Recall: 0.8869565217391304, F1-score: 0.85\n",
      "Epoch 92/100, Loss: 0.00010035933641949768\n",
      "Validation Loss: 10.807651782938835, Validation Accuracy: 0.8214285714285714\n",
      "Precision: 0.8225806451612904, Recall: 0.8869565217391304, F1-score: 0.8535564853556485\n",
      "Epoch 93/100, Loss: 0.00010093436329651946\n",
      "Validation Loss: 11.511491366261984, Validation Accuracy: 0.8112244897959183\n",
      "Precision: 0.8095238095238095, Recall: 0.8869565217391304, F1-score: 0.8464730290456431\n",
      "Epoch 94/100, Loss: 3.3430544343894995e-05\n",
      "Validation Loss: 11.402385691382936, Validation Accuracy: 0.8112244897959183\n",
      "Precision: 0.8095238095238095, Recall: 0.8869565217391304, F1-score: 0.8464730290456431\n",
      "Epoch 95/100, Loss: 1.960669672362858e-05\n",
      "Validation Loss: 9.21285264965679, Validation Accuracy: 0.8163265306122449\n",
      "Precision: 0.8264462809917356, Recall: 0.8695652173913043, F1-score: 0.847457627118644\n",
      "Epoch 96/100, Loss: 3.375761770483635e-05\n",
      "Validation Loss: 11.092927219079813, Validation Accuracy: 0.7959183673469388\n",
      "Precision: 0.7906976744186046, Recall: 0.8869565217391304, F1-score: 0.8360655737704918\n",
      "Epoch 97/100, Loss: 7.793656281324113e-05\n",
      "Validation Loss: 11.060213370780973, Validation Accuracy: 0.8112244897959183\n",
      "Precision: 0.8095238095238095, Recall: 0.8869565217391304, F1-score: 0.8464730290456431\n",
      "Epoch 98/100, Loss: 1.1806723334552757e-05\n",
      "Validation Loss: 11.619528110538198, Validation Accuracy: 0.8061224489795918\n",
      "Precision: 0.8031496062992126, Recall: 0.8869565217391304, F1-score: 0.8429752066115702\n",
      "Epoch 99/100, Loss: 1.1583396382205033e-05\n",
      "Validation Loss: 11.695835787801702, Validation Accuracy: 0.8112244897959183\n",
      "Precision: 0.8095238095238095, Recall: 0.8869565217391304, F1-score: 0.8464730290456431\n",
      "Epoch 100/100, Loss: 5.327426564597874e-05\n",
      "Validation Loss: 10.217863606549404, Validation Accuracy: 0.8112244897959183\n",
      "Precision: 0.8145161290322581, Recall: 0.8782608695652174, F1-score: 0.8451882845188284\n",
      "Validation Loss: 2.188135231306656, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8793103448275862, Recall: 0.8869565217391304, F1-score: 0.8831168831168831\n",
      "Confusion Matrix:\n",
      "[[ 67  14]\n",
      " [ 13 102]]\n",
      "\n",
      "Average results across all folds:\n",
      "Accuracy: 0.8359\n",
      "Precision: 0.8699\n",
      "Recall: 0.8907\n",
      "F1-score: 0.8756\n",
      "Final model saved to final_ensemble_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 51), padding='same')\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.depthwiseConv2d = nn.Conv2d(16, 32, (65, 1), groups=16, padding='same')\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.activation = nn.ELU()\n",
    "        self.pooling = nn.AvgPool2d((1, 4))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(32 * 65 * 31, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.depthwiseConv2d(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class PolygraphNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(PolygraphNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 51), padding='same')\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.depthwiseConv2d = nn.Conv2d(16, 32, (4, 1), groups=16, padding='same')\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.activation = nn.ELU()\n",
    "        self.pooling = nn.AvgPool2d((1, 4))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(32 * 4 * 1118, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.depthwiseConv2d(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, eeg_model, poly_model):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.eeg_model = eeg_model\n",
    "        self.poly_model = poly_model\n",
    "        self.fc = nn.Linear(4, 2)\n",
    "\n",
    "    def forward(self, eeg_input, poly_input):\n",
    "        eeg_output = self.eeg_model(eeg_input)\n",
    "        poly_output = self.poly_model(poly_input)\n",
    "        combined_output = torch.cat((eeg_output, poly_output), dim=1)\n",
    "        output = self.fc(combined_output)\n",
    "        return output\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    all_labels, all_predictions = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for eeg_X_batch, eeg_y_batch, poly_X_batch, poly_y_batch in data_loader:\n",
    "            eeg_X_batch, poly_X_batch = eeg_X_batch.to(device), poly_X_batch.to(device)\n",
    "            labels = eeg_y_batch.to(device)  # Use EEG labels (they should be the same as Poly labels)\n",
    "            \n",
    "            outputs = model(eeg_X_batch, poly_X_batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(all_labels, all_predictions, average='binary', zero_division=1)\n",
    "    recall = recall_score(all_labels, all_predictions, average='binary', zero_division=1)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='binary', zero_division=1)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions, labels=[0, 1])\n",
    "\n",
    "    return total_loss / len(data_loader), accuracy, precision, recall, f1, conf_matrix\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, save_path):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for eeg_X_batch, eeg_y_batch, poly_X_batch, poly_y_batch in train_loader:\n",
    "            eeg_X_batch, poly_X_batch = eeg_X_batch.to(device), poly_X_batch.to(device)\n",
    "            labels = eeg_y_batch.to(device)  # Use EEG labels (they should be the same as Poly labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(eeg_X_batch, poly_X_batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss}')\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy, val_precision, val_recall, val_f1, val_conf_matrix = evaluate_model(model, val_loader, criterion, device)\n",
    "        print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "        print(f'Precision: {val_precision}, Recall: {val_recall}, F1-score: {val_f1}')\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'val_accuracy': val_accuracy,\n",
    "                'val_precision': val_precision,\n",
    "                'val_recall': val_recall,\n",
    "                'val_f1': val_f1,\n",
    "            }, save_path)\n",
    "            print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "# Load data\n",
    "print(\"Loading EEG data...\")\n",
    "eeg_X, eeg_y, file_sample_counts = load_eeg_data(EEG_DATA_DIR)\n",
    "print(\"Loading Poly data...\")\n",
    "poly_X, poly_y = load_poly_data(POLY_DATA_DIR)\n",
    "\n",
    "# Create splits based on file indices\n",
    "splits = create_file_based_splits(file_sample_counts, n_splits=5)\n",
    "\n",
    "for fold, (train_file_indices, val_file_indices) in enumerate(splits):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Split data based on file indices\n",
    "    train_sample_counts = [file_sample_counts[i] for i in train_file_indices]\n",
    "    val_sample_counts = [file_sample_counts[i] for i in val_file_indices]\n",
    "    \n",
    "    train_eeg_indices = np.concatenate([np.arange(sum(file_sample_counts[:i]), \n",
    "                                                  sum(file_sample_counts[:i+1])) \n",
    "                                        for i in train_file_indices])\n",
    "    val_eeg_indices = np.concatenate([np.arange(sum(file_sample_counts[:i]), \n",
    "                                                sum(file_sample_counts[:i+1])) \n",
    "                                      for i in val_file_indices])\n",
    "\n",
    "    # Split EEG data\n",
    "    train_eeg_X, train_eeg_y = eeg_X[train_eeg_indices], eeg_y[train_eeg_indices]\n",
    "    val_eeg_X, val_eeg_y = eeg_X[val_eeg_indices], eeg_y[val_eeg_indices]\n",
    "\n",
    "    # Split Poly data\n",
    "    train_poly_X, train_poly_y = poly_X[train_file_indices], poly_y[train_file_indices]\n",
    "    val_poly_X, val_poly_y = poly_X[val_file_indices], poly_y[val_file_indices]\n",
    "\n",
    "    # Normalize data for this fold\n",
    "    eeg_scaler = StandardScaler()\n",
    "    poly_scaler = StandardScaler()\n",
    "\n",
    "\n",
    "    train_eeg_X_2d = train_eeg_X.reshape(-1, train_eeg_X.shape[-1])  \n",
    "    train_eeg_X_2d_scaled = eeg_scaler.fit_transform(train_eeg_X_2d)\n",
    "    train_eeg_X_scaled = train_eeg_X_2d_scaled.reshape(train_eeg_X.shape)\n",
    "    \n",
    "    # Reshape and transform validation data\n",
    "    val_eeg_X_2d = val_eeg_X.reshape(-1, val_eeg_X.shape[-1])\n",
    "    val_eeg_X_2d_scaled = eeg_scaler.transform(val_eeg_X_2d)\n",
    "    val_eeg_X_scaled = val_eeg_X_2d_scaled.reshape(val_eeg_X.shape)\n",
    "    \n",
    "    train_poly_X_2d = train_poly_X.reshape(-1, train_poly_X.shape[-1])\n",
    "    train_poly_X_2d_scaled = poly_scaler.fit_transform(train_poly_X_2d)\n",
    "    train_poly_X_scaled = train_poly_X_2d_scaled.reshape(train_poly_X.shape)\n",
    "    \n",
    "    val_poly_X_2d = val_poly_X.reshape(-1, val_poly_X.shape[-1])\n",
    "    val_poly_X_2d_scaled = poly_scaler.transform(val_poly_X_2d)\n",
    "    val_poly_X_scaled = val_poly_X_2d_scaled.reshape(val_poly_X.shape)\n",
    "\n",
    "    # Create datasets for this fold\n",
    "    train_dataset = CombinedDataset(train_eeg_X_scaled, train_eeg_y, train_poly_X_scaled, train_poly_y, train_sample_counts)\n",
    "    val_dataset = CombinedDataset(val_eeg_X_scaled, val_eeg_y, val_poly_X_scaled, val_poly_y, val_sample_counts)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize models\n",
    "    eeg_model = EEGNet(num_classes=2).to(device)\n",
    "    poly_model = PolygraphNet(num_classes=2).to(device)\n",
    "    ensemble_model = EnsembleModel(eeg_model, poly_model).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    ensemble_optimizer = optim.Adam(ensemble_model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train and evaluate model (rest of your code remains the same)\n",
    "    ...\n",
    "    # Train the model and save it\n",
    "    save_path = f'ensemble_model_fold_{fold}.pth'\n",
    "    best_model_path = train_model(ensemble_model, train_loader, val_loader, criterion, ensemble_optimizer, num_epochs, device, save_path)\n",
    "\n",
    "    # Load the best model and evaluate on validation set\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    ensemble_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    val_loss, val_accuracy, val_precision, val_recall, val_f1, val_conf_matrix = evaluate_model(ensemble_model, val_loader, criterion, device)\n",
    "    \n",
    "    print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "    print(f'Precision: {val_precision}, Recall: {val_recall}, F1-score: {val_f1}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(val_conf_matrix)\n",
    "    \n",
    "    results.append({\n",
    "        'fold': fold,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    })\n",
    "\n",
    "# Print average results\n",
    "avg_accuracy = np.mean([r['val_accuracy'] for r in results])\n",
    "avg_precision = np.mean([r['val_precision'] for r in results])\n",
    "avg_recall = np.mean([r['val_recall'] for r in results])\n",
    "avg_f1 = np.mean([r['val_f1'] for r in results])\n",
    "\n",
    "print(\"\\nAverage results across all folds:\")\n",
    "print(f\"Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Precision: {avg_precision:.4f}\")\n",
    "print(f\"Recall: {avg_recall:.4f}\")\n",
    "print(f\"F1-score: {avg_f1:.4f}\")\n",
    "\n",
    "# Save the final model (you can choose to save the model from the best fold instead)\n",
    "final_model_path = 'final_ensemble_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': ensemble_model.state_dict(),\n",
    "    'avg_accuracy': avg_accuracy,\n",
    "    'avg_precision': avg_precision,\n",
    "    'avg_recall': avg_recall,\n",
    "    'avg_f1': avg_f1,\n",
    "}, final_model_path)\n",
    "print(f\"Final model saved to {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911294f-a9f1-4b9a-a912-afea5f59c972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
