{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9959ced-48cb-4274-8d76-a93abcdfc4b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 625 and the array at index 1 has size 791",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 213\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mprint\u001b[39m(conf_matrix)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 213\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 150\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m--> 150\u001b[0m     X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    154\u001b[0m     kf \u001b[38;5;241m=\u001b[39m GroupKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m     32\u001b[0m         y\u001b[38;5;241m.\u001b[39mextend([label] \u001b[38;5;241m*\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     33\u001b[0m         groups\u001b[38;5;241m.\u001b[39mextend([idx] \u001b[38;5;241m*\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Use file index as group label\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y)\n\u001b[0;32m     37\u001b[0m groups \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(groups)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\detectlie\\Lib\\site-packages\\numpy\\core\\shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 625 and the array at index 1 has size 791"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from scipy.signal import butter, filtfilt\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Directory containing data files\n",
    "data_dir = r'C:\\Users\\User\\Documents\\Lie detect data\\56M_AugmentedEEGData'\n",
    "model_save_dir = r'C:\\Users\\User\\Documents\\Lie detect data\\Model'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# Function to load and label data\n",
    "def load_data(data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    groups = []\n",
    "    \n",
    "    for idx, file_name in enumerate(os.listdir(data_dir)):\n",
    "        if file_name.endswith('.pkl'):\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            data = pd.read_pickle(file_path)\n",
    "            label = 0 if 'lie' in file_name else 1\n",
    "            X.append(data)\n",
    "            y.extend([label] * data.shape[0])\n",
    "            groups.extend([idx] * data.shape[0])  # Use file index as group label\n",
    "    \n",
    "    X = np.vstack(X)\n",
    "    y = np.array(y)\n",
    "    groups = np.array(groups)\n",
    "    return X, y, groups\n",
    "\n",
    "\n",
    "# Define dataset class\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class EnhancedEEGNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(EnhancedEEGNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 63), padding='same')\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.depthwiseConv = nn.Conv2d(16, 32, (65, 1), groups=16, padding='same')\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.separableConv = nn.Conv2d(32, 64, (1, 16), padding='same')\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        self.avgPool = nn.AvgPool2d((1, 4))\n",
    "        self.dropout = nn.Dropout(0.7)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(64 * 65 * 15, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.depthwiseConv(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.avgPool(x)\n",
    "        x = self.separableConv(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.avgPool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def train_and_evaluate(train_loader, val_loader, model, criterion, optimizer, scheduler, device, num_epochs=100, patience=20):\n",
    "    best_val_loss = float('inf')\n",
    "    trigger_times = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = correct / total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            trigger_times = 0\n",
    "            torch.save(model.state_dict(), r'C:\\Users\\User\\Documents\\Lie detect data\\Model\\fold3_model.pth')\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!')\n",
    "                break\n",
    "    \n",
    "    return model\n",
    "\n",
    "def normalize_eeg_data(X_train, X_val):\n",
    "    # Assuming X_train and X_val shapes are (samples, channels, time_points)\n",
    "    n_channels = X_train.shape[1]\n",
    "    \n",
    "    # Initialize a StandardScaler for each channel\n",
    "    scalers = [StandardScaler() for _ in range(n_channels)]\n",
    "    \n",
    "    # Normalize each channel independently\n",
    "    for i in range(n_channels):\n",
    "        X_train[:, i, :] = scalers[i].fit_transform(X_train[:, i, :])\n",
    "        X_val[:, i, :] = scalers[i].transform(X_val[:, i, :])\n",
    "    \n",
    "    return X_train, X_val\n",
    "\n",
    "def main():\n",
    "    X, y, groups = load_data(data_dir)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    kf = GroupKFold(n_splits=5)\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X, y, groups)):\n",
    "        print(f'Fold {fold + 1}')\n",
    "        \n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        # Data Normalization\n",
    "        X_train, X_val = normalize_eeg_data(X_train, X_val)\n",
    "        \n",
    "        train_dataset = EEGDataset(X_train, y_train)\n",
    "        val_dataset = EEGDataset(X_val, y_val)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "        \n",
    "        model = EnhancedEEGNet().to(device)\n",
    "        \n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "        class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "        \n",
    "        model = train_and_evaluate(train_loader, val_loader, model, criterion, optimizer, scheduler, device)\n",
    "        \n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, _ in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        all_labels.extend(y_val)\n",
    "        all_predictions.extend(predictions)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "    recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    auc = roc_auc_score(all_labels, all_predictions, average='weighted')\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-score: {f1:.4f}')\n",
    "    print(f'AUC: {auc:.4f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572700d9-8886-43e6-98e1-280051d22679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d42b224-127e-413e-844a-a88f2dd5ee5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
