{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc01e5e-9282-427f-bc75-c960c93dc6b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\detectlie\\Lib\\site-packages\\torch\\nn\\init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\detectlie\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.8394130865732828, Validation Loss: 0.6580803990364075, Validation Accuracy: 77.78%, AUC: 0.64\n",
      "Epoch 2/100, Loss: 0.6368493636449178, Validation Loss: 0.6487430930137634, Validation Accuracy: 55.56%, AUC: 0.84\n",
      "Epoch 3/100, Loss: 0.5582949817180634, Validation Loss: 0.6363502740859985, Validation Accuracy: 38.89%, AUC: 0.79\n",
      "Epoch 4/100, Loss: 0.4406478901704152, Validation Loss: 0.5951131582260132, Validation Accuracy: 61.11%, AUC: 0.77\n",
      "Epoch 5/100, Loss: 0.45410295327504474, Validation Loss: 0.5822038650512695, Validation Accuracy: 61.11%, AUC: 0.77\n",
      "Epoch 6/100, Loss: 0.5262102087338766, Validation Loss: 0.574840247631073, Validation Accuracy: 66.67%, AUC: 0.88\n",
      "Epoch 7/100, Loss: 0.40798385938008624, Validation Loss: 0.5974298119544983, Validation Accuracy: 66.67%, AUC: 0.91\n",
      "Epoch 8/100, Loss: 0.3562670548756917, Validation Loss: 0.5751838684082031, Validation Accuracy: 66.67%, AUC: 0.91\n",
      "Epoch 9/100, Loss: 0.25946616133054096, Validation Loss: 0.5293633341789246, Validation Accuracy: 66.67%, AUC: 0.88\n",
      "Epoch 10/100, Loss: 0.2219777504603068, Validation Loss: 0.5035068988800049, Validation Accuracy: 83.33%, AUC: 0.86\n",
      "Epoch 11/100, Loss: 0.22514482835928598, Validation Loss: 0.5051471590995789, Validation Accuracy: 83.33%, AUC: 0.86\n",
      "Epoch 12/100, Loss: 0.2367228219906489, Validation Loss: 0.539054274559021, Validation Accuracy: 77.78%, AUC: 0.89\n",
      "Epoch 13/100, Loss: 0.19338436921437582, Validation Loss: 0.5713745951652527, Validation Accuracy: 72.22%, AUC: 0.86\n",
      "Epoch 14/100, Loss: 0.18310111264387766, Validation Loss: 0.561059296131134, Validation Accuracy: 77.78%, AUC: 0.89\n",
      "Epoch 15/100, Loss: 0.14938047900795937, Validation Loss: 0.5825802087783813, Validation Accuracy: 77.78%, AUC: 0.88\n",
      "Epoch 16/100, Loss: 0.5298091943065325, Validation Loss: 0.6117537021636963, Validation Accuracy: 72.22%, AUC: 0.86\n",
      "Epoch 17/100, Loss: 0.27588409682114917, Validation Loss: 0.6501541137695312, Validation Accuracy: 72.22%, AUC: 0.87\n",
      "Epoch 18/100, Loss: 0.1700555570423603, Validation Loss: 0.5967875719070435, Validation Accuracy: 77.78%, AUC: 0.89\n",
      "Epoch 19/100, Loss: 0.14964211732149124, Validation Loss: 0.6019800901412964, Validation Accuracy: 72.22%, AUC: 0.87\n",
      "Epoch 20/100, Loss: 0.15249740580717722, Validation Loss: 0.531177282333374, Validation Accuracy: 77.78%, AUC: 0.89\n",
      "Epoch 21/100, Loss: 0.12091961316764355, Validation Loss: 0.5070462226867676, Validation Accuracy: 83.33%, AUC: 0.88\n",
      "Epoch 22/100, Loss: 0.12415556609630585, Validation Loss: 0.4928738474845886, Validation Accuracy: 83.33%, AUC: 0.89\n",
      "Epoch 23/100, Loss: 0.12063780426979065, Validation Loss: 0.507926344871521, Validation Accuracy: 83.33%, AUC: 0.89\n",
      "Epoch 24/100, Loss: 0.11245545248190562, Validation Loss: 0.5303104519844055, Validation Accuracy: 83.33%, AUC: 0.89\n",
      "Epoch 25/100, Loss: 0.14571580539147058, Validation Loss: 0.5433207750320435, Validation Accuracy: 83.33%, AUC: 0.89\n",
      "Epoch 26/100, Loss: 0.3025161375602086, Validation Loss: 0.6472265124320984, Validation Accuracy: 77.78%, AUC: 0.86\n",
      "Epoch 27/100, Loss: 0.13125397761662802, Validation Loss: 0.5996613502502441, Validation Accuracy: 77.78%, AUC: 0.84\n",
      "Epoch 28/100, Loss: 0.09592746074000995, Validation Loss: 0.5860036611557007, Validation Accuracy: 77.78%, AUC: 0.89\n",
      "Epoch 29/100, Loss: 0.10176376129190128, Validation Loss: 0.5871002078056335, Validation Accuracy: 77.78%, AUC: 0.84\n",
      "Epoch 30/100, Loss: 0.17588928962747255, Validation Loss: 0.6133002638816833, Validation Accuracy: 77.78%, AUC: 0.84\n",
      "Early stopping at epoch 30\n",
      "Final Accuracy for fold 1: 83.33%\n",
      "Final Precision for fold 1: 0.71\n",
      "Final Recall for fold 1: 0.77\n",
      "Final F1-Score for fold 1: 0.72\n",
      "Final AUC for fold 1: 0.84\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/100, Loss: 0.7458343903223673, Validation Loss: 0.6942117810249329, Validation Accuracy: 38.89%, AUC: 0.60\n",
      "Epoch 2/100, Loss: 0.5860548814137777, Validation Loss: 0.6677489280700684, Validation Accuracy: 66.67%, AUC: 0.50\n",
      "Epoch 3/100, Loss: 0.5049010117848715, Validation Loss: 0.6454921960830688, Validation Accuracy: 55.56%, AUC: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\detectlie\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Loss: 0.41754483183224994, Validation Loss: 0.6461873054504395, Validation Accuracy: 50.00%, AUC: 0.66\n",
      "Epoch 5/100, Loss: 0.34874128301938373, Validation Loss: 0.6759926080703735, Validation Accuracy: 66.67%, AUC: 0.68\n",
      "Epoch 6/100, Loss: 0.3288443088531494, Validation Loss: 0.6626077890396118, Validation Accuracy: 72.22%, AUC: 0.72\n",
      "Epoch 7/100, Loss: 0.43387940526008606, Validation Loss: 0.5666847229003906, Validation Accuracy: 72.22%, AUC: 0.84\n",
      "Epoch 8/100, Loss: 0.3355404684940974, Validation Loss: 0.488547682762146, Validation Accuracy: 77.78%, AUC: 0.80\n",
      "Epoch 9/100, Loss: 0.2894390920797984, Validation Loss: 0.4291003346443176, Validation Accuracy: 83.33%, AUC: 0.80\n",
      "Epoch 10/100, Loss: 0.261380930741628, Validation Loss: 0.4704250693321228, Validation Accuracy: 88.89%, AUC: 0.78\n",
      "Epoch 11/100, Loss: 0.23963954548041025, Validation Loss: 0.525185227394104, Validation Accuracy: 88.89%, AUC: 0.76\n",
      "Epoch 12/100, Loss: 0.15991431723038355, Validation Loss: 0.561599850654602, Validation Accuracy: 83.33%, AUC: 0.76\n",
      "Epoch 13/100, Loss: 0.14498999218146005, Validation Loss: 0.5822719931602478, Validation Accuracy: 83.33%, AUC: 0.76\n",
      "Epoch 14/100, Loss: 0.13298545281092325, Validation Loss: 0.6016373038291931, Validation Accuracy: 83.33%, AUC: 0.78\n",
      "Epoch 15/100, Loss: 0.1731784666577975, Validation Loss: 0.5723239779472351, Validation Accuracy: 83.33%, AUC: 0.80\n",
      "Epoch 16/100, Loss: 0.11522277941306432, Validation Loss: 0.605466365814209, Validation Accuracy: 83.33%, AUC: 0.84\n",
      "Epoch 17/100, Loss: 0.1130954883992672, Validation Loss: 0.6284453272819519, Validation Accuracy: 88.89%, AUC: 0.86\n",
      "Epoch 18/100, Loss: 0.18009979277849197, Validation Loss: 0.723375678062439, Validation Accuracy: 72.22%, AUC: 0.88\n",
      "Epoch 19/100, Loss: 0.14145527283350626, Validation Loss: 0.7036942839622498, Validation Accuracy: 66.67%, AUC: 0.88\n",
      "Epoch 20/100, Loss: 0.14772035429875055, Validation Loss: 0.699497401714325, Validation Accuracy: 72.22%, AUC: 0.88\n",
      "Epoch 21/100, Loss: 0.1271361360947291, Validation Loss: 0.7220723628997803, Validation Accuracy: 77.78%, AUC: 0.85\n",
      "Epoch 22/100, Loss: 0.13557745516300201, Validation Loss: 0.6979886889457703, Validation Accuracy: 77.78%, AUC: 0.88\n",
      "Epoch 23/100, Loss: 0.07988518600662549, Validation Loss: 0.7352957129478455, Validation Accuracy: 66.67%, AUC: 0.88\n",
      "Epoch 24/100, Loss: 0.10901716103156407, Validation Loss: 0.6789132952690125, Validation Accuracy: 72.22%, AUC: 0.88\n",
      "Epoch 25/100, Loss: 0.08810386061668396, Validation Loss: 0.6457818150520325, Validation Accuracy: 72.22%, AUC: 0.86\n",
      "Epoch 26/100, Loss: 0.07398876609901588, Validation Loss: 0.6261669993400574, Validation Accuracy: 77.78%, AUC: 0.86\n",
      "Epoch 27/100, Loss: 0.10206005908548832, Validation Loss: 0.6767962574958801, Validation Accuracy: 77.78%, AUC: 0.84\n",
      "Epoch 28/100, Loss: 0.1678013615310192, Validation Loss: 0.5823039412498474, Validation Accuracy: 83.33%, AUC: 0.88\n",
      "Epoch 29/100, Loss: 0.07744525124629338, Validation Loss: 0.5184375047683716, Validation Accuracy: 88.89%, AUC: 0.86\n",
      "Epoch 30/100, Loss: 0.07887234042088191, Validation Loss: 0.5712926983833313, Validation Accuracy: 88.89%, AUC: 0.85\n",
      "Early stopping at epoch 30\n",
      "Final Accuracy for fold 2: 88.89%\n",
      "Final Precision for fold 2: 0.89\n",
      "Final Recall for fold 2: 0.89\n",
      "Final F1-Score for fold 2: 0.89\n",
      "Final AUC for fold 2: 0.85\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/100, Loss: 0.8157772819201151, Validation Loss: 0.6744129657745361, Validation Accuracy: 66.67%, AUC: 0.69\n",
      "Epoch 2/100, Loss: 0.6570220788319906, Validation Loss: 0.6444587707519531, Validation Accuracy: 61.11%, AUC: 0.84\n",
      "Epoch 3/100, Loss: 0.5816290378570557, Validation Loss: 0.5621191263198853, Validation Accuracy: 94.44%, AUC: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\detectlie\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Loss: 0.5184783438841502, Validation Loss: 0.4995233118534088, Validation Accuracy: 94.44%, AUC: 0.97\n",
      "Epoch 5/100, Loss: 0.4785986344019572, Validation Loss: 0.41728702187538147, Validation Accuracy: 94.44%, AUC: 0.99\n",
      "Epoch 6/100, Loss: 0.4291989902655284, Validation Loss: 0.32324132323265076, Validation Accuracy: 94.44%, AUC: 0.99\n",
      "Epoch 7/100, Loss: 0.3695099949836731, Validation Loss: 0.29678136110305786, Validation Accuracy: 94.44%, AUC: 0.99\n",
      "Epoch 8/100, Loss: 0.3941962917645772, Validation Loss: 0.27829065918922424, Validation Accuracy: 88.89%, AUC: 0.99\n",
      "Epoch 9/100, Loss: 0.3949030538400014, Validation Loss: 0.23695942759513855, Validation Accuracy: 94.44%, AUC: 0.99\n",
      "Epoch 10/100, Loss: 0.28111350536346436, Validation Loss: 0.2014644742012024, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 11/100, Loss: 0.2911706864833832, Validation Loss: 0.17360498011112213, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 12/100, Loss: 0.2537191982070605, Validation Loss: 0.16859865188598633, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 13/100, Loss: 0.23994386196136475, Validation Loss: 0.16907256841659546, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 14/100, Loss: 0.30502240856488544, Validation Loss: 0.18398839235305786, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 15/100, Loss: 0.26123357315858203, Validation Loss: 0.17941072583198547, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 16/100, Loss: 0.17818315823872885, Validation Loss: 0.16113483905792236, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 17/100, Loss: 0.18174511939287186, Validation Loss: 0.16085189580917358, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 18/100, Loss: 0.17701244602600733, Validation Loss: 0.15500058233737946, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 19/100, Loss: 0.16121557851632437, Validation Loss: 0.13976450264453888, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 20/100, Loss: 0.155171071489652, Validation Loss: 0.13904441893100739, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 21/100, Loss: 0.18895638485749564, Validation Loss: 0.14128711819648743, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 22/100, Loss: 0.13477535794178644, Validation Loss: 0.1582275927066803, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 23/100, Loss: 0.12636457631985346, Validation Loss: 0.16385644674301147, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 24/100, Loss: 0.2788388356566429, Validation Loss: 0.1593543142080307, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 25/100, Loss: 0.12907845775286356, Validation Loss: 0.17268095910549164, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 26/100, Loss: 0.10167486282686393, Validation Loss: 0.16062600910663605, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 27/100, Loss: 0.11554795131087303, Validation Loss: 0.14453451335430145, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 28/100, Loss: 0.11457076917092006, Validation Loss: 0.12550373375415802, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 29/100, Loss: 0.11581478019555409, Validation Loss: 0.11140778660774231, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Epoch 30/100, Loss: 0.10471936812003453, Validation Loss: 0.1095687597990036, Validation Accuracy: 100.00%, AUC: 1.00\n",
      "Early stopping at epoch 30\n",
      "Final Accuracy for fold 3: 100.00%\n",
      "Final Precision for fold 3: 1.00\n",
      "Final Recall for fold 3: 1.00\n",
      "Final F1-Score for fold 3: 1.00\n",
      "Final AUC for fold 3: 1.00\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/100, Loss: 0.7530299623807272, Validation Loss: 0.6875835657119751, Validation Accuracy: 38.89%, AUC: 0.70\n",
      "Epoch 2/100, Loss: 0.5090283552805582, Validation Loss: 0.6909734606742859, Validation Accuracy: 55.56%, AUC: 0.66\n",
      "Epoch 3/100, Loss: 0.4573296705881755, Validation Loss: 0.6947743892669678, Validation Accuracy: 55.56%, AUC: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\detectlie\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Loss: 0.5683049658934275, Validation Loss: 0.652737021446228, Validation Accuracy: 61.11%, AUC: 0.69\n",
      "Epoch 5/100, Loss: 0.3951188127199809, Validation Loss: 0.5815105438232422, Validation Accuracy: 77.78%, AUC: 0.75\n",
      "Epoch 6/100, Loss: 0.3656119604905446, Validation Loss: 0.5720276832580566, Validation Accuracy: 77.78%, AUC: 0.81\n",
      "Epoch 7/100, Loss: 0.29989171028137207, Validation Loss: 0.5994699597358704, Validation Accuracy: 88.89%, AUC: 0.79\n",
      "Epoch 8/100, Loss: 0.36214444041252136, Validation Loss: 0.6168983578681946, Validation Accuracy: 72.22%, AUC: 0.80\n",
      "Epoch 9/100, Loss: 0.29865515728791553, Validation Loss: 0.5246726870536804, Validation Accuracy: 88.89%, AUC: 0.80\n",
      "Epoch 10/100, Loss: 0.2010005588332812, Validation Loss: 0.47496169805526733, Validation Accuracy: 83.33%, AUC: 0.81\n",
      "Epoch 11/100, Loss: 0.2372224728266398, Validation Loss: 0.4699316918849945, Validation Accuracy: 83.33%, AUC: 0.81\n",
      "Epoch 12/100, Loss: 0.1903054416179657, Validation Loss: 0.5026645660400391, Validation Accuracy: 77.78%, AUC: 0.79\n",
      "Epoch 13/100, Loss: 0.16546222567558289, Validation Loss: 0.5379487872123718, Validation Accuracy: 77.78%, AUC: 0.79\n",
      "Epoch 14/100, Loss: 0.1827587534983953, Validation Loss: 0.5415843725204468, Validation Accuracy: 77.78%, AUC: 0.82\n",
      "Epoch 15/100, Loss: 0.16043191899855933, Validation Loss: 0.49324941635131836, Validation Accuracy: 77.78%, AUC: 0.84\n",
      "Epoch 16/100, Loss: 0.2443117598692576, Validation Loss: 0.3790746033191681, Validation Accuracy: 88.89%, AUC: 0.84\n",
      "Epoch 17/100, Loss: 0.1489541381597519, Validation Loss: 0.35940009355545044, Validation Accuracy: 88.89%, AUC: 0.85\n",
      "Epoch 18/100, Loss: 0.1664749135573705, Validation Loss: 0.35220369696617126, Validation Accuracy: 88.89%, AUC: 0.85\n",
      "Epoch 19/100, Loss: 0.12326157341400783, Validation Loss: 0.38306477665901184, Validation Accuracy: 88.89%, AUC: 0.85\n",
      "Epoch 20/100, Loss: 0.1398650531967481, Validation Loss: 0.4177525043487549, Validation Accuracy: 83.33%, AUC: 0.85\n",
      "Epoch 21/100, Loss: 0.16159448772668839, Validation Loss: 0.48576033115386963, Validation Accuracy: 77.78%, AUC: 0.85\n",
      "Epoch 22/100, Loss: 0.12210168192783992, Validation Loss: 0.5487499237060547, Validation Accuracy: 77.78%, AUC: 0.85\n",
      "Epoch 23/100, Loss: 0.11843867351611455, Validation Loss: 0.5291722416877747, Validation Accuracy: 77.78%, AUC: 0.84\n",
      "Epoch 24/100, Loss: 0.11439151813586552, Validation Loss: 0.5559667944908142, Validation Accuracy: 77.78%, AUC: 0.85\n",
      "Epoch 25/100, Loss: 0.15035036951303482, Validation Loss: 0.5621166229248047, Validation Accuracy: 77.78%, AUC: 0.85\n",
      "Epoch 26/100, Loss: 0.12743335962295532, Validation Loss: 0.6649718284606934, Validation Accuracy: 77.78%, AUC: 0.85\n",
      "Epoch 27/100, Loss: 0.1221200277407964, Validation Loss: 0.7713233232498169, Validation Accuracy: 77.78%, AUC: 0.85\n",
      "Early stopping at epoch 27\n",
      "Final Accuracy for fold 4: 88.89%\n",
      "Final Precision for fold 4: 0.78\n",
      "Final Recall for fold 4: 0.78\n",
      "Final F1-Score for fold 4: 0.78\n",
      "Final AUC for fold 4: 0.85\n",
      "\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\detectlie\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.8577163418134054, Validation Loss: 0.6934369802474976, Validation Accuracy: 50.00%, AUC: 0.34\n",
      "Epoch 2/100, Loss: 0.6622242331504822, Validation Loss: 0.7093409895896912, Validation Accuracy: 33.33%, AUC: 0.73\n",
      "Epoch 3/100, Loss: 0.5073525110880533, Validation Loss: 0.6601888537406921, Validation Accuracy: 66.67%, AUC: 0.71\n",
      "Epoch 4/100, Loss: 0.5666225751241049, Validation Loss: 0.6272764801979065, Validation Accuracy: 72.22%, AUC: 0.68\n",
      "Epoch 5/100, Loss: 0.4282403488953908, Validation Loss: 0.6139181852340698, Validation Accuracy: 66.67%, AUC: 0.80\n",
      "Epoch 6/100, Loss: 0.36879361669222516, Validation Loss: 0.5994619727134705, Validation Accuracy: 72.22%, AUC: 0.86\n",
      "Epoch 7/100, Loss: 0.30099841952323914, Validation Loss: 0.5856037139892578, Validation Accuracy: 72.22%, AUC: 0.86\n",
      "Epoch 8/100, Loss: 0.284267783164978, Validation Loss: 0.5881832242012024, Validation Accuracy: 72.22%, AUC: 0.88\n",
      "Epoch 9/100, Loss: 0.2867511808872223, Validation Loss: 0.5895050764083862, Validation Accuracy: 72.22%, AUC: 0.84\n",
      "Epoch 10/100, Loss: 0.2562238921721776, Validation Loss: 0.6053907871246338, Validation Accuracy: 72.22%, AUC: 0.84\n",
      "Epoch 11/100, Loss: 0.18403094758590063, Validation Loss: 0.6073217391967773, Validation Accuracy: 72.22%, AUC: 0.80\n",
      "Epoch 12/100, Loss: 0.1981074015299479, Validation Loss: 0.6389449834823608, Validation Accuracy: 72.22%, AUC: 0.80\n",
      "Epoch 13/100, Loss: 0.18603414545456567, Validation Loss: 0.6813229322433472, Validation Accuracy: 72.22%, AUC: 0.80\n",
      "Epoch 14/100, Loss: 0.16508571555217108, Validation Loss: 0.7124720811843872, Validation Accuracy: 72.22%, AUC: 0.82\n",
      "Epoch 15/100, Loss: 0.1395083318154017, Validation Loss: 0.8069310784339905, Validation Accuracy: 72.22%, AUC: 0.84\n",
      "Epoch 16/100, Loss: 0.15412132938702902, Validation Loss: 0.8301746249198914, Validation Accuracy: 72.22%, AUC: 0.80\n",
      "Epoch 17/100, Loss: 0.10710776969790459, Validation Loss: 0.8720120787620544, Validation Accuracy: 72.22%, AUC: 0.75\n",
      "Epoch 18/100, Loss: 0.11046370429297288, Validation Loss: 0.9500517249107361, Validation Accuracy: 72.22%, AUC: 0.79\n",
      "Epoch 19/100, Loss: 0.1061621146897475, Validation Loss: 0.9587286710739136, Validation Accuracy: 72.22%, AUC: 0.82\n",
      "Epoch 20/100, Loss: 0.1121411845088005, Validation Loss: 0.8675982356071472, Validation Accuracy: 72.22%, AUC: 0.80\n",
      "Epoch 21/100, Loss: 0.09282296399275462, Validation Loss: 0.9241490364074707, Validation Accuracy: 72.22%, AUC: 0.79\n",
      "Epoch 22/100, Loss: 0.10703317696849506, Validation Loss: 0.9106029272079468, Validation Accuracy: 72.22%, AUC: 0.82\n",
      "Epoch 23/100, Loss: 0.21262306720018387, Validation Loss: 0.9069608449935913, Validation Accuracy: 72.22%, AUC: 0.79\n",
      "Epoch 24/100, Loss: 0.10128387560447057, Validation Loss: 1.0107405185699463, Validation Accuracy: 72.22%, AUC: 0.77\n",
      "Early stopping at epoch 24\n",
      "Final Accuracy for fold 5: 72.22%\n",
      "Final Precision for fold 5: 0.72\n",
      "Final Recall for fold 5: 0.82\n",
      "Final F1-Score for fold 5: 0.70\n",
      "Final AUC for fold 5: 0.77\n",
      "\n",
      "Average Accuracy: 86.67%\n",
      "Average Precision: 0.82\n",
      "Average Recall: 0.85\n",
      "Average F1-Score: 0.82\n",
      "Average AUC: 0.86\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Define constants\n",
    "DATA_DIR = 'C:/Users/User/Documents/Lie detect data/EEGData'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100  # Increased to allow early stopping\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_FOLDS = 5\n",
    "PATIENCE = 20  # Early stopping patience\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Custom Dataset class for EEG data\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.load_data(data_dir)\n",
    "        self.normalize_data()\n",
    "\n",
    "    def load_data(self, data_dir):\n",
    "        max_length = 0\n",
    "        temp_data = []\n",
    "        \n",
    "        for file_name in os.listdir(data_dir):\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                eeg_data = pickle.load(f)\n",
    "                label = 1 if 'lie' in file_name else 0  # Assuming file names contain 'lie' or 'truth'\n",
    "                temp_data.append((eeg_data, label))\n",
    "                max_length = max(max_length, eeg_data.shape[1])\n",
    "\n",
    "        for eeg_data, label in temp_data:\n",
    "            padded_data = np.pad(eeg_data, ((0, 0), (0, max_length - eeg_data.shape[1])), mode='constant')\n",
    "            self.data.append(padded_data)\n",
    "            self.labels.append(label)\n",
    "        \n",
    "        self.data = [torch.tensor(d, dtype=torch.float32, device=device) for d in self.data]\n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.long, device=device)\n",
    "    \n",
    "    def normalize_data(self):\n",
    "        all_data = torch.cat([d.unsqueeze(0) for d in self.data], dim=0)\n",
    "        mean = all_data.mean()\n",
    "        std = all_data.std()\n",
    "        self.data = [(d - mean) / std for d in self.data]\n",
    "\n",
    "    def augment_data(self, data):\n",
    "        # Advanced augmentations: Gaussian noise, time shift, scaling\n",
    "        noise = torch.randn_like(data, device=device) * 0.01\n",
    "        shift = torch.roll(data, shifts=int(data.shape[1] * 0.1), dims=1)\n",
    "        scale = data * (1 + 0.1 * torch.randn(1, device=device))\n",
    "        return noise + shift + scale\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.data[idx], self.labels[idx]\n",
    "        data = self.augment_data(data)  # Apply augmentation\n",
    "        return data, label\n",
    "\n",
    "# Define the EEGNet model\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.firstconv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, (1, 51), padding=(0, 25)),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "        self.depthwiseConv = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, (65, 1), groups=16),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d((1, 4)),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.separableConv = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, (1, 15), padding=(0, 7)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d((1, 8)),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(output_size, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.firstconv(x)\n",
    "        x = self.depthwiseConv(x)\n",
    "        x = self.separableConv(x)\n",
    "        return self.classify(x)\n",
    "\n",
    "# Function to determine the output size of the EEGNet model before the linear layer\n",
    "def get_output_size(model, shape):\n",
    "    with torch.no_grad():\n",
    "        x = torch.zeros(shape, device=device)\n",
    "        x = model.firstconv(x)\n",
    "        x = model.depthwiseConv(x)\n",
    "        x = model.separableConv(x)\n",
    "        return x.view(x.size(0), -1).size(1)\n",
    "\n",
    "# Load data\n",
    "dataset = EEGDataset(DATA_DIR)\n",
    "\n",
    "# Determine the correct input size for the linear layer\n",
    "dummy_input_shape = (1, 1, 65, max([d.shape[1] for d in dataset.data]))  # (batch_size, channels, height, width)\n",
    "output_size = get_output_size(EEGNet(output_size=0).to(device), dummy_input_shape)\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(dataset)):\n",
    "    print(f'Fold {fold+1}')\n",
    "\n",
    "    # Creating train and validation samplers\n",
    "    train_sampler = SubsetRandomSampler(train_index)\n",
    "    val_sampler = SubsetRandomSampler(val_index)\n",
    "\n",
    "    # Creating DataLoaders\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=val_sampler)\n",
    "\n",
    "    # Calculate class weights based on training data\n",
    "    train_labels = [dataset[i][1].cpu().numpy() for i in train_index]  # Move to CPU and convert to NumPy array\n",
    "    class_counts = np.bincount(train_labels)\n",
    "    class_weights = 1. / class_counts\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = EEGNet(output_size=output_size).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
    "\n",
    "    best_val_accuracy = 0\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.unsqueeze(1))  # Adding channel dimension\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Scheduler step based on running loss\n",
    "        scheduler.step(running_loss)\n",
    "\n",
    "        # Intermediate validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        all_probs = []\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs.unsqueeze(1))  # Adding channel dimension\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_probs.extend(torch.softmax(outputs, dim=1)[:, 1].cpu().numpy())  # Get the probability of class 1\n",
    "\n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_precision = precision_score(all_labels, all_predictions, average='macro')\n",
    "        val_recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "        val_f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "        val_auc = roc_auc_score(all_labels, all_probs)  # Calculate AUC score\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss/len(train_loader)}, Validation Loss: {val_running_loss/len(val_loader)}, Validation Accuracy: {val_accuracy:.2f}%, AUC: {val_auc:.2f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            patience_counter = 0\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), f\"best_model_fold_{fold+1}.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    # Final validation metrics for the fold\n",
    "    accuracies.append(best_val_accuracy)\n",
    "    precisions.append(val_precision)\n",
    "    recalls.append(val_recall)\n",
    "    f1s.append(val_f1)\n",
    "    aucs.append(val_auc)\n",
    "    print(f'Final Accuracy for fold {fold+1}: {best_val_accuracy:.2f}%')\n",
    "    print(f'Final Precision for fold {fold+1}: {val_precision:.2f}')\n",
    "    print(f'Final Recall for fold {fold+1}: {val_recall:.2f}')\n",
    "    print(f'Final F1-Score for fold {fold+1}: {val_f1:.2f}')\n",
    "    print(f'Final AUC for fold {fold+1}: {val_auc:.2f}\\n')\n",
    "\n",
    "# Report average performance across all folds\n",
    "print(f'Average Accuracy: {np.mean(accuracies):.2f}%')\n",
    "print(f'Average Precision: {np.mean(precisions):.2f}')\n",
    "print(f'Average Recall: {np.mean(recalls):.2f}')\n",
    "print(f'Average F1-Score: {np.mean(f1s):.2f}')\n",
    "print(f'Average AUC: {np.mean(aucs):.2f}')\n",
    "\n",
    "\n",
    "# Print confusion matrices for each fold\n",
    "for i, cm in enumerate(confusion_matrices):\n",
    "    print(f'Confusion Matrix for fold {i+1}:')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be073223-299e-46c3-a156-1f38fb1b9379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
