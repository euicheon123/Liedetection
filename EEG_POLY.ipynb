{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1159f92-96e7-4f79-9cd1-ec348c0a4b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG data...\n",
      "EEG File: augmented_lie_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_10.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_11.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_12.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_13.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_14.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_15.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_16.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_17.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_19.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_2.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_20.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_21.pkl, Shape: (17, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_22.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_23.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_24.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_25.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_26.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_27.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_28.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_29.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_3.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_30.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_31.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_33.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_34.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_4.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_5.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_6.pkl, Shape: (26, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_7.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_8.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_9.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_10.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_11.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_12.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_13.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_14.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_15.pkl, Shape: (4, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_16.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_17.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_19.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_2.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_20.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_21.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_22.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_23.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_24.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_25.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_26.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_27.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_28.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_29.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_3.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_30.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_31.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_33.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_34.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_36.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_37.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_38.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_39.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_4.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_40.pkl, Shape: (30, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_41.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_42.pkl, Shape: (18, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_43.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_44.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_45.pkl, Shape: (14, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_46.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_47.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_48.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_49.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_5.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_50.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_51.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_52.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_53.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_54.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_55.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_6.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_7.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_8.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_9.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "Loaded from EEG C:\\Users\\User\\Documents\\Lie detect data\\AugmentedEEGData: 333 lie samples, 602 truth samples\n",
      "Loading Poly data...\n",
      "Poly File: poly_lie_1.pkl, Shape: (4, 2963), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_10.pkl, Shape: (4, 3171), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_11.pkl, Shape: (4, 2917), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_12.pkl, Shape: (4, 2991), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_13.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_14.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_15.pkl, Shape: (4, 2929), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_16.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_17.pkl, Shape: (4, 3234), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_18.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_19.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_2.pkl, Shape: (4, 2895), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_20.pkl, Shape: (4, 3291), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_21.pkl, Shape: (4, 3658), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_22.pkl, Shape: (4, 3375), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_23.pkl, Shape: (4, 3334), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_24.pkl, Shape: (4, 3263), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_25.pkl, Shape: (4, 3292), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_26.pkl, Shape: (4, 3246), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_27.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_28.pkl, Shape: (4, 3262), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_29.pkl, Shape: (4, 3321), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_3.pkl, Shape: (4, 2941), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_30.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_31.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_32.pkl, Shape: (4, 3142), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_33.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_34.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_35.pkl, Shape: (4, 3179), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_4.pkl, Shape: (4, 2967), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_5.pkl, Shape: (4, 2913), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_6.pkl, Shape: (4, 4229), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_7.pkl, Shape: (4, 3129), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_8.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_9.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_1.pkl, Shape: (4, 2958), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_10.pkl, Shape: (4, 3104), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_11.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_12.pkl, Shape: (4, 3391), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_13.pkl, Shape: (4, 3141), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_14.pkl, Shape: (4, 3271), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_15.pkl, Shape: (4, 2859), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_16.pkl, Shape: (4, 3325), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_17.pkl, Shape: (4, 3383), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_18.pkl, Shape: (4, 3233), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_19.pkl, Shape: (4, 3366), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_2.pkl, Shape: (4, 3112), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_20.pkl, Shape: (4, 3313), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_21.pkl, Shape: (4, 3555), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_22.pkl, Shape: (4, 3346), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_23.pkl, Shape: (4, 3305), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_24.pkl, Shape: (4, 3200), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_25.pkl, Shape: (4, 3213), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_26.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_27.pkl, Shape: (4, 3188), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_28.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_29.pkl, Shape: (4, 3242), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_3.pkl, Shape: (4, 3016), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_30.pkl, Shape: (4, 3258), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_31.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_32.pkl, Shape: (4, 3175), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_33.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_34.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_35.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_36.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_37.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_38.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_39.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_4.pkl, Shape: (4, 3058), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_40.pkl, Shape: (4, 4475), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_41.pkl, Shape: (4, 3162), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_42.pkl, Shape: (4, 3704), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_43.pkl, Shape: (4, 3333), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_44.pkl, Shape: (4, 3396), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_45.pkl, Shape: (4, 3450), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_46.pkl, Shape: (4, 3537), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_47.pkl, Shape: (4, 3363), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_48.pkl, Shape: (4, 3250), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_49.pkl, Shape: (4, 3279), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_5.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_50.pkl, Shape: (4, 3508), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_51.pkl, Shape: (4, 3358), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_52.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_53.pkl, Shape: (4, 3379), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_54.pkl, Shape: (4, 3558), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_55.pkl, Shape: (4, 3392), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_6.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_7.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_8.pkl, Shape: (4, 3096), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_9.pkl, Shape: (4, 3225), Type: <class 'numpy.ndarray'>\n",
      "Loaded from Poly C:\\Users\\User\\Documents\\Lie detect data\\CombinedPolyData: 35 lie samples, 55 truth samples\n",
      "EEG Class distribution: {0: 333, 1: 602}\n",
      "Poly Class distribution: {0: 35, 1: 55}\n",
      "EEG data shape: (935, 65, 125)\n",
      "Poly data shape: (90, 4, 4475)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "\n",
    "# Constants\n",
    "EEG_DATA_DIR = r'C:\\Users\\User\\Documents\\Lie detect data\\AugmentedEEGData'\n",
    "POLY_DATA_DIR = r'C:\\Users\\User\\Documents\\Lie detect data\\CombinedPolyData'\n",
    "K_FOLDS = 5  # Number of folds for cross-validation\n",
    "\n",
    "def pad_sequence(sequence, target_length):\n",
    "    \"\"\"Pad the sequence to the target length.\"\"\"\n",
    "    pad_length = target_length - sequence.shape[1]\n",
    "    if pad_length > 0:\n",
    "        return np.pad(sequence, ((0, 0), (0, pad_length)), mode='constant')\n",
    "    else:\n",
    "        return sequence[:, :target_length]\n",
    "\n",
    "def load_eeg_data(data_dir):\n",
    "    X, y = [], []\n",
    "    lie_count, truth_count = 0, 0\n",
    "    file_sample_counts = []\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        if file_name.endswith('.pkl'):\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            try:\n",
    "                data = pd.read_pickle(file_path)\n",
    "                print(f\"EEG File: {file_name}, Shape: {data.shape}, Type: {type(data)}\")\n",
    "                label = 0 if 'lie' in file_name.lower() else 1\n",
    "                X.extend(data)\n",
    "                y.extend([label] * data.shape[0])\n",
    "                file_sample_counts.append(data.shape[0])\n",
    "                if label == 0:\n",
    "                    lie_count += data.shape[0]\n",
    "                else:\n",
    "                    truth_count += data.shape[0]\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading EEG file {file_name}: {str(e)}\")\n",
    "    print(f\"Loaded from EEG {data_dir}: {lie_count} lie samples, {truth_count} truth samples\")\n",
    "    return np.array(X), np.array(y), file_sample_counts\n",
    "\n",
    "def load_poly_data(data_dir):\n",
    "    X, y = [], []\n",
    "    lie_count, truth_count = 0, 0\n",
    "    max_length = 0\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        if file_name.endswith('.pkl'):\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            try:\n",
    "                data = pd.read_pickle(file_path)\n",
    "                print(f\"Poly File: {file_name}, Shape: {data.shape}, Type: {type(data)}\")\n",
    "                max_length = max(max_length, data.shape[1])\n",
    "                label = 0 if 'lie' in file_name.lower() else 1\n",
    "                X.append(data)\n",
    "                y.append(label)\n",
    "                if label == 0:\n",
    "                    lie_count += 1\n",
    "                else:\n",
    "                    truth_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading Poly file {file_name}: {str(e)}\")\n",
    "    print(f\"Loaded from Poly {data_dir}: {lie_count} lie samples, {truth_count} truth samples\")\n",
    "    \n",
    "    # Pad all poly samples to the maximum length\n",
    "    X_padded = np.array([pad_sequence(x, max_length) for x in X])\n",
    "    return X_padded, np.array(y)\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, eeg_X, eeg_y, poly_X, poly_y, file_sample_counts):\n",
    "        self.eeg_X = torch.tensor(eeg_X, dtype=torch.float32)\n",
    "        self.eeg_y = torch.tensor(eeg_y, dtype=torch.long)\n",
    "        self.poly_X = torch.tensor(poly_X, dtype=torch.float32)\n",
    "        self.poly_y = torch.tensor(poly_y, dtype=torch.long)\n",
    "        \n",
    "        # Create a mapping from EEG sample index to Poly file index\n",
    "        self.eeg_to_poly_map = []\n",
    "        poly_index = 0\n",
    "        for count in file_sample_counts:\n",
    "            self.eeg_to_poly_map.extend([poly_index] * count)\n",
    "            poly_index += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eeg_X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg_sample = self.eeg_X[idx]\n",
    "        eeg_label = self.eeg_y[idx]\n",
    "        poly_idx = self.eeg_to_poly_map[idx]\n",
    "        poly_sample = self.poly_X[poly_idx]\n",
    "        poly_label = self.poly_y[poly_idx]\n",
    "        \n",
    "        return eeg_sample, eeg_label, poly_sample, poly_label\n",
    "\n",
    "def create_file_based_splits(file_sample_counts, n_splits=5):\n",
    "    file_indices = np.arange(len(file_sample_counts))\n",
    "    group_kfold = GroupKFold(n_splits=n_splits)\n",
    "    return list(group_kfold.split(X=file_indices, groups=file_indices))\n",
    "\n",
    "# Load data\n",
    "print(\"Loading EEG data...\")\n",
    "eeg_X, eeg_y, file_sample_counts = load_eeg_data(EEG_DATA_DIR)\n",
    "print(\"Loading Poly data...\")\n",
    "poly_X, poly_y = load_poly_data(POLY_DATA_DIR)\n",
    "\n",
    "# Check for class imbalance\n",
    "unique, counts = np.unique(eeg_y, return_counts=True)\n",
    "print(\"EEG Class distribution:\", dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(poly_y, return_counts=True)\n",
    "print(\"Poly Class distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "# Print dataset size and shapes\n",
    "print(\"EEG data shape:\", eeg_X.shape)\n",
    "print(\"Poly data shape:\", poly_X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "807dc975-266c-4193-ac4b-3c69be28d126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG data...\n",
      "EEG File: augmented_lie_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_10.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_11.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_12.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_13.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_14.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_15.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_16.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_17.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_19.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_2.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_20.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_21.pkl, Shape: (17, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_22.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_23.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_24.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_25.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_26.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_27.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_28.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_29.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_3.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_30.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_31.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_33.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_34.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_4.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_5.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_6.pkl, Shape: (26, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_7.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_8.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_9.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_10.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_11.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_12.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_13.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_14.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_15.pkl, Shape: (4, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_16.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_17.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_19.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_2.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_20.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_21.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_22.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_23.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_24.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_25.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_26.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_27.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_28.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_29.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_3.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_30.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_31.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_33.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_34.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_36.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_37.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_38.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_39.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_4.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_40.pkl, Shape: (30, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_41.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_42.pkl, Shape: (18, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_43.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_44.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_45.pkl, Shape: (14, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_46.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_47.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_48.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_49.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_5.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_50.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_51.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_52.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_53.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_54.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_55.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_6.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_7.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_8.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_9.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "Loaded from EEG C:\\Users\\User\\Documents\\Lie detect data\\AugmentedEEGData: 333 lie samples, 602 truth samples\n",
      "Loading Poly data...\n",
      "Poly File: poly_lie_1.pkl, Shape: (4, 2963), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_10.pkl, Shape: (4, 3171), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_11.pkl, Shape: (4, 2917), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_12.pkl, Shape: (4, 2991), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_13.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_14.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_15.pkl, Shape: (4, 2929), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_16.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_17.pkl, Shape: (4, 3234), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_18.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_19.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_2.pkl, Shape: (4, 2895), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_20.pkl, Shape: (4, 3291), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_21.pkl, Shape: (4, 3658), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_22.pkl, Shape: (4, 3375), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_23.pkl, Shape: (4, 3334), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_24.pkl, Shape: (4, 3263), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_25.pkl, Shape: (4, 3292), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_26.pkl, Shape: (4, 3246), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_27.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_28.pkl, Shape: (4, 3262), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_29.pkl, Shape: (4, 3321), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_3.pkl, Shape: (4, 2941), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_30.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_31.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_32.pkl, Shape: (4, 3142), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_33.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_34.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_35.pkl, Shape: (4, 3179), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_4.pkl, Shape: (4, 2967), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_5.pkl, Shape: (4, 2913), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_6.pkl, Shape: (4, 4229), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_7.pkl, Shape: (4, 3129), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_8.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_9.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_1.pkl, Shape: (4, 2958), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_10.pkl, Shape: (4, 3104), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_11.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_12.pkl, Shape: (4, 3391), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_13.pkl, Shape: (4, 3141), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_14.pkl, Shape: (4, 3271), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_15.pkl, Shape: (4, 2859), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_16.pkl, Shape: (4, 3325), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_17.pkl, Shape: (4, 3383), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_18.pkl, Shape: (4, 3233), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_19.pkl, Shape: (4, 3366), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_2.pkl, Shape: (4, 3112), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_20.pkl, Shape: (4, 3313), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_21.pkl, Shape: (4, 3555), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_22.pkl, Shape: (4, 3346), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_23.pkl, Shape: (4, 3305), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_24.pkl, Shape: (4, 3200), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_25.pkl, Shape: (4, 3213), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_26.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_27.pkl, Shape: (4, 3188), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_28.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_29.pkl, Shape: (4, 3242), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_3.pkl, Shape: (4, 3016), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_30.pkl, Shape: (4, 3258), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_31.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_32.pkl, Shape: (4, 3175), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_33.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_34.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_35.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_36.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_37.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_38.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_39.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_4.pkl, Shape: (4, 3058), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_40.pkl, Shape: (4, 4475), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_41.pkl, Shape: (4, 3162), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_42.pkl, Shape: (4, 3704), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_43.pkl, Shape: (4, 3333), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_44.pkl, Shape: (4, 3396), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_45.pkl, Shape: (4, 3450), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_46.pkl, Shape: (4, 3537), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_47.pkl, Shape: (4, 3363), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_48.pkl, Shape: (4, 3250), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_49.pkl, Shape: (4, 3279), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_5.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_50.pkl, Shape: (4, 3508), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_51.pkl, Shape: (4, 3358), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_52.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_53.pkl, Shape: (4, 3379), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_54.pkl, Shape: (4, 3558), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_55.pkl, Shape: (4, 3392), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_6.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_7.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_8.pkl, Shape: (4, 3096), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_9.pkl, Shape: (4, 3225), Type: <class 'numpy.ndarray'>\n",
      "Loaded from Poly C:\\Users\\User\\Documents\\Lie detect data\\CombinedPolyData: 35 lie samples, 55 truth samples\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Epoch 1/50, Loss: 0.34966189165910083\n",
      "Validation Loss: 0.9500243862469991, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.8235294117647058, Recall: 0.6511627906976745, F1-score: 0.7272727272727273\n",
      "Model saved to ensemble_model_fold_0.pth\n",
      "Epoch 2/50, Loss: 0.14302464698751768\n",
      "Validation Loss: 1.3369097312291462, Validation Accuracy: 0.6574585635359116\n",
      "Precision: 0.8252427184466019, Recall: 0.6589147286821705, F1-score: 0.7327586206896551\n",
      "Epoch 3/50, Loss: 0.09480631879220407\n",
      "Validation Loss: 1.4953395128250122, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 4/50, Loss: 0.07198063687731822\n",
      "Validation Loss: 1.641299565633138, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 5/50, Loss: 0.054898328613489866\n",
      "Validation Loss: 1.784635861714681, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 6/50, Loss: 0.05214022907118002\n",
      "Validation Loss: 1.7857938607533772, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 7/50, Loss: 0.04238443495705724\n",
      "Validation Loss: 1.8242858250935872, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 8/50, Loss: 0.03641240500534574\n",
      "Validation Loss: 1.8485832611719768, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 9/50, Loss: 0.037878789162884154\n",
      "Validation Loss: 1.8450297514597576, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 10/50, Loss: 0.033946372025335826\n",
      "Validation Loss: 2.01815927028656, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 11/50, Loss: 0.029376810338969033\n",
      "Validation Loss: 1.8347973028818767, Validation Accuracy: 0.7237569060773481\n",
      "Precision: 0.8319327731092437, Recall: 0.7674418604651163, F1-score: 0.7983870967741935\n",
      "Epoch 12/50, Loss: 0.02955157224399348\n",
      "Validation Loss: 2.0532250006993613, Validation Accuracy: 0.7348066298342542\n",
      "Precision: 0.8461538461538461, Recall: 0.7674418604651163, F1-score: 0.8048780487804879\n",
      "Epoch 13/50, Loss: 0.02193357570407291\n",
      "Validation Loss: 1.9876348574956257, Validation Accuracy: 0.7182320441988951\n",
      "Precision: 0.825, Recall: 0.7674418604651163, F1-score: 0.7951807228915663\n",
      "Epoch 14/50, Loss: 0.021589671183998387\n",
      "Validation Loss: 2.071778933207194, Validation Accuracy: 0.7182320441988951\n",
      "Precision: 0.825, Recall: 0.7674418604651163, F1-score: 0.7951807228915663\n",
      "Epoch 15/50, Loss: 0.019480427416662376\n",
      "Validation Loss: 2.1002013285954795, Validation Accuracy: 0.7237569060773481\n",
      "Precision: 0.8319327731092437, Recall: 0.7674418604651163, F1-score: 0.7983870967741935\n",
      "Epoch 16/50, Loss: 0.017389971918116014\n",
      "Validation Loss: 2.173189322153727, Validation Accuracy: 0.7237569060773481\n",
      "Precision: 0.8319327731092437, Recall: 0.7674418604651163, F1-score: 0.7983870967741935\n",
      "Epoch 17/50, Loss: 0.016063306635866564\n",
      "Validation Loss: 2.2067943016688027, Validation Accuracy: 0.7182320441988951\n",
      "Precision: 0.825, Recall: 0.7674418604651163, F1-score: 0.7951807228915663\n",
      "Epoch 18/50, Loss: 0.015000568586401641\n",
      "Validation Loss: 2.1451586484909058, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 19/50, Loss: 0.01423686013246576\n",
      "Validation Loss: 2.228798786799113, Validation Accuracy: 0.7182320441988951\n",
      "Precision: 0.825, Recall: 0.7674418604651163, F1-score: 0.7951807228915663\n",
      "Epoch 20/50, Loss: 0.01323873111202071\n",
      "Validation Loss: 2.260385433832804, Validation Accuracy: 0.7182320441988951\n",
      "Precision: 0.825, Recall: 0.7674418604651163, F1-score: 0.7951807228915663\n",
      "Epoch 21/50, Loss: 0.0122109263514479\n",
      "Validation Loss: 2.2618864377339682, Validation Accuracy: 0.7182320441988951\n",
      "Precision: 0.825, Recall: 0.7674418604651163, F1-score: 0.7951807228915663\n",
      "Epoch 22/50, Loss: 0.011665102288437387\n",
      "Validation Loss: 2.3421552578608194, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 23/50, Loss: 0.010906044626608491\n",
      "Validation Loss: 2.3278889656066895, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 24/50, Loss: 0.010554296779446304\n",
      "Validation Loss: 2.3862399657567344, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 25/50, Loss: 0.01019793632440269\n",
      "Validation Loss: 2.4112801551818848, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 26/50, Loss: 0.009873401490040123\n",
      "Validation Loss: 2.4384703636169434, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 27/50, Loss: 0.00961293790411825\n",
      "Validation Loss: 2.4466131130854287, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 28/50, Loss: 0.010067155992146581\n",
      "Validation Loss: 2.4990153312683105, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 29/50, Loss: 0.007204606139566749\n",
      "Validation Loss: 2.615319569905599, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 30/50, Loss: 0.00717304398616155\n",
      "Validation Loss: 2.485670487085978, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 31/50, Loss: 0.006857066861509035\n",
      "Validation Loss: 2.595195452372233, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 32/50, Loss: 0.007474580702061455\n",
      "Validation Loss: 2.5986329714457193, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 33/50, Loss: 0.005554912281998743\n",
      "Validation Loss: 2.52021058400472, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 34/50, Loss: 0.005609572923276573\n",
      "Validation Loss: 2.622458299001058, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 35/50, Loss: 0.004948177918170889\n",
      "Validation Loss: 2.393778165181478, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 36/50, Loss: 0.004836545859385903\n",
      "Validation Loss: 2.4289667208989463, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 37/50, Loss: 0.004510165085472788\n",
      "Validation Loss: 2.446744958559672, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 38/50, Loss: 0.004430620911686371\n",
      "Validation Loss: 2.518218676249186, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 39/50, Loss: 0.004141578431396435\n",
      "Validation Loss: 2.5529836416244507, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 40/50, Loss: 0.0037812340985207507\n",
      "Validation Loss: 2.575106978416443, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 41/50, Loss: 0.003765746718272567\n",
      "Validation Loss: 2.6108290751775107, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 42/50, Loss: 0.003856736555462703\n",
      "Validation Loss: 2.6711177825927734, Validation Accuracy: 0.712707182320442\n",
      "Precision: 0.8181818181818182, Recall: 0.7674418604651163, F1-score: 0.792\n",
      "Epoch 43/50, Loss: 0.0039718953194096684\n",
      "Validation Loss: 2.5884384711583457, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 44/50, Loss: 0.0034980500931851566\n",
      "Validation Loss: 2.6728002230326333, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 45/50, Loss: 0.0030113483856742582\n",
      "Validation Loss: 2.6996273199717202, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 46/50, Loss: 0.002582956939780464\n",
      "Validation Loss: 2.7580358187357583, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 47/50, Loss: 0.003026824134091536\n",
      "Validation Loss: 2.764793078104655, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 48/50, Loss: 0.002949479516246356\n",
      "Validation Loss: 2.7785472869873047, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 49/50, Loss: 0.0027851313619369953\n",
      "Validation Loss: 2.7986618677775064, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Epoch 50/50, Loss: 0.0023509729847622416\n",
      "Validation Loss: 2.86846129099528, Validation Accuracy: 0.7071823204419889\n",
      "Precision: 0.8114754098360656, Recall: 0.7674418604651163, F1-score: 0.7888446215139442\n",
      "Validation Loss: 0.9500243862469991, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.8235294117647058, Recall: 0.6511627906976745, F1-score: 0.7272727272727273\n",
      "Confusion Matrix:\n",
      "[[34 18]\n",
      " [45 84]]\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch 1/50, Loss: 0.3185659622152646\n",
      "Validation Loss: 0.5627216051022211, Validation Accuracy: 0.8457142857142858\n",
      "Precision: 0.9081632653061225, Recall: 0.8317757009345794, F1-score: 0.8682926829268293\n",
      "Model saved to ensemble_model_fold_1.pth\n",
      "Epoch 2/50, Loss: 0.08362679990629356\n",
      "Validation Loss: 0.6973966906468073, Validation Accuracy: 0.7828571428571428\n",
      "Precision: 0.8165137614678899, Recall: 0.8317757009345794, F1-score: 0.8240740740740741\n",
      "Epoch 3/50, Loss: 0.0468068472109735\n",
      "Validation Loss: 0.8528282046318054, Validation Accuracy: 0.7771428571428571\n",
      "Precision: 0.8090909090909091, Recall: 0.8317757009345794, F1-score: 0.8202764976958525\n",
      "Epoch 4/50, Loss: 0.034112004951263465\n",
      "Validation Loss: 0.9363219837347666, Validation Accuracy: 0.7542857142857143\n",
      "Precision: 0.7807017543859649, Recall: 0.8317757009345794, F1-score: 0.8054298642533937\n",
      "Epoch 5/50, Loss: 0.02977808634750545\n",
      "Validation Loss: 1.029858152071635, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7542372881355932, Recall: 0.8317757009345794, F1-score: 0.7911111111111111\n",
      "Epoch 6/50, Loss: 0.02231430565007031\n",
      "Validation Loss: 1.0490075250466664, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 7/50, Loss: 0.021075135135712724\n",
      "Validation Loss: 1.10354549686114, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 8/50, Loss: 0.017427418458585937\n",
      "Validation Loss: 1.175800661245982, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 9/50, Loss: 0.01623785445311417\n",
      "Validation Loss: 1.2240398228168488, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 10/50, Loss: 0.014174687016444901\n",
      "Validation Loss: 1.2631135682264965, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 11/50, Loss: 0.013314968130240837\n",
      "Validation Loss: 1.3022254506746929, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 12/50, Loss: 0.011648894539879015\n",
      "Validation Loss: 1.3251683314641316, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 13/50, Loss: 0.010273328439022103\n",
      "Validation Loss: 1.3862428267796834, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 14/50, Loss: 0.009179956454318017\n",
      "Validation Loss: 1.4156353573004405, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 15/50, Loss: 0.008287467722160121\n",
      "Validation Loss: 1.4490397572517395, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 16/50, Loss: 0.007667784482085456\n",
      "Validation Loss: 1.4801947275797527, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 17/50, Loss: 0.007575401085584114\n",
      "Validation Loss: 1.5278851588567097, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 18/50, Loss: 0.006650407740380615\n",
      "Validation Loss: 1.548830509185791, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 19/50, Loss: 0.006228799970510106\n",
      "Validation Loss: 1.5698922276496887, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 20/50, Loss: 0.005554212781134993\n",
      "Validation Loss: 1.626349965731303, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 21/50, Loss: 0.005550984370832642\n",
      "Validation Loss: 1.6344741781552632, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 22/50, Loss: 0.0048440479052563505\n",
      "Validation Loss: 1.671563744544983, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 23/50, Loss: 0.004615014486868556\n",
      "Validation Loss: 1.6982109745343525, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 24/50, Loss: 0.00431543947585548\n",
      "Validation Loss: 1.7300646901130676, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 25/50, Loss: 0.004053915035910904\n",
      "Validation Loss: 1.760474681854248, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 26/50, Loss: 0.003690455681256329\n",
      "Validation Loss: 1.780032992362976, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 27/50, Loss: 0.0038505013847801215\n",
      "Validation Loss: 1.7907921274503071, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 28/50, Loss: 0.003329999337438494\n",
      "Validation Loss: 1.8199476599693298, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 29/50, Loss: 0.0030961115165458373\n",
      "Validation Loss: 1.8321660955746968, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 30/50, Loss: 0.0030207379216638706\n",
      "Validation Loss: 1.8605131308237712, Validation Accuracy: 0.7371428571428571\n",
      "Precision: 0.7606837606837606, Recall: 0.8317757009345794, F1-score: 0.7946428571428571\n",
      "Epoch 31/50, Loss: 0.0028546836838359013\n",
      "Validation Loss: 1.865099012851715, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 32/50, Loss: 0.00275697025062982\n",
      "Validation Loss: 1.864817460378011, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 33/50, Loss: 0.002420864145581921\n",
      "Validation Loss: 1.8982945283253987, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 34/50, Loss: 0.002245957036696685\n",
      "Validation Loss: 1.9180074135462444, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 35/50, Loss: 0.002175834912729139\n",
      "Validation Loss: 1.9577588438987732, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 36/50, Loss: 0.0020533209171844646\n",
      "Validation Loss: 1.9850449164708455, Validation Accuracy: 0.7371428571428571\n",
      "Precision: 0.7606837606837606, Recall: 0.8317757009345794, F1-score: 0.7946428571428571\n",
      "Epoch 37/50, Loss: 0.0020872592237234735\n",
      "Validation Loss: 1.982779085636139, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 38/50, Loss: 0.0019339751888765022\n",
      "Validation Loss: 2.0109835664431253, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 39/50, Loss: 0.0018447977539229516\n",
      "Validation Loss: 1.98993319272995, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 40/50, Loss: 0.0018688881245907396\n",
      "Validation Loss: 2.0292197664578757, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 41/50, Loss: 0.001774471241030066\n",
      "Validation Loss: 2.0337117513020835, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 42/50, Loss: 0.0014882366279683386\n",
      "Validation Loss: 2.0262203415234885, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 43/50, Loss: 0.0013740271388087422\n",
      "Validation Loss: 2.0358930627504983, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 44/50, Loss: 0.0014581119127493973\n",
      "Validation Loss: 2.056941568851471, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 45/50, Loss: 0.0015673731492521863\n",
      "Validation Loss: 2.084721585114797, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 46/50, Loss: 0.0012918204277715024\n",
      "Validation Loss: 2.0829511086146035, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 47/50, Loss: 0.0011716212320607156\n",
      "Validation Loss: 2.1002095143000283, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 48/50, Loss: 0.0012944464118239314\n",
      "Validation Loss: 2.133900821208954, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 49/50, Loss: 0.0011838894667259108\n",
      "Validation Loss: 2.150422473748525, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Epoch 50/50, Loss: 0.0012719304904749151\n",
      "Validation Loss: 2.146232763926188, Validation Accuracy: 0.7428571428571429\n",
      "Precision: 0.7672413793103449, Recall: 0.8317757009345794, F1-score: 0.7982062780269058\n",
      "Validation Loss: 0.5627216051022211, Validation Accuracy: 0.8457142857142858\n",
      "Precision: 0.9081632653061225, Recall: 0.8317757009345794, F1-score: 0.8682926829268293\n",
      "Confusion Matrix:\n",
      "[[59  9]\n",
      " [18 89]]\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch 1/50, Loss: 0.3321867448588212\n",
      "Validation Loss: 0.5600673854351044, Validation Accuracy: 0.7473118279569892\n",
      "Precision: 0.7185185185185186, Recall: 0.9150943396226415, F1-score: 0.8049792531120332\n",
      "Model saved to ensemble_model_fold_2.pth\n",
      "Epoch 2/50, Loss: 0.12824344510833421\n",
      "Validation Loss: 0.6765394111474355, Validation Accuracy: 0.7473118279569892\n",
      "Precision: 0.743801652892562, Recall: 0.8490566037735849, F1-score: 0.7929515418502202\n",
      "Epoch 3/50, Loss: 0.0717927369599541\n",
      "Validation Loss: 0.8143865565458933, Validation Accuracy: 0.6720430107526881\n",
      "Precision: 0.7027027027027027, Recall: 0.7358490566037735, F1-score: 0.7188940092165899\n",
      "Epoch 4/50, Loss: 0.05011475800226132\n",
      "Validation Loss: 0.9498528937498728, Validation Accuracy: 0.6666666666666666\n",
      "Precision: 0.7075471698113207, Recall: 0.7075471698113207, F1-score: 0.7075471698113207\n",
      "Epoch 5/50, Loss: 0.040476862185945116\n",
      "Validation Loss: 1.0630909899870555, Validation Accuracy: 0.6666666666666666\n",
      "Precision: 0.6964285714285714, Recall: 0.7358490566037735, F1-score: 0.7155963302752294\n",
      "Epoch 6/50, Loss: 0.0359975405347844\n",
      "Validation Loss: 1.1465570330619812, Validation Accuracy: 0.6559139784946236\n",
      "Precision: 0.6944444444444444, Recall: 0.7075471698113207, F1-score: 0.7009345794392523\n",
      "Epoch 7/50, Loss: 0.03135722797984878\n",
      "Validation Loss: 1.2251056730747223, Validation Accuracy: 0.6559139784946236\n",
      "Precision: 0.6944444444444444, Recall: 0.7075471698113207, F1-score: 0.7009345794392523\n",
      "Epoch 8/50, Loss: 0.02509326410169403\n",
      "Validation Loss: 1.3067835172017415, Validation Accuracy: 0.6666666666666666\n",
      "Precision: 0.7, Recall: 0.7264150943396226, F1-score: 0.7129629629629629\n",
      "Epoch 9/50, Loss: 0.021901217677320044\n",
      "Validation Loss: 1.3640555838743846, Validation Accuracy: 0.6612903225806451\n",
      "Precision: 0.6972477064220184, Recall: 0.7169811320754716, F1-score: 0.7069767441860465\n",
      "Epoch 10/50, Loss: 0.021866116827974718\n",
      "Validation Loss: 1.427389880021413, Validation Accuracy: 0.6612903225806451\n",
      "Precision: 0.6972477064220184, Recall: 0.7169811320754716, F1-score: 0.7069767441860465\n",
      "Epoch 11/50, Loss: 0.019200152562310297\n",
      "Validation Loss: 1.4808126489321392, Validation Accuracy: 0.6559139784946236\n",
      "Precision: 0.6909090909090909, Recall: 0.7169811320754716, F1-score: 0.7037037037037037\n",
      "Epoch 12/50, Loss: 0.017523935219893854\n",
      "Validation Loss: 1.5539550681908925, Validation Accuracy: 0.6720430107526881\n",
      "Precision: 0.7027027027027027, Recall: 0.7358490566037735, F1-score: 0.7188940092165899\n",
      "Epoch 13/50, Loss: 0.016468475533959765\n",
      "Validation Loss: 1.6094799141089122, Validation Accuracy: 0.6774193548387096\n",
      "Precision: 0.7090909090909091, Recall: 0.7358490566037735, F1-score: 0.7222222222222222\n",
      "Epoch 14/50, Loss: 0.01364531418463836\n",
      "Validation Loss: 1.6850806375344594, Validation Accuracy: 0.6720430107526881\n",
      "Precision: 0.6991150442477876, Recall: 0.7452830188679245, F1-score: 0.7214611872146118\n",
      "Epoch 15/50, Loss: 0.013494637135105828\n",
      "Validation Loss: 1.730982929468155, Validation Accuracy: 0.6720430107526881\n",
      "Precision: 0.6991150442477876, Recall: 0.7452830188679245, F1-score: 0.7214611872146118\n",
      "Epoch 16/50, Loss: 0.014202830730937421\n",
      "Validation Loss: 1.784376084804535, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.7117117117117117, Recall: 0.7452830188679245, F1-score: 0.728110599078341\n",
      "Epoch 17/50, Loss: 0.013650757144205272\n",
      "Validation Loss: 1.8455261985460918, Validation Accuracy: 0.6774193548387096\n",
      "Precision: 0.7053571428571429, Recall: 0.7452830188679245, F1-score: 0.7247706422018348\n",
      "Epoch 18/50, Loss: 0.01349210029002279\n",
      "Validation Loss: 1.9050670166810353, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 19/50, Loss: 0.010547416692133993\n",
      "Validation Loss: 1.9877637028694153, Validation Accuracy: 0.6774193548387096\n",
      "Precision: 0.7053571428571429, Recall: 0.7452830188679245, F1-score: 0.7247706422018348\n",
      "Epoch 20/50, Loss: 0.00911297796604534\n",
      "Validation Loss: 2.011565069357554, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 21/50, Loss: 0.008230718628813824\n",
      "Validation Loss: 2.055575499931971, Validation Accuracy: 0.6774193548387096\n",
      "Precision: 0.7053571428571429, Recall: 0.7452830188679245, F1-score: 0.7247706422018348\n",
      "Epoch 22/50, Loss: 0.00730719023461764\n",
      "Validation Loss: 2.098950852950414, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 23/50, Loss: 0.006867464263147364\n",
      "Validation Loss: 2.1458862324555716, Validation Accuracy: 0.6774193548387096\n",
      "Precision: 0.7053571428571429, Recall: 0.7452830188679245, F1-score: 0.7247706422018348\n",
      "Epoch 24/50, Loss: 0.006855591646550844\n",
      "Validation Loss: 2.1724195182323456, Validation Accuracy: 0.6774193548387096\n",
      "Precision: 0.7053571428571429, Recall: 0.7452830188679245, F1-score: 0.7247706422018348\n",
      "Epoch 25/50, Loss: 0.006555740023031831\n",
      "Validation Loss: 2.2295930882294974, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 26/50, Loss: 0.006192546953874019\n",
      "Validation Loss: 2.2850227455298104, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.7117117117117117, Recall: 0.7452830188679245, F1-score: 0.728110599078341\n",
      "Epoch 27/50, Loss: 0.005816903159332772\n",
      "Validation Loss: 2.3198205331961312, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.7117117117117117, Recall: 0.7452830188679245, F1-score: 0.728110599078341\n",
      "Epoch 28/50, Loss: 0.005191559088416398\n",
      "Validation Loss: 2.33445343375206, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.7117117117117117, Recall: 0.7452830188679245, F1-score: 0.728110599078341\n",
      "Epoch 29/50, Loss: 0.004913226002827287\n",
      "Validation Loss: 2.363756557305654, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.7117117117117117, Recall: 0.7452830188679245, F1-score: 0.728110599078341\n",
      "Epoch 30/50, Loss: 0.00480063195573166\n",
      "Validation Loss: 2.3989887734254203, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7207207207207207, Recall: 0.7547169811320755, F1-score: 0.7373271889400922\n",
      "Epoch 31/50, Loss: 0.004767517316698407\n",
      "Validation Loss: 2.423194388548533, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7142857142857143, Recall: 0.7547169811320755, F1-score: 0.7339449541284404\n",
      "Epoch 32/50, Loss: 0.004678375708560149\n",
      "Validation Loss: 2.4465482234954834, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 33/50, Loss: 0.0043572465850350755\n",
      "Validation Loss: 2.506403386592865, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.7117117117117117, Recall: 0.7452830188679245, F1-score: 0.728110599078341\n",
      "Epoch 34/50, Loss: 0.003996320980756233\n",
      "Validation Loss: 2.5360167225201926, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 35/50, Loss: 0.0037739018929035715\n",
      "Validation Loss: 2.5428304374217987, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.7117117117117117, Recall: 0.7452830188679245, F1-score: 0.728110599078341\n",
      "Epoch 36/50, Loss: 0.0036499922280199826\n",
      "Validation Loss: 2.585251122713089, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7181818181818181, Recall: 0.7452830188679245, F1-score: 0.7314814814814815\n",
      "Epoch 37/50, Loss: 0.003622274777929609\n",
      "Validation Loss: 2.6295663317044577, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7142857142857143, Recall: 0.7547169811320755, F1-score: 0.7339449541284404\n",
      "Epoch 38/50, Loss: 0.0031510039067749553\n",
      "Validation Loss: 2.6508580446243286, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7142857142857143, Recall: 0.7547169811320755, F1-score: 0.7339449541284404\n",
      "Epoch 39/50, Loss: 0.002984244318213314\n",
      "Validation Loss: 2.6998512943585715, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7142857142857143, Recall: 0.7547169811320755, F1-score: 0.7339449541284404\n",
      "Epoch 40/50, Loss: 0.0028244684557042397\n",
      "Validation Loss: 2.6969104508558908, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7207207207207207, Recall: 0.7547169811320755, F1-score: 0.7373271889400922\n",
      "Epoch 41/50, Loss: 0.0030462030263151973\n",
      "Validation Loss: 2.7034572660923004, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7142857142857143, Recall: 0.7547169811320755, F1-score: 0.7339449541284404\n",
      "Epoch 42/50, Loss: 0.002860449613460029\n",
      "Validation Loss: 2.7880879938602448, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 43/50, Loss: 0.0024968972381126755\n",
      "Validation Loss: 2.79352014263471, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 44/50, Loss: 0.0024852947875236473\n",
      "Validation Loss: 2.825641711552938, Validation Accuracy: 0.6881720430107527\n",
      "Precision: 0.7142857142857143, Recall: 0.7547169811320755, F1-score: 0.7339449541284404\n",
      "Epoch 45/50, Loss: 0.002126606365588183\n",
      "Validation Loss: 2.83070832490921, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 46/50, Loss: 0.002332884425413795\n",
      "Validation Loss: 2.8415597677230835, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 47/50, Loss: 0.0021264422490882375\n",
      "Validation Loss: 2.8904120922088623, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7207207207207207, Recall: 0.7547169811320755, F1-score: 0.7373271889400922\n",
      "Epoch 48/50, Loss: 0.001984814603929408\n",
      "Validation Loss: 2.8976677457491555, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Epoch 49/50, Loss: 0.0020884006371488795\n",
      "Validation Loss: 2.921808342138926, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7207207207207207, Recall: 0.7547169811320755, F1-score: 0.7373271889400922\n",
      "Epoch 50/50, Loss: 0.0019729666237253696\n",
      "Validation Loss: 2.9461578726768494, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7272727272727273, Recall: 0.7547169811320755, F1-score: 0.7407407407407407\n",
      "Validation Loss: 0.5600673854351044, Validation Accuracy: 0.7473118279569892\n",
      "Precision: 0.7185185185185186, Recall: 0.9150943396226415, F1-score: 0.8049792531120332\n",
      "Confusion Matrix:\n",
      "[[42 38]\n",
      " [ 9 97]]\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch 1/50, Loss: 0.29961801692843437\n",
      "Validation Loss: 1.0318229272961617, Validation Accuracy: 0.7106598984771574\n",
      "Precision: 0.9680851063829787, Recall: 0.6275862068965518, F1-score: 0.7615062761506276\n",
      "Model saved to ensemble_model_fold_3.pth\n",
      "Epoch 2/50, Loss: 0.07773249503225088\n",
      "Validation Loss: 2.303163170814514, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9789473684210527, Recall: 0.6413793103448275, F1-score: 0.775\n",
      "Epoch 3/50, Loss: 0.03770901526634892\n",
      "Validation Loss: 3.1614338755607605, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9789473684210527, Recall: 0.6413793103448275, F1-score: 0.775\n",
      "Epoch 4/50, Loss: 0.024232428210477035\n",
      "Validation Loss: 3.401441812515259, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9789473684210527, Recall: 0.6413793103448275, F1-score: 0.775\n",
      "Epoch 5/50, Loss: 0.016935709165409207\n",
      "Validation Loss: 3.629588410258293, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9789473684210527, Recall: 0.6413793103448275, F1-score: 0.775\n",
      "Epoch 6/50, Loss: 0.013027538584234813\n",
      "Validation Loss: 3.7603501975536346, Validation Accuracy: 0.7157360406091371\n",
      "Precision: 0.978494623655914, Recall: 0.6275862068965518, F1-score: 0.7647058823529411\n",
      "Epoch 7/50, Loss: 0.01081628305837512\n",
      "Validation Loss: 3.8180108666419983, Validation Accuracy: 0.7106598984771574\n",
      "Precision: 0.9782608695652174, Recall: 0.6206896551724138, F1-score: 0.759493670886076\n",
      "Epoch 8/50, Loss: 0.009793313181338211\n",
      "Validation Loss: 3.8630582988262177, Validation Accuracy: 0.7055837563451777\n",
      "Precision: 0.978021978021978, Recall: 0.6137931034482759, F1-score: 0.7542372881355932\n",
      "Epoch 9/50, Loss: 0.007540711861414214\n",
      "Validation Loss: 3.7776706367731094, Validation Accuracy: 0.7106598984771574\n",
      "Precision: 0.9782608695652174, Recall: 0.6206896551724138, F1-score: 0.759493670886076\n",
      "Epoch 10/50, Loss: 0.006211785405563812\n",
      "Validation Loss: 3.9768763929605484, Validation Accuracy: 0.6903553299492385\n",
      "Precision: 0.9772727272727273, Recall: 0.593103448275862, F1-score: 0.7381974248927039\n",
      "Epoch 11/50, Loss: 0.005647808449187626\n",
      "Validation Loss: 4.0486437529325485, Validation Accuracy: 0.6802030456852792\n",
      "Precision: 0.9767441860465116, Recall: 0.5793103448275863, F1-score: 0.7272727272727273\n",
      "Epoch 12/50, Loss: 0.004910031702214231\n",
      "Validation Loss: 4.029259227216244, Validation Accuracy: 0.6802030456852792\n",
      "Precision: 0.9767441860465116, Recall: 0.5793103448275863, F1-score: 0.7272727272727273\n",
      "Epoch 13/50, Loss: 0.004386471099375437\n",
      "Validation Loss: 4.0636327639222145, Validation Accuracy: 0.6802030456852792\n",
      "Precision: 0.9767441860465116, Recall: 0.5793103448275863, F1-score: 0.7272727272727273\n",
      "Epoch 14/50, Loss: 0.004013203259091824\n",
      "Validation Loss: 4.134981498122215, Validation Accuracy: 0.6700507614213198\n",
      "Precision: 0.9651162790697675, Recall: 0.5724137931034483, F1-score: 0.7186147186147186\n",
      "Epoch 15/50, Loss: 0.004014857850658397\n",
      "Validation Loss: 4.218111298978329, Validation Accuracy: 0.6649746192893401\n",
      "Precision: 0.9759036144578314, Recall: 0.5586206896551724, F1-score: 0.7105263157894737\n",
      "Epoch 16/50, Loss: 0.00320611439140824\n",
      "Validation Loss: 4.335494942963123, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9753086419753086, Recall: 0.5448275862068965, F1-score: 0.6991150442477876\n",
      "Epoch 17/50, Loss: 0.0029698367579840124\n",
      "Validation Loss: 4.369013622403145, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9753086419753086, Recall: 0.5448275862068965, F1-score: 0.6991150442477876\n",
      "Epoch 18/50, Loss: 0.00284527837842082\n",
      "Validation Loss: 4.360892593860626, Validation Accuracy: 0.649746192893401\n",
      "Precision: 0.9634146341463414, Recall: 0.5448275862068965, F1-score: 0.6960352422907489\n",
      "Epoch 19/50, Loss: 0.002564922887055824\n",
      "Validation Loss: 4.45744676887989, Validation Accuracy: 0.649746192893401\n",
      "Precision: 0.9634146341463414, Recall: 0.5448275862068965, F1-score: 0.6960352422907489\n",
      "Epoch 20/50, Loss: 0.0025076162952852124\n",
      "Validation Loss: 4.450620025396347, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9753086419753086, Recall: 0.5448275862068965, F1-score: 0.6991150442477876\n",
      "Epoch 21/50, Loss: 0.0021663026952107125\n",
      "Validation Loss: 4.5641326159238815, Validation Accuracy: 0.649746192893401\n",
      "Precision: 0.975, Recall: 0.5379310344827586, F1-score: 0.6933333333333334\n",
      "Epoch 22/50, Loss: 0.002118977669548864\n",
      "Validation Loss: 4.533587619662285, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9753086419753086, Recall: 0.5448275862068965, F1-score: 0.6991150442477876\n",
      "Epoch 23/50, Loss: 0.0019533234832730764\n",
      "Validation Loss: 4.566473193466663, Validation Accuracy: 0.7055837563451777\n",
      "Precision: 0.978021978021978, Recall: 0.6137931034482759, F1-score: 0.7542372881355932\n",
      "Epoch 24/50, Loss: 0.0018232373743861292\n",
      "Validation Loss: 4.570905216038227, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9789473684210527, Recall: 0.6413793103448275, F1-score: 0.775\n",
      "Epoch 25/50, Loss: 0.0016624445027749364\n",
      "Validation Loss: 4.632533453404903, Validation Accuracy: 0.7563451776649747\n",
      "Precision: 0.9801980198019802, Recall: 0.6827586206896552, F1-score: 0.8048780487804879\n",
      "Epoch 26/50, Loss: 0.0016730599624376434\n",
      "Validation Loss: 4.6650096252560616, Validation Accuracy: 0.7309644670050761\n",
      "Precision: 0.9791666666666666, Recall: 0.6482758620689655, F1-score: 0.7800829875518672\n",
      "Epoch 27/50, Loss: 0.0013951354097419728\n",
      "Validation Loss: 4.780257023870945, Validation Accuracy: 0.7360406091370558\n",
      "Precision: 0.979381443298969, Recall: 0.6551724137931034, F1-score: 0.7851239669421488\n",
      "Epoch 28/50, Loss: 0.0013841869707296912\n",
      "Validation Loss: 4.8187976107001305, Validation Accuracy: 0.7715736040609137\n",
      "Precision: 0.9807692307692307, Recall: 0.7034482758620689, F1-score: 0.8192771084337349\n",
      "Epoch 29/50, Loss: 0.0013713784210267477\n",
      "Validation Loss: 4.816906426101923, Validation Accuracy: 0.7715736040609137\n",
      "Precision: 0.9716981132075472, Recall: 0.7103448275862069, F1-score: 0.8207171314741036\n",
      "Epoch 30/50, Loss: 0.001365588410408236\n",
      "Validation Loss: 4.858637675642967, Validation Accuracy: 0.7918781725888325\n",
      "Precision: 0.9727272727272728, Recall: 0.7379310344827587, F1-score: 0.8392156862745098\n",
      "Epoch 31/50, Loss: 0.0012054950542127092\n",
      "Validation Loss: 4.8712441101670265, Validation Accuracy: 0.7715736040609137\n",
      "Precision: 0.9807692307692307, Recall: 0.7034482758620689, F1-score: 0.8192771084337349\n",
      "Epoch 32/50, Loss: 0.001085342436757249\n",
      "Validation Loss: 4.89628267288208, Validation Accuracy: 0.766497461928934\n",
      "Precision: 0.9805825242718447, Recall: 0.696551724137931, F1-score: 0.8145161290322581\n",
      "Epoch 33/50, Loss: 0.0011535379065511127\n",
      "Validation Loss: 4.929575055837631, Validation Accuracy: 0.751269035532995\n",
      "Precision: 0.98, Recall: 0.6758620689655173, F1-score: 0.8\n",
      "Epoch 34/50, Loss: 0.0010489646689772296\n",
      "Validation Loss: 4.982266835868359, Validation Accuracy: 0.751269035532995\n",
      "Precision: 0.98, Recall: 0.6758620689655173, F1-score: 0.8\n",
      "Epoch 35/50, Loss: 0.0009728360516116178\n",
      "Validation Loss: 5.012356996536255, Validation Accuracy: 0.7563451776649747\n",
      "Precision: 0.9801980198019802, Recall: 0.6827586206896552, F1-score: 0.8048780487804879\n",
      "Epoch 36/50, Loss: 0.0009571489548155417\n",
      "Validation Loss: 5.005483664572239, Validation Accuracy: 0.7360406091370558\n",
      "Precision: 0.979381443298969, Recall: 0.6551724137931034, F1-score: 0.7851239669421488\n",
      "Epoch 37/50, Loss: 0.0009419592242920771\n",
      "Validation Loss: 5.035389557480812, Validation Accuracy: 0.7360406091370558\n",
      "Precision: 0.979381443298969, Recall: 0.6551724137931034, F1-score: 0.7851239669421488\n",
      "Epoch 38/50, Loss: 0.0008454858119269678\n",
      "Validation Loss: 5.087210431694984, Validation Accuracy: 0.7360406091370558\n",
      "Precision: 0.979381443298969, Recall: 0.6551724137931034, F1-score: 0.7851239669421488\n",
      "Epoch 39/50, Loss: 0.0008580665198678616\n",
      "Validation Loss: 5.1475928500294685, Validation Accuracy: 0.7360406091370558\n",
      "Precision: 0.979381443298969, Recall: 0.6551724137931034, F1-score: 0.7851239669421488\n",
      "Epoch 40/50, Loss: 0.0007568777145934291\n",
      "Validation Loss: 5.1983737424016, Validation Accuracy: 0.7309644670050761\n",
      "Precision: 0.9791666666666666, Recall: 0.6482758620689655, F1-score: 0.7800829875518672\n",
      "Epoch 41/50, Loss: 0.0008503472599841189\n",
      "Validation Loss: 5.172207459807396, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9789473684210527, Recall: 0.6413793103448275, F1-score: 0.775\n",
      "Epoch 42/50, Loss: 0.0007696276370552368\n",
      "Validation Loss: 5.276331916451454, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9690721649484536, Recall: 0.6482758620689655, F1-score: 0.7768595041322314\n",
      "Epoch 43/50, Loss: 0.00083822112113315\n",
      "Validation Loss: 5.263628289103508, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9690721649484536, Recall: 0.6482758620689655, F1-score: 0.7768595041322314\n",
      "Epoch 44/50, Loss: 0.0007521611623815261\n",
      "Validation Loss: 5.293181367218494, Validation Accuracy: 0.7461928934010152\n",
      "Precision: 0.9702970297029703, Recall: 0.6758620689655173, F1-score: 0.7967479674796748\n",
      "Epoch 45/50, Loss: 0.0006975923812812349\n",
      "Validation Loss: 5.299833111464977, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9690721649484536, Recall: 0.6482758620689655, F1-score: 0.7768595041322314\n",
      "Epoch 46/50, Loss: 0.0006032301595647974\n",
      "Validation Loss: 5.385494247078896, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9690721649484536, Recall: 0.6482758620689655, F1-score: 0.7768595041322314\n",
      "Epoch 47/50, Loss: 0.0006448207174495716\n",
      "Validation Loss: 5.3632053062319756, Validation Accuracy: 0.7208121827411168\n",
      "Precision: 0.9787234042553191, Recall: 0.6344827586206897, F1-score: 0.7698744769874477\n",
      "Epoch 48/50, Loss: 0.000599315727110176\n",
      "Validation Loss: 5.383034139871597, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9789473684210527, Recall: 0.6413793103448275, F1-score: 0.775\n",
      "Epoch 49/50, Loss: 0.0005295546379784355\n",
      "Validation Loss: 5.469453915953636, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9690721649484536, Recall: 0.6482758620689655, F1-score: 0.7768595041322314\n",
      "Epoch 50/50, Loss: 0.0006265735634466788\n",
      "Validation Loss: 5.441444702446461, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9690721649484536, Recall: 0.6482758620689655, F1-score: 0.7768595041322314\n",
      "Validation Loss: 1.0318229272961617, Validation Accuracy: 0.7106598984771574\n",
      "Precision: 0.9680851063829787, Recall: 0.6275862068965518, F1-score: 0.7615062761506276\n",
      "Confusion Matrix:\n",
      "[[49  3]\n",
      " [54 91]]\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch 1/50, Loss: 0.3923470228910446\n",
      "Validation Loss: 0.4857618659734726, Validation Accuracy: 0.8469387755102041\n",
      "Precision: 0.9047619047619048, Recall: 0.8260869565217391, F1-score: 0.8636363636363636\n",
      "Model saved to ensemble_model_fold_4.pth\n",
      "Epoch 2/50, Loss: 0.20525764798124632\n",
      "Validation Loss: 0.39534467086195946, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.9238095238095239, Recall: 0.8434782608695652, F1-score: 0.8818181818181818\n",
      "Model saved to ensemble_model_fold_4.pth\n",
      "Epoch 3/50, Loss: 0.14655416955550513\n",
      "Validation Loss: 0.40917225927114487, Validation Accuracy: 0.8469387755102041\n",
      "Precision: 0.897196261682243, Recall: 0.8347826086956521, F1-score: 0.8648648648648649\n",
      "Epoch 4/50, Loss: 0.10415186174213886\n",
      "Validation Loss: 0.4622060265392065, Validation Accuracy: 0.8367346938775511\n",
      "Precision: 0.8738738738738738, Recall: 0.8434782608695652, F1-score: 0.8584070796460177\n",
      "Epoch 5/50, Loss: 0.078940876138707\n",
      "Validation Loss: 0.5209343833848834, Validation Accuracy: 0.7551020408163265\n",
      "Precision: 0.7596899224806202, Recall: 0.8521739130434782, F1-score: 0.8032786885245902\n",
      "Epoch 6/50, Loss: 0.06377001758664846\n",
      "Validation Loss: 0.5472261644899845, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7246376811594203, Recall: 0.8695652173913043, F1-score: 0.7905138339920948\n",
      "Epoch 7/50, Loss: 0.05381477406869332\n",
      "Validation Loss: 0.6385613409802318, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 8/50, Loss: 0.04692274875318011\n",
      "Validation Loss: 0.7193355015479028, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 9/50, Loss: 0.040442502591758966\n",
      "Validation Loss: 0.7466663494706154, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 10/50, Loss: 0.03598596202209592\n",
      "Validation Loss: 0.8010382438078523, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 11/50, Loss: 0.03304027789272368\n",
      "Validation Loss: 0.848879971774295, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 12/50, Loss: 0.02936769463121891\n",
      "Validation Loss: 0.9046776590403169, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 13/50, Loss: 0.02689300027365486\n",
      "Validation Loss: 0.9004052883246914, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 14/50, Loss: 0.025519018061459064\n",
      "Validation Loss: 1.020159935229458, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 15/50, Loss: 0.023014531820081174\n",
      "Validation Loss: 1.0005135565297678, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 16/50, Loss: 0.02309574365305404\n",
      "Validation Loss: 1.0606649695546366, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 17/50, Loss: 0.02075794603054722\n",
      "Validation Loss: 1.135999279562384, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 18/50, Loss: 0.018409554613754153\n",
      "Validation Loss: 1.1870231038774364, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 19/50, Loss: 0.018041719488489132\n",
      "Validation Loss: 1.2520949157187715, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 20/50, Loss: 0.01584574518104394\n",
      "Validation Loss: 1.2469471389485989, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 21/50, Loss: 0.014588218104715148\n",
      "Validation Loss: 1.2944144666544162, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 22/50, Loss: 0.01567147020250559\n",
      "Validation Loss: 1.2859610909072217, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 23/50, Loss: 0.013150911079719663\n",
      "Validation Loss: 1.369936022994807, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 24/50, Loss: 0.013671727928643426\n",
      "Validation Loss: 1.3123031889263075, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 25/50, Loss: 0.011482787590163449\n",
      "Validation Loss: 1.4118320003472036, Validation Accuracy: 0.7193877551020408\n",
      "Precision: 0.7083333333333334, Recall: 0.8869565217391304, F1-score: 0.7876447876447876\n",
      "Epoch 26/50, Loss: 0.012741008676433315\n",
      "Validation Loss: 1.3992737399239559, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 27/50, Loss: 0.00960519645983974\n",
      "Validation Loss: 1.4516395339596784, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 28/50, Loss: 0.010192041692789644\n",
      "Validation Loss: 1.485557087296911, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 29/50, Loss: 0.0102017522828343\n",
      "Validation Loss: 1.4967508617119165, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 30/50, Loss: 0.009486524329986423\n",
      "Validation Loss: 1.5998446585217607, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 31/50, Loss: 0.008884477467897037\n",
      "Validation Loss: 1.5591577082668664, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 32/50, Loss: 0.007628704401819657\n",
      "Validation Loss: 1.60917244508164, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 33/50, Loss: 0.007595889852382243\n",
      "Validation Loss: 1.6659910915259388, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 34/50, Loss: 0.007231747993500903\n",
      "Validation Loss: 1.737236354227207, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 35/50, Loss: 0.006449013094728191\n",
      "Validation Loss: 1.7312621959863463, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 36/50, Loss: 0.006193301882982875\n",
      "Validation Loss: 1.6951392930095608, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 37/50, Loss: 0.006845413629586498\n",
      "Validation Loss: 1.7323171621756046, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 38/50, Loss: 0.005900074490151989\n",
      "Validation Loss: 1.736201694002375, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 39/50, Loss: 0.005179487003867204\n",
      "Validation Loss: 1.836339271218094, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 40/50, Loss: 0.005420071926588814\n",
      "Validation Loss: 1.8431455107456713, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 41/50, Loss: 0.005414835565413038\n",
      "Validation Loss: 1.855231678862765, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 42/50, Loss: 0.004723846980292971\n",
      "Validation Loss: 1.810902057797648, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 43/50, Loss: 0.00507630987946565\n",
      "Validation Loss: 1.8925394631332892, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 44/50, Loss: 0.004773062246385962\n",
      "Validation Loss: 1.9413320193052641, Validation Accuracy: 0.7193877551020408\n",
      "Precision: 0.7083333333333334, Recall: 0.8869565217391304, F1-score: 0.7876447876447876\n",
      "Epoch 45/50, Loss: 0.004281572269974276\n",
      "Validation Loss: 1.9387888977798866, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 46/50, Loss: 0.003929011067763592\n",
      "Validation Loss: 1.9432010794771486, Validation Accuracy: 0.7295918367346939\n",
      "Precision: 0.7183098591549296, Recall: 0.8869565217391304, F1-score: 0.7937743190661478\n",
      "Epoch 47/50, Loss: 0.004298038373235613\n",
      "Validation Loss: 1.9300585681921802, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 48/50, Loss: 0.0036408951079162457\n",
      "Validation Loss: 1.9411594490484276, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 49/50, Loss: 0.0038829035377906016\n",
      "Validation Loss: 1.9603801588855276, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Epoch 50/50, Loss: 0.0033884960236415886\n",
      "Validation Loss: 2.00284917623776, Validation Accuracy: 0.7244897959183674\n",
      "Precision: 0.7132867132867133, Recall: 0.8869565217391304, F1-score: 0.7906976744186046\n",
      "Validation Loss: 0.39534467086195946, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.9238095238095239, Recall: 0.8434782608695652, F1-score: 0.8818181818181818\n",
      "Confusion Matrix:\n",
      "[[73  8]\n",
      " [18 97]]\n",
      "\n",
      "Average results across all folds:\n",
      "Accuracy: 0.7451\n",
      "Precision: 0.8489\n",
      "Recall: 0.7674\n",
      "F1-score: 0.7922\n",
      "Final model saved to final_ensemble_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 51), padding='same')\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.depthwiseConv2d = nn.Conv2d(16, 32, (65, 1), groups=16, padding='same')\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.activation = nn.ELU()\n",
    "        self.pooling = nn.AvgPool2d((1, 4))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(32 * 65 * 31, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.depthwiseConv2d(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class PolygraphNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(PolygraphNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 51), padding='same')\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.depthwiseConv2d = nn.Conv2d(16, 32, (4, 1), groups=16, padding='same')\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.activation = nn.ELU()\n",
    "        self.pooling = nn.AvgPool2d((1, 4))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(32 * 4 * 1118, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.depthwiseConv2d(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, eeg_model, poly_model):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.eeg_model = eeg_model\n",
    "        self.poly_model = poly_model\n",
    "        self.fc = nn.Linear(4, 2)\n",
    "\n",
    "    def forward(self, eeg_input, poly_input):\n",
    "        eeg_output = self.eeg_model(eeg_input)\n",
    "        poly_output = self.poly_model(poly_input)\n",
    "        combined_output = torch.cat((eeg_output, poly_output), dim=1)\n",
    "        output = self.fc(combined_output)\n",
    "        return output\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    all_labels, all_predictions = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for eeg_X_batch, eeg_y_batch, poly_X_batch, poly_y_batch in data_loader:\n",
    "            eeg_X_batch, poly_X_batch = eeg_X_batch.to(device), poly_X_batch.to(device)\n",
    "            labels = eeg_y_batch.to(device)  # Use EEG labels (they should be the same as Poly labels)\n",
    "            \n",
    "            outputs = model(eeg_X_batch, poly_X_batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(all_labels, all_predictions, average='binary', zero_division=1)\n",
    "    recall = recall_score(all_labels, all_predictions, average='binary', zero_division=1)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='binary', zero_division=1)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions, labels=[0, 1])\n",
    "\n",
    "    return total_loss / len(data_loader), accuracy, precision, recall, f1, conf_matrix\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, save_path):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for eeg_X_batch, eeg_y_batch, poly_X_batch, poly_y_batch in train_loader:\n",
    "            eeg_X_batch, poly_X_batch = eeg_X_batch.to(device), poly_X_batch.to(device)\n",
    "            labels = eeg_y_batch.to(device)  # Use EEG labels (they should be the same as Poly labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(eeg_X_batch, poly_X_batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss}')\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy, val_precision, val_recall, val_f1, val_conf_matrix = evaluate_model(model, val_loader, criterion, device)\n",
    "        print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "        print(f'Precision: {val_precision}, Recall: {val_recall}, F1-score: {val_f1}')\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'val_accuracy': val_accuracy,\n",
    "                'val_precision': val_precision,\n",
    "                'val_recall': val_recall,\n",
    "                'val_f1': val_f1,\n",
    "            }, save_path)\n",
    "            print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "# Load data\n",
    "print(\"Loading EEG data...\")\n",
    "eeg_X, eeg_y, file_sample_counts = load_eeg_data(EEG_DATA_DIR)\n",
    "print(\"Loading Poly data...\")\n",
    "poly_X, poly_y = load_poly_data(POLY_DATA_DIR)\n",
    "\n",
    "# Create splits based on file indices\n",
    "splits = create_file_based_splits(file_sample_counts, n_splits=5)\n",
    "\n",
    "for fold, (train_file_indices, val_file_indices) in enumerate(splits):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Split data based on file indices\n",
    "    train_sample_counts = [file_sample_counts[i] for i in train_file_indices]\n",
    "    val_sample_counts = [file_sample_counts[i] for i in val_file_indices]\n",
    "    \n",
    "    train_eeg_indices = np.concatenate([np.arange(sum(file_sample_counts[:i]), \n",
    "                                                  sum(file_sample_counts[:i+1])) \n",
    "                                        for i in train_file_indices])\n",
    "    val_eeg_indices = np.concatenate([np.arange(sum(file_sample_counts[:i]), \n",
    "                                                sum(file_sample_counts[:i+1])) \n",
    "                                      for i in val_file_indices])\n",
    "\n",
    "    # Split EEG data\n",
    "    train_eeg_X, train_eeg_y = eeg_X[train_eeg_indices], eeg_y[train_eeg_indices]\n",
    "    val_eeg_X, val_eeg_y = eeg_X[val_eeg_indices], eeg_y[val_eeg_indices]\n",
    "\n",
    "    # Split Poly data\n",
    "    train_poly_X, train_poly_y = poly_X[train_file_indices], poly_y[train_file_indices]\n",
    "    val_poly_X, val_poly_y = poly_X[val_file_indices], poly_y[val_file_indices]\n",
    "\n",
    "    # Normalize data for this fold\n",
    "    eeg_scaler = StandardScaler()\n",
    "    poly_scaler = StandardScaler()\n",
    "\n",
    "\n",
    "    train_eeg_X_2d = train_eeg_X.reshape(-1, train_eeg_X.shape[-1])  \n",
    "    train_eeg_X_2d_scaled = eeg_scaler.fit_transform(train_eeg_X_2d)\n",
    "    train_eeg_X_scaled = train_eeg_X_2d_scaled.reshape(train_eeg_X.shape)\n",
    "    \n",
    "    # Reshape and transform validation data\n",
    "    val_eeg_X_2d = val_eeg_X.reshape(-1, val_eeg_X.shape[-1])\n",
    "    val_eeg_X_2d_scaled = eeg_scaler.transform(val_eeg_X_2d)\n",
    "    val_eeg_X_scaled = val_eeg_X_2d_scaled.reshape(val_eeg_X.shape)\n",
    "    \n",
    "    train_poly_X_2d = train_poly_X.reshape(-1, train_poly_X.shape[-1])\n",
    "    train_poly_X_2d_scaled = poly_scaler.fit_transform(train_poly_X_2d)\n",
    "    train_poly_X_scaled = train_poly_X_2d_scaled.reshape(train_poly_X.shape)\n",
    "    \n",
    "    val_poly_X_2d = val_poly_X.reshape(-1, val_poly_X.shape[-1])\n",
    "    val_poly_X_2d_scaled = poly_scaler.transform(val_poly_X_2d)\n",
    "    val_poly_X_scaled = val_poly_X_2d_scaled.reshape(val_poly_X.shape)\n",
    "\n",
    "    # Create datasets for this fold\n",
    "    train_dataset = CombinedDataset(train_eeg_X_scaled, train_eeg_y, train_poly_X_scaled, train_poly_y, train_sample_counts)\n",
    "    val_dataset = CombinedDataset(val_eeg_X_scaled, val_eeg_y, val_poly_X_scaled, val_poly_y, val_sample_counts)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Initialize models\n",
    "    eeg_model = EEGNet(num_classes=2).to(device)\n",
    "    poly_model = PolygraphNet(num_classes=2).to(device)\n",
    "    ensemble_model = EnsembleModel(eeg_model, poly_model).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    ensemble_optimizer = optim.Adam(ensemble_model.parameters(), lr=0.0001)\n",
    "\n",
    "    # Train and evaluate model (rest of your code remains the same)\n",
    "    ...\n",
    "    # Train the model and save it\n",
    "    save_path = f'ensemble_model_fold_{fold}.pth'\n",
    "    best_model_path = train_model(ensemble_model, train_loader, val_loader, criterion, ensemble_optimizer, num_epochs, device, save_path)\n",
    "\n",
    "    # Load the best model and evaluate on validation set\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    ensemble_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    val_loss, val_accuracy, val_precision, val_recall, val_f1, val_conf_matrix = evaluate_model(ensemble_model, val_loader, criterion, device)\n",
    "    \n",
    "    print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "    print(f'Precision: {val_precision}, Recall: {val_recall}, F1-score: {val_f1}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(val_conf_matrix)\n",
    "    \n",
    "    results.append({\n",
    "        'fold': fold,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    })\n",
    "\n",
    "# Print average results\n",
    "avg_accuracy = np.mean([r['val_accuracy'] for r in results])\n",
    "avg_precision = np.mean([r['val_precision'] for r in results])\n",
    "avg_recall = np.mean([r['val_recall'] for r in results])\n",
    "avg_f1 = np.mean([r['val_f1'] for r in results])\n",
    "\n",
    "print(\"\\nAverage results across all folds:\")\n",
    "print(f\"Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Precision: {avg_precision:.4f}\")\n",
    "print(f\"Recall: {avg_recall:.4f}\")\n",
    "print(f\"F1-score: {avg_f1:.4f}\")\n",
    "\n",
    "# Save the final model (you can choose to save the model from the best fold instead)\n",
    "final_model_path = 'final_ensemble_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': ensemble_model.state_dict(),\n",
    "    'avg_accuracy': avg_accuracy,\n",
    "    'avg_precision': avg_precision,\n",
    "    'avg_recall': avg_recall,\n",
    "    'avg_f1': avg_f1,\n",
    "}, final_model_path)\n",
    "print(f\"Final model saved to {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911294f-a9f1-4b9a-a912-afea5f59c972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af669253-0646-4a15-88de-6e4de56c97bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
