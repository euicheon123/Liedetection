{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1159f92-96e7-4f79-9cd1-ec348c0a4b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG data...\n",
      "EEG File: augmented_lie_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_10.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_11.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_12.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_13.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_14.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_15.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_16.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_17.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_19.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_2.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_20.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_21.pkl, Shape: (17, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_22.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_23.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_24.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_25.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_26.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_27.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_28.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_29.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_3.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_30.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_31.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_33.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_34.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_4.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_5.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_6.pkl, Shape: (26, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_7.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_8.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_9.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_10.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_11.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_12.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_13.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_14.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_15.pkl, Shape: (4, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_16.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_17.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_19.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_2.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_20.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_21.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_22.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_23.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_24.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_25.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_26.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_27.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_28.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_29.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_3.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_30.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_31.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_33.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_34.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_36.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_37.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_38.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_39.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_4.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_40.pkl, Shape: (30, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_41.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_42.pkl, Shape: (18, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_43.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_44.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_45.pkl, Shape: (14, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_46.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_47.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_48.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_49.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_5.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_50.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_51.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_52.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_53.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_54.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_55.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_6.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_7.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_8.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_9.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "Loaded from EEG C:\\Users\\User\\Documents\\Lie detect data\\AugmentedEEGData: 333 lie samples, 602 truth samples\n",
      "Loading Poly data...\n",
      "Poly File: poly_lie_1.pkl, Shape: (4, 2963), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_10.pkl, Shape: (4, 3171), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_11.pkl, Shape: (4, 2917), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_12.pkl, Shape: (4, 2991), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_13.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_14.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_15.pkl, Shape: (4, 2929), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_16.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_17.pkl, Shape: (4, 3234), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_18.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_19.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_2.pkl, Shape: (4, 2895), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_20.pkl, Shape: (4, 3291), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_21.pkl, Shape: (4, 3658), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_22.pkl, Shape: (4, 3375), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_23.pkl, Shape: (4, 3334), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_24.pkl, Shape: (4, 3263), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_25.pkl, Shape: (4, 3292), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_26.pkl, Shape: (4, 3246), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_27.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_28.pkl, Shape: (4, 3262), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_29.pkl, Shape: (4, 3321), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_3.pkl, Shape: (4, 2941), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_30.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_31.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_32.pkl, Shape: (4, 3142), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_33.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_34.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_35.pkl, Shape: (4, 3179), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_4.pkl, Shape: (4, 2967), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_5.pkl, Shape: (4, 2913), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_6.pkl, Shape: (4, 4229), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_7.pkl, Shape: (4, 3129), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_8.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_9.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_1.pkl, Shape: (4, 2958), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_10.pkl, Shape: (4, 3104), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_11.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_12.pkl, Shape: (4, 3391), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_13.pkl, Shape: (4, 3141), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_14.pkl, Shape: (4, 3271), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_15.pkl, Shape: (4, 2859), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_16.pkl, Shape: (4, 3325), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_17.pkl, Shape: (4, 3383), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_18.pkl, Shape: (4, 3233), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_19.pkl, Shape: (4, 3366), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_2.pkl, Shape: (4, 3112), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_20.pkl, Shape: (4, 3313), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_21.pkl, Shape: (4, 3555), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_22.pkl, Shape: (4, 3346), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_23.pkl, Shape: (4, 3305), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_24.pkl, Shape: (4, 3200), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_25.pkl, Shape: (4, 3213), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_26.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_27.pkl, Shape: (4, 3188), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_28.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_29.pkl, Shape: (4, 3242), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_3.pkl, Shape: (4, 3016), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_30.pkl, Shape: (4, 3258), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_31.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_32.pkl, Shape: (4, 3175), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_33.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_34.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_35.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_36.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_37.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_38.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_39.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_4.pkl, Shape: (4, 3058), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_40.pkl, Shape: (4, 4475), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_41.pkl, Shape: (4, 3162), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_42.pkl, Shape: (4, 3704), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_43.pkl, Shape: (4, 3333), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_44.pkl, Shape: (4, 3396), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_45.pkl, Shape: (4, 3450), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_46.pkl, Shape: (4, 3537), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_47.pkl, Shape: (4, 3363), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_48.pkl, Shape: (4, 3250), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_49.pkl, Shape: (4, 3279), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_5.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_50.pkl, Shape: (4, 3508), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_51.pkl, Shape: (4, 3358), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_52.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_53.pkl, Shape: (4, 3379), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_54.pkl, Shape: (4, 3558), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_55.pkl, Shape: (4, 3392), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_6.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_7.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_8.pkl, Shape: (4, 3096), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_9.pkl, Shape: (4, 3225), Type: <class 'numpy.ndarray'>\n",
      "Loaded from Poly C:\\Users\\User\\Documents\\Lie detect data\\CombinedPolyData: 35 lie samples, 55 truth samples\n",
      "EEG Class distribution: {0: 333, 1: 602}\n",
      "Poly Class distribution: {0: 35, 1: 55}\n",
      "EEG data shape: (935, 65, 125)\n",
      "Poly data shape: (90, 4, 4475)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "\n",
    "# Constants\n",
    "EEG_DATA_DIR = r'C:\\Users\\User\\Documents\\Lie detect data\\AugmentedEEGData'\n",
    "POLY_DATA_DIR = r'C:\\Users\\User\\Documents\\Lie detect data\\CombinedPolyData'\n",
    "K_FOLDS = 5  # Number of folds for cross-validation\n",
    "\n",
    "def pad_sequence(sequence, target_length):\n",
    "    \"\"\"Pad the sequence to the target length.\"\"\"\n",
    "    pad_length = target_length - sequence.shape[1]\n",
    "    if pad_length > 0:\n",
    "        return np.pad(sequence, ((0, 0), (0, pad_length)), mode='constant')\n",
    "    else:\n",
    "        return sequence[:, :target_length]\n",
    "\n",
    "def load_eeg_data(data_dir):\n",
    "    X, y = [], []\n",
    "    lie_count, truth_count = 0, 0\n",
    "    file_sample_counts = []\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        if file_name.endswith('.pkl'):\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            try:\n",
    "                data = pd.read_pickle(file_path)\n",
    "                print(f\"EEG File: {file_name}, Shape: {data.shape}, Type: {type(data)}\")\n",
    "                label = 0 if 'lie' in file_name.lower() else 1\n",
    "                X.extend(data)\n",
    "                y.extend([label] * data.shape[0])\n",
    "                file_sample_counts.append(data.shape[0])\n",
    "                if label == 0:\n",
    "                    lie_count += data.shape[0]\n",
    "                else:\n",
    "                    truth_count += data.shape[0]\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading EEG file {file_name}: {str(e)}\")\n",
    "    print(f\"Loaded from EEG {data_dir}: {lie_count} lie samples, {truth_count} truth samples\")\n",
    "    return np.array(X), np.array(y), file_sample_counts\n",
    "\n",
    "def load_poly_data(data_dir):\n",
    "    X, y = [], []\n",
    "    lie_count, truth_count = 0, 0\n",
    "    max_length = 0\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        if file_name.endswith('.pkl'):\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            try:\n",
    "                data = pd.read_pickle(file_path)\n",
    "                print(f\"Poly File: {file_name}, Shape: {data.shape}, Type: {type(data)}\")\n",
    "                max_length = max(max_length, data.shape[1])\n",
    "                label = 0 if 'lie' in file_name.lower() else 1\n",
    "                X.append(data)\n",
    "                y.append(label)\n",
    "                if label == 0:\n",
    "                    lie_count += 1\n",
    "                else:\n",
    "                    truth_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading Poly file {file_name}: {str(e)}\")\n",
    "    print(f\"Loaded from Poly {data_dir}: {lie_count} lie samples, {truth_count} truth samples\")\n",
    "    \n",
    "    # Pad all poly samples to the maximum length\n",
    "    X_padded = np.array([pad_sequence(x, max_length) for x in X])\n",
    "    return X_padded, np.array(y)\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, eeg_X, eeg_y, poly_X, poly_y, file_sample_counts):\n",
    "        self.eeg_X = torch.tensor(eeg_X, dtype=torch.float32)\n",
    "        self.eeg_y = torch.tensor(eeg_y, dtype=torch.long)\n",
    "        self.poly_X = torch.tensor(poly_X, dtype=torch.float32)\n",
    "        self.poly_y = torch.tensor(poly_y, dtype=torch.long)\n",
    "        \n",
    "        # Create a mapping from EEG sample index to Poly file index\n",
    "        self.eeg_to_poly_map = []\n",
    "        poly_index = 0\n",
    "        for count in file_sample_counts:\n",
    "            self.eeg_to_poly_map.extend([poly_index] * count)\n",
    "            poly_index += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eeg_X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg_sample = self.eeg_X[idx]\n",
    "        eeg_label = self.eeg_y[idx]\n",
    "        poly_idx = self.eeg_to_poly_map[idx]\n",
    "        poly_sample = self.poly_X[poly_idx]\n",
    "        poly_label = self.poly_y[poly_idx]\n",
    "        \n",
    "        return eeg_sample, eeg_label, poly_sample, poly_label\n",
    "\n",
    "def create_file_based_splits(file_sample_counts, n_splits=5):\n",
    "    file_indices = np.arange(len(file_sample_counts))\n",
    "    group_kfold = GroupKFold(n_splits=n_splits)\n",
    "    return list(group_kfold.split(X=file_indices, groups=file_indices))\n",
    "\n",
    "# Load data\n",
    "print(\"Loading EEG data...\")\n",
    "eeg_X, eeg_y, file_sample_counts = load_eeg_data(EEG_DATA_DIR)\n",
    "print(\"Loading Poly data...\")\n",
    "poly_X, poly_y = load_poly_data(POLY_DATA_DIR)\n",
    "\n",
    "# Check for class imbalance\n",
    "unique, counts = np.unique(eeg_y, return_counts=True)\n",
    "print(\"EEG Class distribution:\", dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(poly_y, return_counts=True)\n",
    "print(\"Poly Class distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "# Print dataset size and shapes\n",
    "print(\"EEG data shape:\", eeg_X.shape)\n",
    "print(\"Poly data shape:\", poly_X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807dc975-266c-4193-ac4b-3c69be28d126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG data...\n",
      "EEG File: augmented_lie_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_10.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_11.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_12.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_13.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_14.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_15.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_16.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_17.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_19.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_2.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_20.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_21.pkl, Shape: (17, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_22.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_23.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_24.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_25.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_26.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_27.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_28.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_29.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_3.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_30.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_31.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_33.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_34.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_4.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_5.pkl, Shape: (5, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_6.pkl, Shape: (26, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_7.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_8.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_lie_9.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_1.pkl, Shape: (6, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_10.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_11.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_12.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_13.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_14.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_15.pkl, Shape: (4, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_16.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_17.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_18.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_19.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_2.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_20.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_21.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_22.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_23.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_24.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_25.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_26.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_27.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_28.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_29.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_3.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_30.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_31.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_32.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_33.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_34.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_35.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_36.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_37.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_38.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_39.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_4.pkl, Shape: (7, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_40.pkl, Shape: (30, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_41.pkl, Shape: (9, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_42.pkl, Shape: (18, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_43.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_44.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_45.pkl, Shape: (14, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_46.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_47.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_48.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_49.pkl, Shape: (11, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_5.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_50.pkl, Shape: (15, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_51.pkl, Shape: (12, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_52.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_53.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_54.pkl, Shape: (16, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_55.pkl, Shape: (13, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_6.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_7.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_8.pkl, Shape: (8, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "EEG File: augmented_truth_9.pkl, Shape: (10, 65, 125), Type: <class 'numpy.ndarray'>\n",
      "Loaded from EEG C:\\Users\\User\\Documents\\Lie detect data\\AugmentedEEGData: 333 lie samples, 602 truth samples\n",
      "Loading Poly data...\n",
      "Poly File: poly_lie_1.pkl, Shape: (4, 2963), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_10.pkl, Shape: (4, 3171), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_11.pkl, Shape: (4, 2917), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_12.pkl, Shape: (4, 2991), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_13.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_14.pkl, Shape: (4, 2962), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_15.pkl, Shape: (4, 2929), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_16.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_17.pkl, Shape: (4, 3234), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_18.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_19.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_2.pkl, Shape: (4, 2895), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_20.pkl, Shape: (4, 3291), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_21.pkl, Shape: (4, 3658), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_22.pkl, Shape: (4, 3375), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_23.pkl, Shape: (4, 3334), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_24.pkl, Shape: (4, 3263), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_25.pkl, Shape: (4, 3292), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_26.pkl, Shape: (4, 3246), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_27.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_28.pkl, Shape: (4, 3262), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_29.pkl, Shape: (4, 3321), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_3.pkl, Shape: (4, 2941), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_30.pkl, Shape: (4, 3216), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_31.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_32.pkl, Shape: (4, 3142), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_33.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_34.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_35.pkl, Shape: (4, 3179), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_4.pkl, Shape: (4, 2967), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_5.pkl, Shape: (4, 2913), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_6.pkl, Shape: (4, 4229), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_7.pkl, Shape: (4, 3129), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_8.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_lie_9.pkl, Shape: (4, 3050), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_1.pkl, Shape: (4, 2958), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_10.pkl, Shape: (4, 3104), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_11.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_12.pkl, Shape: (4, 3391), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_13.pkl, Shape: (4, 3141), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_14.pkl, Shape: (4, 3271), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_15.pkl, Shape: (4, 2859), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_16.pkl, Shape: (4, 3325), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_17.pkl, Shape: (4, 3383), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_18.pkl, Shape: (4, 3233), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_19.pkl, Shape: (4, 3366), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_2.pkl, Shape: (4, 3112), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_20.pkl, Shape: (4, 3313), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_21.pkl, Shape: (4, 3555), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_22.pkl, Shape: (4, 3346), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_23.pkl, Shape: (4, 3305), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_24.pkl, Shape: (4, 3200), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_25.pkl, Shape: (4, 3213), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_26.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_27.pkl, Shape: (4, 3188), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_28.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_29.pkl, Shape: (4, 3242), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_3.pkl, Shape: (4, 3016), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_30.pkl, Shape: (4, 3258), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_31.pkl, Shape: (4, 3125), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_32.pkl, Shape: (4, 3175), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_33.pkl, Shape: (4, 3288), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_34.pkl, Shape: (4, 3138), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_35.pkl, Shape: (4, 3150), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_36.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_37.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_38.pkl, Shape: (4, 3070), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_39.pkl, Shape: (4, 3283), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_4.pkl, Shape: (4, 3058), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_40.pkl, Shape: (4, 4475), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_41.pkl, Shape: (4, 3162), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_42.pkl, Shape: (4, 3704), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_43.pkl, Shape: (4, 3333), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_44.pkl, Shape: (4, 3396), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_45.pkl, Shape: (4, 3450), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_46.pkl, Shape: (4, 3537), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_47.pkl, Shape: (4, 3363), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_48.pkl, Shape: (4, 3250), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_49.pkl, Shape: (4, 3279), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_5.pkl, Shape: (4, 3212), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_50.pkl, Shape: (4, 3508), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_51.pkl, Shape: (4, 3358), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_52.pkl, Shape: (4, 3388), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_53.pkl, Shape: (4, 3379), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_54.pkl, Shape: (4, 3558), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_55.pkl, Shape: (4, 3392), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_6.pkl, Shape: (4, 3095), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_7.pkl, Shape: (4, 3071), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_8.pkl, Shape: (4, 3096), Type: <class 'numpy.ndarray'>\n",
      "Poly File: poly_truth_9.pkl, Shape: (4, 3225), Type: <class 'numpy.ndarray'>\n",
      "Loaded from Poly C:\\Users\\User\\Documents\\Lie detect data\\CombinedPolyData: 35 lie samples, 55 truth samples\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Epoch 1/100, Loss: 0.3361302172609915\n",
      "Validation Loss: 3.0216649820407233, Validation Accuracy: 0.585635359116022\n",
      "Precision: 0.7410714285714286, Recall: 0.6434108527131783, F1-score: 0.6887966804979253\n",
      "Model saved to ensemble_model_fold_0.pth\n",
      "Epoch 2/100, Loss: 0.04131205218921726\n",
      "Validation Loss: 4.766150017579396, Validation Accuracy: 0.6353591160220995\n",
      "Precision: 0.7603305785123967, Recall: 0.7131782945736435, F1-score: 0.736\n",
      "Epoch 3/100, Loss: 0.028970862515658762\n",
      "Validation Loss: 5.941318926711877, Validation Accuracy: 0.6077348066298343\n",
      "Precision: 0.7338709677419355, Recall: 0.7054263565891473, F1-score: 0.7193675889328063\n",
      "Epoch 4/100, Loss: 0.029858551416206563\n",
      "Validation Loss: 5.553406196335952, Validation Accuracy: 0.5966850828729282\n",
      "Precision: 0.7295081967213115, Recall: 0.689922480620155, F1-score: 0.7091633466135459\n",
      "Epoch 5/100, Loss: 0.02038052102398069\n",
      "Validation Loss: 5.519242224593957, Validation Accuracy: 0.585635359116022\n",
      "Precision: 0.7213114754098361, Recall: 0.6821705426356589, F1-score: 0.701195219123506\n",
      "Epoch 6/100, Loss: 0.005678031642067556\n",
      "Validation Loss: 5.501446170111497, Validation Accuracy: 0.6022099447513812\n",
      "Precision: 0.7317073170731707, Recall: 0.6976744186046512, F1-score: 0.7142857142857143\n",
      "Epoch 7/100, Loss: 0.0024066537892698157\n",
      "Validation Loss: 5.686721671372652, Validation Accuracy: 0.6022099447513812\n",
      "Precision: 0.7317073170731707, Recall: 0.6976744186046512, F1-score: 0.7142857142857143\n",
      "Epoch 8/100, Loss: 0.002247204130374788\n",
      "Validation Loss: 5.762601727930208, Validation Accuracy: 0.6298342541436464\n",
      "Precision: 0.7384615384615385, Recall: 0.7441860465116279, F1-score: 0.7413127413127413\n",
      "Epoch 9/100, Loss: 0.0017578379896197778\n",
      "Validation Loss: 5.785534092846016, Validation Accuracy: 0.6187845303867403\n",
      "Precision: 0.7380952380952381, Recall: 0.7209302325581395, F1-score: 0.7294117647058823\n",
      "Epoch 10/100, Loss: 0.001767497605214885\n",
      "Validation Loss: 5.771845421753824, Validation Accuracy: 0.6243093922651933\n",
      "Precision: 0.7401574803149606, Recall: 0.7286821705426356, F1-score: 0.734375\n",
      "Epoch 11/100, Loss: 0.001049002838499291\n",
      "Validation Loss: 5.609140788204968, Validation Accuracy: 0.6077348066298343\n",
      "Precision: 0.7338709677419355, Recall: 0.7054263565891473, F1-score: 0.7193675889328063\n",
      "Epoch 12/100, Loss: 0.0008242589774454245\n",
      "Validation Loss: 6.024996952153742, Validation Accuracy: 0.6187845303867403\n",
      "Precision: 0.7380952380952381, Recall: 0.7209302325581395, F1-score: 0.7294117647058823\n",
      "Epoch 13/100, Loss: 0.0009853686788119376\n",
      "Validation Loss: 5.952122916467488, Validation Accuracy: 0.6243093922651933\n",
      "Precision: 0.7401574803149606, Recall: 0.7286821705426356, F1-score: 0.734375\n",
      "Epoch 14/100, Loss: 0.0007848980179308759\n",
      "Validation Loss: 6.030373995192349, Validation Accuracy: 0.6408839779005525\n",
      "Precision: 0.7461538461538462, Recall: 0.751937984496124, F1-score: 0.749034749034749\n",
      "Epoch 15/100, Loss: 0.0006428195558025133\n",
      "Validation Loss: 6.1683019556415575, Validation Accuracy: 0.6408839779005525\n",
      "Precision: 0.7461538461538462, Recall: 0.751937984496124, F1-score: 0.749034749034749\n",
      "Epoch 16/100, Loss: 0.0005485601465503956\n",
      "Validation Loss: 6.2443470801226795, Validation Accuracy: 0.6464088397790055\n",
      "Precision: 0.751937984496124, Recall: 0.751937984496124, F1-score: 0.751937984496124\n",
      "Epoch 17/100, Loss: 0.0003703015642410416\n",
      "Validation Loss: 6.239784344332293, Validation Accuracy: 0.6353591160220995\n",
      "Precision: 0.7441860465116279, Recall: 0.7441860465116279, F1-score: 0.7441860465116279\n",
      "Epoch 18/100, Loss: 0.0003756990201585116\n",
      "Validation Loss: 6.3035867218083395, Validation Accuracy: 0.6408839779005525\n",
      "Precision: 0.7461538461538462, Recall: 0.751937984496124, F1-score: 0.749034749034749\n",
      "Epoch 19/100, Loss: 0.0004755745574887745\n",
      "Validation Loss: 6.228611615641664, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.7578125, Recall: 0.751937984496124, F1-score: 0.754863813229572\n",
      "Epoch 20/100, Loss: 0.0003186181526568059\n",
      "Validation Loss: 6.153660330766191, Validation Accuracy: 0.6353591160220995\n",
      "Precision: 0.7480314960629921, Recall: 0.7364341085271318, F1-score: 0.7421875\n",
      "Epoch 21/100, Loss: 0.00038756758681302017\n",
      "Validation Loss: 6.312168618431315, Validation Accuracy: 0.6574585635359116\n",
      "Precision: 0.7637795275590551, Recall: 0.751937984496124, F1-score: 0.7578125\n",
      "Epoch 22/100, Loss: 0.0003582434895292863\n",
      "Validation Loss: 6.2694008454370005, Validation Accuracy: 0.6574585635359116\n",
      "Precision: 0.7637795275590551, Recall: 0.751937984496124, F1-score: 0.7578125\n",
      "Epoch 23/100, Loss: 0.0005079995338140483\n",
      "Validation Loss: 5.903131735511124, Validation Accuracy: 0.6298342541436464\n",
      "Precision: 0.7421875, Recall: 0.7364341085271318, F1-score: 0.7392996108949417\n",
      "Epoch 24/100, Loss: 0.0003551825720933266\n",
      "Validation Loss: 5.699631744219611, Validation Accuracy: 0.6298342541436464\n",
      "Precision: 0.7421875, Recall: 0.7364341085271318, F1-score: 0.7392996108949417\n",
      "Epoch 25/100, Loss: 0.0003660644429146487\n",
      "Validation Loss: 6.095608646438147, Validation Accuracy: 0.6408839779005525\n",
      "Precision: 0.7461538461538462, Recall: 0.751937984496124, F1-score: 0.749034749034749\n",
      "Epoch 26/100, Loss: 0.0002916690043548442\n",
      "Validation Loss: 6.071344650428121, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.7578125, Recall: 0.751937984496124, F1-score: 0.754863813229572\n",
      "Epoch 27/100, Loss: 0.0003012409847732063\n",
      "Validation Loss: 6.167601698776707, Validation Accuracy: 0.6408839779005525\n",
      "Precision: 0.7461538461538462, Recall: 0.751937984496124, F1-score: 0.749034749034749\n",
      "Epoch 28/100, Loss: 0.00029065847214345314\n",
      "Validation Loss: 6.249552082115163, Validation Accuracy: 0.6408839779005525\n",
      "Precision: 0.7461538461538462, Recall: 0.751937984496124, F1-score: 0.749034749034749\n",
      "Epoch 29/100, Loss: 0.00016173149140286114\n",
      "Validation Loss: 6.329306137360011, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.7578125, Recall: 0.751937984496124, F1-score: 0.754863813229572\n",
      "Epoch 30/100, Loss: 0.00022571338551339673\n",
      "Validation Loss: 6.156698660071318, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.7578125, Recall: 0.751937984496124, F1-score: 0.754863813229572\n",
      "Epoch 31/100, Loss: 0.0001627616587332644\n",
      "Validation Loss: 6.137798404553905, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.7578125, Recall: 0.751937984496124, F1-score: 0.754863813229572\n",
      "Epoch 32/100, Loss: 0.00018108544645656366\n",
      "Validation Loss: 6.370653477264568, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.7578125, Recall: 0.751937984496124, F1-score: 0.754863813229572\n",
      "Epoch 33/100, Loss: 0.0001587003155994656\n",
      "Validation Loss: 6.122631526086479, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.7578125, Recall: 0.751937984496124, F1-score: 0.754863813229572\n",
      "Epoch 34/100, Loss: 0.0001649892675269863\n",
      "Validation Loss: 6.394704269439292, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.7578125, Recall: 0.751937984496124, F1-score: 0.754863813229572\n",
      "Epoch 35/100, Loss: 0.0001414130084450941\n",
      "Validation Loss: 6.624670492407556, Validation Accuracy: 0.6408839779005525\n",
      "Precision: 0.7461538461538462, Recall: 0.751937984496124, F1-score: 0.749034749034749\n",
      "Epoch 36/100, Loss: 0.00019991022994266436\n",
      "Validation Loss: 6.413020357955247, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.7578125, Recall: 0.751937984496124, F1-score: 0.754863813229572\n",
      "Epoch 37/100, Loss: 0.00013290257220432977\n",
      "Validation Loss: 6.378077681331585, Validation Accuracy: 0.6574585635359116\n",
      "Precision: 0.7637795275590551, Recall: 0.751937984496124, F1-score: 0.7578125\n",
      "Epoch 38/100, Loss: 0.00017217581091699685\n",
      "Validation Loss: 6.515078728902154, Validation Accuracy: 0.6574585635359116\n",
      "Precision: 0.7637795275590551, Recall: 0.751937984496124, F1-score: 0.7578125\n",
      "Epoch 39/100, Loss: 0.00012241065011645938\n",
      "Validation Loss: 6.606463027962794, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.7578125, Recall: 0.751937984496124, F1-score: 0.754863813229572\n",
      "Epoch 40/100, Loss: 0.00010647904934065384\n",
      "Validation Loss: 6.457692360777098, Validation Accuracy: 0.6574585635359116\n",
      "Precision: 0.7637795275590551, Recall: 0.751937984496124, F1-score: 0.7578125\n",
      "Epoch 41/100, Loss: 0.0001347498539416847\n",
      "Validation Loss: 6.365658945015942, Validation Accuracy: 0.6574585635359116\n",
      "Precision: 0.7637795275590551, Recall: 0.751937984496124, F1-score: 0.7578125\n",
      "Epoch 42/100, Loss: 0.0001202971965976\n",
      "Validation Loss: 6.587673643332285, Validation Accuracy: 0.6519337016574586\n",
      "Precision: 0.7578125, Recall: 0.751937984496124, F1-score: 0.754863813229572\n",
      "Epoch 43/100, Loss: 0.00010619457615727394\n",
      "Validation Loss: 6.62540017766878, Validation Accuracy: 0.6574585635359116\n",
      "Precision: 0.7637795275590551, Recall: 0.751937984496124, F1-score: 0.7578125\n",
      "Epoch 44/100, Loss: 0.00010182227456804564\n",
      "Validation Loss: 6.62133945330667, Validation Accuracy: 0.6629834254143646\n",
      "Precision: 0.765625, Recall: 0.7596899224806202, F1-score: 0.7626459143968871\n",
      "Epoch 45/100, Loss: 7.74597493773399e-05\n",
      "Validation Loss: 6.846195871689512, Validation Accuracy: 0.6629834254143646\n",
      "Precision: 0.765625, Recall: 0.7596899224806202, F1-score: 0.7626459143968871\n",
      "Epoch 46/100, Loss: 9.131548105756337e-05\n",
      "Validation Loss: 6.872396173169061, Validation Accuracy: 0.6629834254143646\n",
      "Precision: 0.765625, Recall: 0.7596899224806202, F1-score: 0.7626459143968871\n",
      "Epoch 47/100, Loss: 0.00010958263357470817\n",
      "Validation Loss: 6.958121726405807, Validation Accuracy: 0.6629834254143646\n",
      "Precision: 0.765625, Recall: 0.7596899224806202, F1-score: 0.7626459143968871\n",
      "Epoch 48/100, Loss: 9.501483132604942e-05\n",
      "Validation Loss: 6.7216565574053675, Validation Accuracy: 0.6629834254143646\n",
      "Precision: 0.765625, Recall: 0.7596899224806202, F1-score: 0.7626459143968871\n",
      "Epoch 49/100, Loss: 0.0001002710192210543\n",
      "Validation Loss: 6.887289628289484, Validation Accuracy: 0.6629834254143646\n",
      "Precision: 0.765625, Recall: 0.7596899224806202, F1-score: 0.7626459143968871\n",
      "Epoch 50/100, Loss: 0.00011400647360915173\n",
      "Validation Loss: 6.726318400236778, Validation Accuracy: 0.6685082872928176\n",
      "Precision: 0.7716535433070866, Recall: 0.7596899224806202, F1-score: 0.765625\n",
      "Epoch 51/100, Loss: 7.321244186186959e-05\n",
      "Validation Loss: 6.8164543153446475, Validation Accuracy: 0.6740331491712708\n",
      "Precision: 0.7777777777777778, Recall: 0.7596899224806202, F1-score: 0.7686274509803922\n",
      "Epoch 52/100, Loss: 9.190699717898099e-05\n",
      "Validation Loss: 6.943301040582203, Validation Accuracy: 0.6629834254143646\n",
      "Precision: 0.765625, Recall: 0.7596899224806202, F1-score: 0.7626459143968871\n",
      "Epoch 53/100, Loss: 6.518530881294282e-05\n",
      "Validation Loss: 6.951197390463979, Validation Accuracy: 0.6629834254143646\n",
      "Precision: 0.765625, Recall: 0.7596899224806202, F1-score: 0.7626459143968871\n",
      "Epoch 54/100, Loss: 6.042542948610693e-05\n",
      "Validation Loss: 7.1672452040171875, Validation Accuracy: 0.6629834254143646\n",
      "Precision: 0.765625, Recall: 0.7596899224806202, F1-score: 0.7626459143968871\n",
      "Epoch 55/100, Loss: 7.23656519880933e-05\n",
      "Validation Loss: 6.868062592208541, Validation Accuracy: 0.6740331491712708\n",
      "Precision: 0.7777777777777778, Recall: 0.7596899224806202, F1-score: 0.7686274509803922\n",
      "Epoch 56/100, Loss: 8.096735890224711e-05\n",
      "Validation Loss: 6.782335026092672, Validation Accuracy: 0.6740331491712708\n",
      "Precision: 0.7777777777777778, Recall: 0.7596899224806202, F1-score: 0.7686274509803922\n",
      "Epoch 57/100, Loss: 7.324032219457877e-05\n",
      "Validation Loss: 6.995655820666191, Validation Accuracy: 0.6795580110497238\n",
      "Precision: 0.784, Recall: 0.7596899224806202, F1-score: 0.7716535433070866\n",
      "Epoch 58/100, Loss: 5.7740152035042534e-05\n",
      "Validation Loss: 6.916140060910645, Validation Accuracy: 0.6795580110497238\n",
      "Precision: 0.784, Recall: 0.7596899224806202, F1-score: 0.7716535433070866\n",
      "Epoch 59/100, Loss: 6.344015452934097e-05\n",
      "Validation Loss: 6.976300380386722, Validation Accuracy: 0.6740331491712708\n",
      "Precision: 0.7777777777777778, Recall: 0.7596899224806202, F1-score: 0.7686274509803922\n",
      "Epoch 60/100, Loss: 6.889072868077051e-05\n",
      "Validation Loss: 6.907565443854158, Validation Accuracy: 0.6629834254143646\n",
      "Precision: 0.765625, Recall: 0.7596899224806202, F1-score: 0.7626459143968871\n",
      "Epoch 61/100, Loss: 5.5529866614278944e-05\n",
      "Validation Loss: 7.075045794306789, Validation Accuracy: 0.6740331491712708\n",
      "Precision: 0.7777777777777778, Recall: 0.7596899224806202, F1-score: 0.7686274509803922\n",
      "Epoch 62/100, Loss: 4.9723648809655664e-05\n",
      "Validation Loss: 6.9359074500195375, Validation Accuracy: 0.6740331491712708\n",
      "Precision: 0.7777777777777778, Recall: 0.7596899224806202, F1-score: 0.7686274509803922\n",
      "Epoch 63/100, Loss: 6.290185780244428e-05\n",
      "Validation Loss: 6.948293901941118, Validation Accuracy: 0.6795580110497238\n",
      "Precision: 0.784, Recall: 0.7596899224806202, F1-score: 0.7716535433070866\n",
      "Epoch 64/100, Loss: 6.118079941804429e-05\n",
      "Validation Loss: 7.142848884783841, Validation Accuracy: 0.6795580110497238\n",
      "Precision: 0.784, Recall: 0.7596899224806202, F1-score: 0.7716535433070866\n",
      "Epoch 65/100, Loss: 5.4417042451386045e-05\n",
      "Validation Loss: 7.127172949568679, Validation Accuracy: 0.6740331491712708\n",
      "Precision: 0.7777777777777778, Recall: 0.7596899224806202, F1-score: 0.7686274509803922\n",
      "Epoch 66/100, Loss: 5.069354274667148e-05\n",
      "Validation Loss: 7.097247771860566, Validation Accuracy: 0.6795580110497238\n",
      "Precision: 0.784, Recall: 0.7596899224806202, F1-score: 0.7716535433070866\n",
      "Epoch 67/100, Loss: 3.756253766103631e-05\n",
      "Validation Loss: 7.131938934500795, Validation Accuracy: 0.6906077348066298\n",
      "Precision: 0.7967479674796748, Recall: 0.7596899224806202, F1-score: 0.7777777777777778\n",
      "Epoch 68/100, Loss: 4.3539485588439675e-05\n",
      "Validation Loss: 7.125608284996512, Validation Accuracy: 0.6740331491712708\n",
      "Precision: 0.7777777777777778, Recall: 0.7596899224806202, F1-score: 0.7686274509803922\n",
      "Epoch 69/100, Loss: 5.2804784758109236e-05\n",
      "Validation Loss: 7.0773841558063095, Validation Accuracy: 0.6906077348066298\n",
      "Precision: 0.7967479674796748, Recall: 0.7596899224806202, F1-score: 0.7777777777777778\n",
      "Epoch 70/100, Loss: 3.801696036968375e-05\n",
      "Validation Loss: 7.09694598322191, Validation Accuracy: 0.6795580110497238\n",
      "Precision: 0.784, Recall: 0.7596899224806202, F1-score: 0.7716535433070866\n",
      "Epoch 71/100, Loss: 4.6937544671739793e-05\n",
      "Validation Loss: 7.3023539705900475, Validation Accuracy: 0.6740331491712708\n",
      "Precision: 0.7777777777777778, Recall: 0.7596899224806202, F1-score: 0.7686274509803922\n",
      "Epoch 72/100, Loss: 5.6145384121464303e-05\n",
      "Validation Loss: 7.216843022829077, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 73/100, Loss: 4.733765865694295e-05\n",
      "Validation Loss: 7.01763694161006, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 74/100, Loss: 3.8261837213819185e-05\n",
      "Validation Loss: 7.203467586582216, Validation Accuracy: 0.6850828729281768\n",
      "Precision: 0.7903225806451613, Recall: 0.7596899224806202, F1-score: 0.7747035573122529\n",
      "Epoch 75/100, Loss: 4.8971089048185e-05\n",
      "Validation Loss: 7.044618485767084, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 76/100, Loss: 4.024039278268295e-05\n",
      "Validation Loss: 7.181300933327293, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 77/100, Loss: 4.5059192975926976e-05\n",
      "Validation Loss: 7.113151230635897, Validation Accuracy: 0.6795580110497238\n",
      "Precision: 0.784, Recall: 0.7596899224806202, F1-score: 0.7716535433070866\n",
      "Epoch 78/100, Loss: 4.393771697645358e-05\n",
      "Validation Loss: 7.068828498731212, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 79/100, Loss: 3.6039807679818146e-05\n",
      "Validation Loss: 7.316563103988301, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 80/100, Loss: 3.328884710640523e-05\n",
      "Validation Loss: 7.459924264422928, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 81/100, Loss: 2.8815049266957733e-05\n",
      "Validation Loss: 7.356943403487094, Validation Accuracy: 0.6850828729281768\n",
      "Precision: 0.7903225806451613, Recall: 0.7596899224806202, F1-score: 0.7747035573122529\n",
      "Epoch 82/100, Loss: 3.3236068404107755e-05\n",
      "Validation Loss: 7.402773847745266, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 83/100, Loss: 2.846754541489342e-05\n",
      "Validation Loss: 7.474612016424847, Validation Accuracy: 0.6850828729281768\n",
      "Precision: 0.7903225806451613, Recall: 0.7596899224806202, F1-score: 0.7747035573122529\n",
      "Epoch 84/100, Loss: 3.3489571042840303e-05\n",
      "Validation Loss: 7.34069906406027, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 85/100, Loss: 3.030438697138038e-05\n",
      "Validation Loss: 7.452207920587777, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 86/100, Loss: 2.7451107484921522e-05\n",
      "Validation Loss: 7.368138401167623, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 87/100, Loss: 3.2348701035781836e-05\n",
      "Validation Loss: 7.292834480147576, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 88/100, Loss: 6.875892176338994e-05\n",
      "Validation Loss: 6.942317920329515, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 89/100, Loss: 2.480221389807487e-05\n",
      "Validation Loss: 7.372147531335941, Validation Accuracy: 0.6795580110497238\n",
      "Precision: 0.784, Recall: 0.7596899224806202, F1-score: 0.7716535433070866\n",
      "Epoch 90/100, Loss: 3.059599864959258e-05\n",
      "Validation Loss: 7.36350491088039, Validation Accuracy: 0.6850828729281768\n",
      "Precision: 0.7903225806451613, Recall: 0.7596899224806202, F1-score: 0.7747035573122529\n",
      "Epoch 91/100, Loss: 2.5124776864042058e-05\n",
      "Validation Loss: 7.4026229782127, Validation Accuracy: 0.6850828729281768\n",
      "Precision: 0.7903225806451613, Recall: 0.7596899224806202, F1-score: 0.7747035573122529\n",
      "Epoch 92/100, Loss: 2.3310982783186773e-05\n",
      "Validation Loss: 7.306802075026401, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 93/100, Loss: 2.7586639959054082e-05\n",
      "Validation Loss: 7.280384411113725, Validation Accuracy: 0.6795580110497238\n",
      "Precision: 0.784, Recall: 0.7596899224806202, F1-score: 0.7716535433070866\n",
      "Epoch 94/100, Loss: 3.013206826688967e-05\n",
      "Validation Loss: 7.4595425996230915, Validation Accuracy: 0.6850828729281768\n",
      "Precision: 0.7903225806451613, Recall: 0.7596899224806202, F1-score: 0.7747035573122529\n",
      "Epoch 95/100, Loss: 2.569899623949823e-05\n",
      "Validation Loss: 7.557488494848561, Validation Accuracy: 0.6795580110497238\n",
      "Precision: 0.784, Recall: 0.7596899224806202, F1-score: 0.7716535433070866\n",
      "Epoch 96/100, Loss: 2.921480363227147e-05\n",
      "Validation Loss: 7.663945573838039, Validation Accuracy: 0.6795580110497238\n",
      "Precision: 0.784, Recall: 0.7596899224806202, F1-score: 0.7716535433070866\n",
      "Epoch 97/100, Loss: 1.823949658330548e-05\n",
      "Validation Loss: 7.429447552703398, Validation Accuracy: 0.6906077348066298\n",
      "Precision: 0.7967479674796748, Recall: 0.7596899224806202, F1-score: 0.7777777777777778\n",
      "Epoch 98/100, Loss: 2.5667333360364825e-05\n",
      "Validation Loss: 7.597335126857312, Validation Accuracy: 0.6961325966850829\n",
      "Precision: 0.8032786885245902, Recall: 0.7596899224806202, F1-score: 0.7808764940239044\n",
      "Epoch 99/100, Loss: 1.856337307041637e-05\n",
      "Validation Loss: 7.408700493212867, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Epoch 100/100, Loss: 2.2436011313686777e-05\n",
      "Validation Loss: 7.646343105409566, Validation Accuracy: 0.7016574585635359\n",
      "Precision: 0.8099173553719008, Recall: 0.7596899224806202, F1-score: 0.784\n",
      "Validation Loss: 3.0216649820407233, Validation Accuracy: 0.585635359116022\n",
      "Precision: 0.7410714285714286, Recall: 0.6434108527131783, F1-score: 0.6887966804979253\n",
      "Confusion Matrix:\n",
      "[[23 29]\n",
      " [46 83]]\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch 1/100, Loss: 0.262803580815671\n",
      "Validation Loss: 1.4273523520678282, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7542372881355932, Recall: 0.8317757009345794, F1-score: 0.7911111111111111\n",
      "Model saved to ensemble_model_fold_1.pth\n",
      "Epoch 2/100, Loss: 0.03287448266443486\n",
      "Validation Loss: 3.68868890053515, Validation Accuracy: 0.6057142857142858\n",
      "Precision: 0.6357142857142857, Recall: 0.8317757009345794, F1-score: 0.7206477732793523\n",
      "Epoch 3/100, Loss: 0.03881981638748281\n",
      "Validation Loss: 3.5403480390571835, Validation Accuracy: 0.6914285714285714\n",
      "Precision: 0.712, Recall: 0.8317757009345794, F1-score: 0.7672413793103449\n",
      "Epoch 4/100, Loss: 0.07262965921169477\n",
      "Validation Loss: 4.273905413536643, Validation Accuracy: 0.6514285714285715\n",
      "Precision: 0.6742424242424242, Recall: 0.8317757009345794, F1-score: 0.7447698744769874\n",
      "Epoch 5/100, Loss: 0.0072322339218165626\n",
      "Validation Loss: 4.216443693182858, Validation Accuracy: 0.6857142857142857\n",
      "Precision: 0.7063492063492064, Recall: 0.8317757009345794, F1-score: 0.7639484978540773\n",
      "Epoch 6/100, Loss: 0.0011511723973853805\n",
      "Validation Loss: 4.367427505111361, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 7/100, Loss: 0.00048281836658740457\n",
      "Validation Loss: 4.512895396672927, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 8/100, Loss: 0.0002963459966546604\n",
      "Validation Loss: 4.445524729550622, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 9/100, Loss: 0.00034661876399392594\n",
      "Validation Loss: 4.428186690478469, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 10/100, Loss: 0.00022462333701393314\n",
      "Validation Loss: 4.4255556220499175, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 11/100, Loss: 0.00024322971012225025\n",
      "Validation Loss: 4.513459491218479, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 12/100, Loss: 0.00023180980131580023\n",
      "Validation Loss: 4.486338243053372, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 13/100, Loss: 0.00025532514663003286\n",
      "Validation Loss: 4.397615167331726, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 14/100, Loss: 0.0002445202711669481\n",
      "Validation Loss: 4.545678189004927, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 15/100, Loss: 0.00025832742613829396\n",
      "Validation Loss: 4.44663544598249, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 16/100, Loss: 0.00015369043383846778\n",
      "Validation Loss: 4.514836312121285, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 17/100, Loss: 0.00015593153864301712\n",
      "Validation Loss: 4.526614774474486, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 18/100, Loss: 0.00013978967577562193\n",
      "Validation Loss: 4.5560158715185635, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 19/100, Loss: 0.0001269309673830321\n",
      "Validation Loss: 4.574233565794809, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 20/100, Loss: 0.00012083420807821692\n",
      "Validation Loss: 4.75692135496259, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 21/100, Loss: 0.0001168558168179364\n",
      "Validation Loss: 4.533627896181618, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 22/100, Loss: 8.40344413764645e-05\n",
      "Validation Loss: 4.705436552355725, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 23/100, Loss: 0.00013321044076519684\n",
      "Validation Loss: 4.6941189783246955, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 24/100, Loss: 0.00013504326686112714\n",
      "Validation Loss: 4.654011675978836, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 25/100, Loss: 0.00010668365688578281\n",
      "Validation Loss: 4.714334530416333, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 26/100, Loss: 8.373548755002957e-05\n",
      "Validation Loss: 4.654139966626341, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 27/100, Loss: 8.654961404393664e-05\n",
      "Validation Loss: 4.802205496314855, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 28/100, Loss: 0.0001494016130957713\n",
      "Validation Loss: 4.8870064744381425, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 29/100, Loss: 0.00012002689972708443\n",
      "Validation Loss: 4.8667857704834505, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 30/100, Loss: 6.734600411088347e-05\n",
      "Validation Loss: 4.7474649166324525, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 31/100, Loss: 7.276065158616045e-05\n",
      "Validation Loss: 4.818496845725652, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 32/100, Loss: 5.719060952931917e-05\n",
      "Validation Loss: 4.789638386755541, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 33/100, Loss: 6.359065097664522e-05\n",
      "Validation Loss: 4.708554824918489, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 34/100, Loss: 6.577479505646504e-05\n",
      "Validation Loss: 4.862745610029378, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 35/100, Loss: 6.398844816620415e-05\n",
      "Validation Loss: 4.872558921764721, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 36/100, Loss: 6.937978745706157e-05\n",
      "Validation Loss: 4.875744067949806, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 37/100, Loss: 4.875448337315902e-05\n",
      "Validation Loss: 4.912022762216414, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 38/100, Loss: 4.872886665907572e-05\n",
      "Validation Loss: 4.840547225016053, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 39/100, Loss: 5.2319394517515626e-05\n",
      "Validation Loss: 4.9334157243696, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 40/100, Loss: 5.9879200231686504e-05\n",
      "Validation Loss: 4.736704630243669, Validation Accuracy: 0.6857142857142857\n",
      "Precision: 0.7063492063492064, Recall: 0.8317757009345794, F1-score: 0.7639484978540773\n",
      "Epoch 41/100, Loss: 4.2743658748160364e-05\n",
      "Validation Loss: 4.790760506681788, Validation Accuracy: 0.6857142857142857\n",
      "Precision: 0.7063492063492064, Recall: 0.8317757009345794, F1-score: 0.7639484978540773\n",
      "Epoch 42/100, Loss: 4.9652238523378855e-05\n",
      "Validation Loss: 5.0213349326829, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 43/100, Loss: 4.379984545721527e-05\n",
      "Validation Loss: 5.051685395112145, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 44/100, Loss: 5.149158508525412e-05\n",
      "Validation Loss: 5.126913635832655, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 45/100, Loss: 4.73456869324688e-05\n",
      "Validation Loss: 5.033711776935282, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 46/100, Loss: 3.839940356442639e-05\n",
      "Validation Loss: 5.148310270518171, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 47/100, Loss: 3.926217847549651e-05\n",
      "Validation Loss: 4.911716601144387, Validation Accuracy: 0.6857142857142857\n",
      "Precision: 0.7063492063492064, Recall: 0.8317757009345794, F1-score: 0.7639484978540773\n",
      "Epoch 48/100, Loss: 4.479208268293178e-05\n",
      "Validation Loss: 4.931974565183434, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 49/100, Loss: 3.709501334962321e-05\n",
      "Validation Loss: 5.0888553274053265, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 50/100, Loss: 5.014027062107592e-05\n",
      "Validation Loss: 5.0390900855903356, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 51/100, Loss: 3.54444100831112e-05\n",
      "Validation Loss: 5.100994107651786, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 52/100, Loss: 3.60625959956451e-05\n",
      "Validation Loss: 5.006334905679978, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 53/100, Loss: 3.4189227169652746e-05\n",
      "Validation Loss: 5.065657936332475, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 54/100, Loss: 3.183281217822298e-05\n",
      "Validation Loss: 4.997680684835359, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 55/100, Loss: 4.221741474452756e-05\n",
      "Validation Loss: 4.980009332452028, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 56/100, Loss: 4.700753256751492e-05\n",
      "Validation Loss: 4.970816145507949, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 57/100, Loss: 4.2390931800658414e-05\n",
      "Validation Loss: 5.092677629176857, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 58/100, Loss: 2.5661672386452967e-05\n",
      "Validation Loss: 5.143409893287753, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 59/100, Loss: 3.215652348368773e-05\n",
      "Validation Loss: 5.190189326423327, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 60/100, Loss: 2.2118927210120393e-05\n",
      "Validation Loss: 5.103125963735995, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 61/100, Loss: 2.3968618277100024e-05\n",
      "Validation Loss: 5.224453214267366, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 62/100, Loss: 2.6584494245677586e-05\n",
      "Validation Loss: 5.168372530374957, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 63/100, Loss: 3.4162485488783055e-05\n",
      "Validation Loss: 5.104583681497995, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 64/100, Loss: 2.6241087510925354e-05\n",
      "Validation Loss: 5.118839692418987, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 65/100, Loss: 4.228479612870354e-05\n",
      "Validation Loss: 5.163269357002719, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 66/100, Loss: 1.9730982711981444e-05\n",
      "Validation Loss: 5.108789976848736, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 67/100, Loss: 3.17293601277413e-05\n",
      "Validation Loss: 5.330673053157322, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 68/100, Loss: 2.1556767462035015e-05\n",
      "Validation Loss: 5.259797897993849, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 69/100, Loss: 1.9976528504865126e-05\n",
      "Validation Loss: 5.289815335296832, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 70/100, Loss: 1.6798378190685526e-05\n",
      "Validation Loss: 5.2994818999759445, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 71/100, Loss: 2.1849469374520442e-05\n",
      "Validation Loss: 5.164885436532738, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 72/100, Loss: 1.6273161842642974e-05\n",
      "Validation Loss: 5.228777009813105, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 73/100, Loss: 2.1792794283233736e-05\n",
      "Validation Loss: 5.287045332564351, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 74/100, Loss: 2.194646183302969e-05\n",
      "Validation Loss: 5.146605324819878, Validation Accuracy: 0.6857142857142857\n",
      "Precision: 0.7063492063492064, Recall: 0.8317757009345794, F1-score: 0.7639484978540773\n",
      "Epoch 75/100, Loss: 1.6675648701891532e-05\n",
      "Validation Loss: 5.263608179566897, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 76/100, Loss: 2.178652455597785e-05\n",
      "Validation Loss: 5.275802531060132, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 77/100, Loss: 1.3598349833425042e-05\n",
      "Validation Loss: 5.155318071891088, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 78/100, Loss: 2.0070092734414402e-05\n",
      "Validation Loss: 5.251841441403182, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 79/100, Loss: 2.7030482903015834e-05\n",
      "Validation Loss: 5.470705391793672, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 80/100, Loss: 1.247615974856823e-05\n",
      "Validation Loss: 5.328952286976953, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 81/100, Loss: 1.705001295200977e-05\n",
      "Validation Loss: 5.319417397867558, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 82/100, Loss: 1.63439469726967e-05\n",
      "Validation Loss: 5.287414357781624, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 83/100, Loss: 1.4149477361039923e-05\n",
      "Validation Loss: 5.264218154009238, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 84/100, Loss: 1.0448404977954814e-05\n",
      "Validation Loss: 5.331652747924333, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 85/100, Loss: 1.2453328729122859e-05\n",
      "Validation Loss: 5.439473666244642, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 86/100, Loss: 1.0169239706906788e-05\n",
      "Validation Loss: 5.2700157695059415, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 87/100, Loss: 1.652735101250376e-05\n",
      "Validation Loss: 5.4075165403689125, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 88/100, Loss: 1.961076475727926e-05\n",
      "Validation Loss: 5.463486892965496, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 89/100, Loss: 1.3118828557997139e-05\n",
      "Validation Loss: 5.350527307646796, Validation Accuracy: 0.6685714285714286\n",
      "Precision: 0.689922480620155, Recall: 0.8317757009345794, F1-score: 0.7542372881355932\n",
      "Epoch 90/100, Loss: 1.0139323528335353e-05\n",
      "Validation Loss: 5.304413564356461, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 91/100, Loss: 1.438756420431749e-05\n",
      "Validation Loss: 5.352227055608334, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 92/100, Loss: 1.2702948090748123e-05\n",
      "Validation Loss: 5.345971725592487, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 93/100, Loss: 8.762051754966175e-06\n",
      "Validation Loss: 5.351454044302955, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 94/100, Loss: 1.55098303883013e-05\n",
      "Validation Loss: 5.2890224022242665, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 95/100, Loss: 1.0985519815894426e-05\n",
      "Validation Loss: 5.467871913854954, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 96/100, Loss: 1.2208033400777177e-05\n",
      "Validation Loss: 5.398499415904856, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 97/100, Loss: 1.1770816191377284e-05\n",
      "Validation Loss: 5.3957711509380415, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Epoch 98/100, Loss: 1.3637581241473148e-05\n",
      "Validation Loss: 5.254824169478525, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 99/100, Loss: 1.1521960987674143e-05\n",
      "Validation Loss: 5.33519395012748, Validation Accuracy: 0.68\n",
      "Precision: 0.7007874015748031, Recall: 0.8317757009345794, F1-score: 0.7606837606837606\n",
      "Epoch 100/100, Loss: 1.0169930130624985e-05\n",
      "Validation Loss: 5.468362796513247, Validation Accuracy: 0.6742857142857143\n",
      "Precision: 0.6953125, Recall: 0.8317757009345794, F1-score: 0.7574468085106383\n",
      "Validation Loss: 1.4273523520678282, Validation Accuracy: 0.7314285714285714\n",
      "Precision: 0.7542372881355932, Recall: 0.8317757009345794, F1-score: 0.7911111111111111\n",
      "Confusion Matrix:\n",
      "[[39 29]\n",
      " [18 89]]\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch 1/100, Loss: 0.2111212469947835\n",
      "Validation Loss: 0.9211562871932983, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.719626168224299, Recall: 0.7264150943396226, F1-score: 0.7230046948356808\n",
      "Model saved to ensemble_model_fold_2.pth\n",
      "Epoch 2/100, Loss: 0.04624603086267598\n",
      "Validation Loss: 1.9298736055692036, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7083333333333334, Recall: 0.8018867924528302, F1-score: 0.7522123893805309\n",
      "Epoch 3/100, Loss: 0.020212404648191296\n",
      "Validation Loss: 2.0467459857463837, Validation Accuracy: 0.7419354838709677\n",
      "Precision: 0.7230769230769231, Recall: 0.8867924528301887, F1-score: 0.7966101694915254\n",
      "Epoch 4/100, Loss: 0.01783916965359822\n",
      "Validation Loss: 2.025684886922439, Validation Accuracy: 0.7150537634408602\n",
      "Precision: 0.712, Recall: 0.839622641509434, F1-score: 0.7705627705627706\n",
      "Epoch 5/100, Loss: 0.008127654143512094\n",
      "Validation Loss: 1.9713248958190281, Validation Accuracy: 0.7204301075268817\n",
      "Precision: 0.7288135593220338, Recall: 0.8113207547169812, F1-score: 0.7678571428571429\n",
      "Epoch 6/100, Loss: 0.004295350122144252\n",
      "Validation Loss: 2.012906844417254, Validation Accuracy: 0.7258064516129032\n",
      "Precision: 0.7235772357723578, Recall: 0.839622641509434, F1-score: 0.777292576419214\n",
      "Epoch 7/100, Loss: 0.0029247749201507154\n",
      "Validation Loss: 2.1004723086953163, Validation Accuracy: 0.7258064516129032\n",
      "Precision: 0.7235772357723578, Recall: 0.839622641509434, F1-score: 0.777292576419214\n",
      "Epoch 8/100, Loss: 0.002246494223982154\n",
      "Validation Loss: 2.2087858828405538, Validation Accuracy: 0.7311827956989247\n",
      "Precision: 0.7372881355932204, Recall: 0.8207547169811321, F1-score: 0.7767857142857143\n",
      "Epoch 9/100, Loss: 0.0017513226500038097\n",
      "Validation Loss: 2.1925489008426666, Validation Accuracy: 0.7419354838709677\n",
      "Precision: 0.7416666666666667, Recall: 0.839622641509434, F1-score: 0.7876106194690266\n",
      "Epoch 10/100, Loss: 0.0017724342889475035\n",
      "Validation Loss: 2.23490956860284, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.711864406779661, Recall: 0.7924528301886793, F1-score: 0.75\n",
      "Epoch 11/100, Loss: 0.0014066918536930946\n",
      "Validation Loss: 2.381029179940621, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7256637168141593, Recall: 0.7735849056603774, F1-score: 0.7488584474885844\n",
      "Epoch 12/100, Loss: 0.0010790041364998615\n",
      "Validation Loss: 2.437267338236173, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7207207207207207, Recall: 0.7547169811320755, F1-score: 0.7373271889400922\n",
      "Epoch 13/100, Loss: 0.0007781727639060895\n",
      "Validation Loss: 2.5432934102912745, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 14/100, Loss: 0.0006192647197925302\n",
      "Validation Loss: 2.5932034185777106, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7207207207207207, Recall: 0.7547169811320755, F1-score: 0.7373271889400922\n",
      "Epoch 15/100, Loss: 0.0006002183940836403\n",
      "Validation Loss: 2.6683330250283084, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 16/100, Loss: 0.00043751755826330435\n",
      "Validation Loss: 2.6864805333316326, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 17/100, Loss: 0.0004336379674138395\n",
      "Validation Loss: 2.7325987853109837, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 18/100, Loss: 0.0003995820111413195\n",
      "Validation Loss: 2.8236868201444545, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 19/100, Loss: 0.0004305878119860533\n",
      "Validation Loss: 2.8623401491592326, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7207207207207207, Recall: 0.7547169811320755, F1-score: 0.7373271889400922\n",
      "Epoch 20/100, Loss: 0.0004133164992102441\n",
      "Validation Loss: 2.9272245888908706, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 21/100, Loss: 0.0002902536945536364\n",
      "Validation Loss: 2.944394050166011, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 22/100, Loss: 0.00027263936246413323\n",
      "Validation Loss: 2.959213476628065, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 23/100, Loss: 0.00020980707874211171\n",
      "Validation Loss: 3.0306912076969943, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 24/100, Loss: 0.00026461178507967514\n",
      "Validation Loss: 3.0391626500835023, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 25/100, Loss: 0.0002490974911590153\n",
      "Validation Loss: 3.0472369703153768, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 26/100, Loss: 0.00018451136399259363\n",
      "Validation Loss: 3.156711665292581, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 27/100, Loss: 0.00016167418630175234\n",
      "Validation Loss: 3.143409668157498, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 28/100, Loss: 0.0001753043589853102\n",
      "Validation Loss: 3.164474161962668, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 29/100, Loss: 0.0001467284062073304\n",
      "Validation Loss: 3.1931155187388263, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 30/100, Loss: 0.00011371027471795969\n",
      "Validation Loss: 3.2558195839325585, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 31/100, Loss: 0.00013815339972704047\n",
      "Validation Loss: 3.3292578427741923, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 32/100, Loss: 0.0001438872309809843\n",
      "Validation Loss: 3.3141589170942702, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 33/100, Loss: 0.0001245984683843441\n",
      "Validation Loss: 3.3492255130161843, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 34/100, Loss: 0.00011398905489083215\n",
      "Validation Loss: 3.3789296858012676, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 35/100, Loss: 0.0001610679291464597\n",
      "Validation Loss: 3.4113238559414945, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 36/100, Loss: 0.0001114667299333405\n",
      "Validation Loss: 3.4346630250414214, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 37/100, Loss: 9.642889729851352e-05\n",
      "Validation Loss: 3.443528402596712, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 38/100, Loss: 8.887226316289798e-05\n",
      "Validation Loss: 3.55803476087749, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 39/100, Loss: 6.711094640869202e-05\n",
      "Validation Loss: 3.6094892943898835, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 40/100, Loss: 5.638128939248569e-05\n",
      "Validation Loss: 3.5289622358977795, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 41/100, Loss: 7.801680377876134e-05\n",
      "Validation Loss: 3.6196389676382146, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 42/100, Loss: 6.539010702984645e-05\n",
      "Validation Loss: 3.5595077065130076, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 43/100, Loss: 8.25012203146495e-05\n",
      "Validation Loss: 3.6052200148502984, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 44/100, Loss: 8.291276009231296e-05\n",
      "Validation Loss: 3.647330523158113, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 45/100, Loss: 6.547782118104806e-05\n",
      "Validation Loss: 3.6963079224030175, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 46/100, Loss: 5.650184472945815e-05\n",
      "Validation Loss: 3.6866428845872483, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 47/100, Loss: 5.185248958620529e-05\n",
      "Validation Loss: 3.618360615024964, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 48/100, Loss: 5.947027177436818e-05\n",
      "Validation Loss: 3.7842379212379456, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 49/100, Loss: 5.864802817582652e-05\n",
      "Validation Loss: 3.7823634886493287, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 50/100, Loss: 3.9294719816969824e-05\n",
      "Validation Loss: 3.7558315470814705, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 51/100, Loss: 5.0215686570709295e-05\n",
      "Validation Loss: 3.8002600564310947, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 52/100, Loss: 5.085779855562578e-05\n",
      "Validation Loss: 3.7791911996901035, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 53/100, Loss: 4.3947368107311036e-05\n",
      "Validation Loss: 3.8606919764230647, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 54/100, Loss: 5.162332942513596e-05\n",
      "Validation Loss: 3.820756777500113, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 55/100, Loss: 4.1957080979907836e-05\n",
      "Validation Loss: 3.827118213598927, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 56/100, Loss: 3.268918777621366e-05\n",
      "Validation Loss: 3.8360810869683823, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 57/100, Loss: 4.4612727682154706e-05\n",
      "Validation Loss: 3.8406205431868634, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 58/100, Loss: 4.152414602121013e-05\n",
      "Validation Loss: 3.8787701235463223, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 59/100, Loss: 3.9609783871223193e-05\n",
      "Validation Loss: 3.923589240759611, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 60/100, Loss: 3.0997265739074464e-05\n",
      "Validation Loss: 3.9172395213196674, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 61/100, Loss: 3.097319484860842e-05\n",
      "Validation Loss: 3.886955825611949, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 62/100, Loss: 2.5535972274800162e-05\n",
      "Validation Loss: 3.865978537748257, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 63/100, Loss: 3.4515364499535885e-05\n",
      "Validation Loss: 3.973385561257601, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 64/100, Loss: 3.804958456044005e-05\n",
      "Validation Loss: 3.82788268600901, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 65/100, Loss: 2.810573782596748e-05\n",
      "Validation Loss: 4.0653483010828495, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 66/100, Loss: 2.9499241129826714e-05\n",
      "Validation Loss: 4.001305776337783, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 67/100, Loss: 3.406514613546463e-05\n",
      "Validation Loss: 4.091453000282248, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 68/100, Loss: 2.3532397484871126e-05\n",
      "Validation Loss: 4.06439941128095, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 69/100, Loss: 2.762273216679508e-05\n",
      "Validation Loss: 3.978460982441902, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 70/100, Loss: 2.4761396784829987e-05\n",
      "Validation Loss: 3.9918367316325507, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 71/100, Loss: 3.2483870823737014e-05\n",
      "Validation Loss: 4.0240069056550665, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 72/100, Loss: 1.66344588545068e-05\n",
      "Validation Loss: 4.020498645802339, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 73/100, Loss: 3.0279499355856387e-05\n",
      "Validation Loss: 4.075462440028787, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 74/100, Loss: 2.3235170355443795e-05\n",
      "Validation Loss: 4.243770067269604, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7256637168141593, Recall: 0.7735849056603774, F1-score: 0.7488584474885844\n",
      "Epoch 75/100, Loss: 2.2077963213481173e-05\n",
      "Validation Loss: 4.1543411786357565, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 76/100, Loss: 2.260262204127154e-05\n",
      "Validation Loss: 4.189564457784097, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 77/100, Loss: 2.2909228052962288e-05\n",
      "Validation Loss: 4.21666278069218, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7256637168141593, Recall: 0.7735849056603774, F1-score: 0.7488584474885844\n",
      "Epoch 78/100, Loss: 2.2995856821713307e-05\n",
      "Validation Loss: 4.199046667665243, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7256637168141593, Recall: 0.7735849056603774, F1-score: 0.7488584474885844\n",
      "Epoch 79/100, Loss: 1.8802801447985e-05\n",
      "Validation Loss: 4.186858467757702, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 80/100, Loss: 2.316110841841616e-05\n",
      "Validation Loss: 4.210600147644679, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7256637168141593, Recall: 0.7735849056603774, F1-score: 0.7488584474885844\n",
      "Epoch 81/100, Loss: 1.9749321796306656e-05\n",
      "Validation Loss: 4.221504756559928, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7256637168141593, Recall: 0.7735849056603774, F1-score: 0.7488584474885844\n",
      "Epoch 82/100, Loss: 1.4706804768375529e-05\n",
      "Validation Loss: 4.162628335257371, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 83/100, Loss: 2.5302919008633278e-05\n",
      "Validation Loss: 4.3508706378440065, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7256637168141593, Recall: 0.7735849056603774, F1-score: 0.7488584474885844\n",
      "Epoch 84/100, Loss: 1.5110388748832785e-05\n",
      "Validation Loss: 4.296087589114904, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 85/100, Loss: 1.5417921514530402e-05\n",
      "Validation Loss: 4.283333705117305, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 86/100, Loss: 1.98645382774032e-05\n",
      "Validation Loss: 4.261717362950246, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7256637168141593, Recall: 0.7735849056603774, F1-score: 0.7488584474885844\n",
      "Epoch 87/100, Loss: 1.4594264467297316e-05\n",
      "Validation Loss: 4.4228437667091685, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7256637168141593, Recall: 0.7735849056603774, F1-score: 0.7488584474885844\n",
      "Epoch 88/100, Loss: 2.774160282588885e-05\n",
      "Validation Loss: 4.312721125781536, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7256637168141593, Recall: 0.7735849056603774, F1-score: 0.7488584474885844\n",
      "Epoch 89/100, Loss: 1.005743892020424e-05\n",
      "Validation Loss: 4.359289119640986, Validation Accuracy: 0.7043010752688172\n",
      "Precision: 0.7256637168141593, Recall: 0.7735849056603774, F1-score: 0.7488584474885844\n",
      "Epoch 90/100, Loss: 2.655640603421716e-05\n",
      "Validation Loss: 4.206865022579829, Validation Accuracy: 0.6935483870967742\n",
      "Precision: 0.7207207207207207, Recall: 0.7547169811320755, F1-score: 0.7373271889400922\n",
      "Epoch 91/100, Loss: 1.6347778721836903e-05\n",
      "Validation Loss: 4.351192732652028, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 92/100, Loss: 1.6153925396148832e-05\n",
      "Validation Loss: 4.333267991741498, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 93/100, Loss: 1.2925492460643303e-05\n",
      "Validation Loss: 4.426797948777676, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 94/100, Loss: 9.691676929435289e-06\n",
      "Validation Loss: 4.330069420238336, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 95/100, Loss: 1.4923288066478099e-05\n",
      "Validation Loss: 4.382961037258307, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 96/100, Loss: 1.3645880397206156e-05\n",
      "Validation Loss: 4.454315009216468, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 97/100, Loss: 1.2388787131574949e-05\n",
      "Validation Loss: 4.457755436499913, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 98/100, Loss: 1.0813795674617191e-05\n",
      "Validation Loss: 4.354886444906394, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 99/100, Loss: 9.009206920040924e-06\n",
      "Validation Loss: 4.417164819935958, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Epoch 100/100, Loss: 1.1215489116978006e-05\n",
      "Validation Loss: 4.406591989099979, Validation Accuracy: 0.6989247311827957\n",
      "Precision: 0.7232142857142857, Recall: 0.7641509433962265, F1-score: 0.7431192660550459\n",
      "Validation Loss: 0.9211562871932983, Validation Accuracy: 0.6827956989247311\n",
      "Precision: 0.719626168224299, Recall: 0.7264150943396226, F1-score: 0.7230046948356808\n",
      "Confusion Matrix:\n",
      "[[50 30]\n",
      " [29 77]]\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch 1/100, Loss: 0.2550421273141789\n",
      "Validation Loss: 6.7444245756736825, Validation Accuracy: 0.6649746192893401\n",
      "Precision: 1.0, Recall: 0.5448275862068965, F1-score: 0.7053571428571429\n",
      "Model saved to ensemble_model_fold_3.pth\n",
      "Epoch 2/100, Loss: 0.013975328755047181\n",
      "Validation Loss: 10.928648422335495, Validation Accuracy: 0.6852791878172588\n",
      "Precision: 0.9029126213592233, Recall: 0.6413793103448275, F1-score: 0.75\n",
      "Epoch 3/100, Loss: 0.0020170282550679985\n",
      "Validation Loss: 11.591570501019046, Validation Accuracy: 0.7106598984771574\n",
      "Precision: 0.9583333333333334, Recall: 0.6344827586206897, F1-score: 0.7634854771784232\n",
      "Epoch 4/100, Loss: 0.001541829915671163\n",
      "Validation Loss: 11.094492796913462, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9789473684210527, Recall: 0.6413793103448275, F1-score: 0.775\n",
      "Epoch 5/100, Loss: 0.002837443743070859\n",
      "Validation Loss: 13.18463774036536, Validation Accuracy: 0.7258883248730964\n",
      "Precision: 0.9789473684210527, Recall: 0.6413793103448275, F1-score: 0.775\n",
      "Epoch 6/100, Loss: 0.013582152598398048\n",
      "Validation Loss: 17.992583273244755, Validation Accuracy: 0.6852791878172588\n",
      "Precision: 0.9662921348314607, Recall: 0.593103448275862, F1-score: 0.7350427350427351\n",
      "Epoch 7/100, Loss: 0.002070676987993162\n",
      "Validation Loss: 17.48862481276904, Validation Accuracy: 0.6091370558375635\n",
      "Precision: 0.8333333333333334, Recall: 0.5862068965517241, F1-score: 0.6882591093117408\n",
      "Epoch 8/100, Loss: 0.000467502876593547\n",
      "Validation Loss: 17.891617607325315, Validation Accuracy: 0.6091370558375635\n",
      "Precision: 0.8333333333333334, Recall: 0.5862068965517241, F1-score: 0.6882591093117408\n",
      "Epoch 9/100, Loss: 0.00030826102795344923\n",
      "Validation Loss: 17.772404792053358, Validation Accuracy: 0.6091370558375635\n",
      "Precision: 0.8333333333333334, Recall: 0.5862068965517241, F1-score: 0.6882591093117408\n",
      "Epoch 10/100, Loss: 0.00022783641706306904\n",
      "Validation Loss: 17.614106905247485, Validation Accuracy: 0.6091370558375635\n",
      "Precision: 0.8333333333333334, Recall: 0.5862068965517241, F1-score: 0.6882591093117408\n",
      "Epoch 11/100, Loss: 0.02356220161728591\n",
      "Validation Loss: 17.093375010681935, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 12/100, Loss: 0.27079714090643847\n",
      "Validation Loss: 23.42183435053864, Validation Accuracy: 0.700507614213198\n",
      "Precision: 0.9056603773584906, Recall: 0.6620689655172414, F1-score: 0.7649402390438247\n",
      "Epoch 13/100, Loss: 0.03274232888607761\n",
      "Validation Loss: 21.30732665796365, Validation Accuracy: 0.6852791878172588\n",
      "Precision: 0.9029126213592233, Recall: 0.6413793103448275, F1-score: 0.75\n",
      "Epoch 14/100, Loss: 0.018958729324064432\n",
      "Validation Loss: 18.879280284263327, Validation Accuracy: 0.6852791878172588\n",
      "Precision: 0.9029126213592233, Recall: 0.6413793103448275, F1-score: 0.75\n",
      "Epoch 15/100, Loss: 0.0182978502348868\n",
      "Validation Loss: 31.962317875453405, Validation Accuracy: 0.6345177664974619\n",
      "Precision: 0.8924731182795699, Recall: 0.5724137931034483, F1-score: 0.6974789915966386\n",
      "Epoch 16/100, Loss: 0.002276182996454897\n",
      "Validation Loss: 34.45977449417114, Validation Accuracy: 0.6294416243654822\n",
      "Precision: 0.8913043478260869, Recall: 0.5655172413793104, F1-score: 0.6919831223628692\n",
      "Epoch 17/100, Loss: 0.00017958603989380131\n",
      "Validation Loss: 34.433364391326904, Validation Accuracy: 0.6294416243654822\n",
      "Precision: 0.8913043478260869, Recall: 0.5655172413793104, F1-score: 0.6919831223628692\n",
      "Epoch 18/100, Loss: 0.00012811749129563546\n",
      "Validation Loss: 34.699282714298796, Validation Accuracy: 0.6294416243654822\n",
      "Precision: 0.8913043478260869, Recall: 0.5655172413793104, F1-score: 0.6919831223628692\n",
      "Epoch 19/100, Loss: 0.00016491844084498553\n",
      "Validation Loss: 36.14108725956508, Validation Accuracy: 0.6294416243654822\n",
      "Precision: 0.8913043478260869, Recall: 0.5655172413793104, F1-score: 0.6919831223628692\n",
      "Epoch 20/100, Loss: 0.0021492033132594437\n",
      "Validation Loss: 35.42219270978655, Validation Accuracy: 0.6294416243654822\n",
      "Precision: 0.8913043478260869, Recall: 0.5655172413793104, F1-score: 0.6919831223628692\n",
      "Epoch 21/100, Loss: 0.21678752102314588\n",
      "Validation Loss: 33.604176010404316, Validation Accuracy: 0.6040609137055838\n",
      "Precision: 0.8850574712643678, Recall: 0.5310344827586206, F1-score: 0.6637931034482759\n",
      "Epoch 22/100, Loss: 0.33641246088273863\n",
      "Validation Loss: 30.63058180855439, Validation Accuracy: 0.6649746192893401\n",
      "Precision: 0.9157894736842105, Recall: 0.6, F1-score: 0.725\n",
      "Epoch 23/100, Loss: 0.69116410774753\n",
      "Validation Loss: 32.576667999582625, Validation Accuracy: 0.7157360406091371\n",
      "Precision: 1.0, Recall: 0.6137931034482759, F1-score: 0.7606837606837606\n",
      "Epoch 24/100, Loss: 0.4662947925221846\n",
      "Validation Loss: 34.58235887114097, Validation Accuracy: 0.5786802030456852\n",
      "Precision: 0.7870370370370371, Recall: 0.5862068965517241, F1-score: 0.6719367588932806\n",
      "Epoch 25/100, Loss: 0.008970303159912874\n",
      "Validation Loss: 32.01666466093489, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 26/100, Loss: 0.006287024874284934\n",
      "Validation Loss: 31.58671615858163, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 27/100, Loss: 0.004231402958750093\n",
      "Validation Loss: 33.32258363600287, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 28/100, Loss: 0.000299406960581422\n",
      "Validation Loss: 33.832643777664195, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 29/100, Loss: 0.0008812952221379696\n",
      "Validation Loss: 33.558274056227965, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 30/100, Loss: 0.00011594397005805963\n",
      "Validation Loss: 30.00040091680628, Validation Accuracy: 0.6649746192893401\n",
      "Precision: 0.9340659340659341, Recall: 0.5862068965517241, F1-score: 0.7203389830508474\n",
      "Epoch 31/100, Loss: 0.00012883414547124974\n",
      "Validation Loss: 33.067321361175594, Validation Accuracy: 0.6649746192893401\n",
      "Precision: 0.9340659340659341, Recall: 0.5862068965517241, F1-score: 0.7203389830508474\n",
      "Epoch 32/100, Loss: 9.14174132991552e-05\n",
      "Validation Loss: 33.78171582626444, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 33/100, Loss: 0.00017893777942445954\n",
      "Validation Loss: 35.12268876976197, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 34/100, Loss: 2.845671428512257e-05\n",
      "Validation Loss: 33.77268739204036, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 35/100, Loss: 0.00017896582354337554\n",
      "Validation Loss: 33.647690454231785, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 36/100, Loss: 0.0001853144619590926\n",
      "Validation Loss: 33.77745404360549, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 37/100, Loss: 0.00019798415598515362\n",
      "Validation Loss: 32.539190450417145, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 38/100, Loss: 4.776702105700285e-05\n",
      "Validation Loss: 31.441241795995406, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9239130434782609, Recall: 0.5862068965517241, F1-score: 0.7172995780590717\n",
      "Epoch 39/100, Loss: 5.171913815556669e-05\n",
      "Validation Loss: 31.1964019105902, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 40/100, Loss: 2.0389044406302997e-05\n",
      "Validation Loss: 31.53748933811272, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 41/100, Loss: 0.0005394324432419495\n",
      "Validation Loss: 31.896248108042133, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 42/100, Loss: 2.646075187628938e-05\n",
      "Validation Loss: 32.55793464396681, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 43/100, Loss: 4.4122733662989765e-05\n",
      "Validation Loss: 32.8239784772907, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 44/100, Loss: 0.0002447348057978138\n",
      "Validation Loss: 32.0288989911122, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 45/100, Loss: 3.960133638762168e-05\n",
      "Validation Loss: 33.196296150130884, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 46/100, Loss: 7.014704908728242e-05\n",
      "Validation Loss: 33.36623612897737, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 47/100, Loss: 9.173974847091297e-05\n",
      "Validation Loss: 33.66652029167329, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 48/100, Loss: 4.119885759508909e-05\n",
      "Validation Loss: 34.22994116693735, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 49/100, Loss: 4.417843061865767e-05\n",
      "Validation Loss: 34.091019549540114, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 50/100, Loss: 2.1392539406213846e-05\n",
      "Validation Loss: 33.74317297445876, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 51/100, Loss: 1.4216051290816267e-05\n",
      "Validation Loss: 33.52869882700698, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 52/100, Loss: 5.1720663799178133e-05\n",
      "Validation Loss: 33.9836405403912, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 53/100, Loss: 4.7522920768039434e-05\n",
      "Validation Loss: 34.30291014430778, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 54/100, Loss: 5.2166026846360104e-05\n",
      "Validation Loss: 34.07076975809676, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 55/100, Loss: 1.752980333668182e-05\n",
      "Validation Loss: 31.58935734363539, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 56/100, Loss: 1.0801407565624865e-05\n",
      "Validation Loss: 33.51732693772231, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 57/100, Loss: 0.0001597145342545995\n",
      "Validation Loss: 32.23972245412211, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 58/100, Loss: 2.189397849128305e-05\n",
      "Validation Loss: 31.407185505543435, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 59/100, Loss: 1.4166961297560713e-05\n",
      "Validation Loss: 28.90885606142027, Validation Accuracy: 0.6649746192893401\n",
      "Precision: 0.9247311827956989, Recall: 0.593103448275862, F1-score: 0.7226890756302521\n",
      "Epoch 60/100, Loss: 5.204994133386117e-05\n",
      "Validation Loss: 31.85193438615118, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 61/100, Loss: 6.062189586764077e-06\n",
      "Validation Loss: 33.83733994939497, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 62/100, Loss: 1.5346725730743433e-05\n",
      "Validation Loss: 32.10658981917159, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 63/100, Loss: 1.2326856949370265e-05\n",
      "Validation Loss: 33.74493306555918, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 64/100, Loss: 1.1307161314024391e-05\n",
      "Validation Loss: 33.41873126689877, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 65/100, Loss: 2.2938054814088577e-05\n",
      "Validation Loss: 32.468458025051014, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 66/100, Loss: 1.326770886513525e-05\n",
      "Validation Loss: 31.185718030801837, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 67/100, Loss: 5.879851062895458e-05\n",
      "Validation Loss: 32.46556126911723, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 68/100, Loss: 0.00015643187639894732\n",
      "Validation Loss: 33.57192927439297, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 69/100, Loss: 4.418888031959556e-06\n",
      "Validation Loss: 28.969796862453222, Validation Accuracy: 0.6802030456852792\n",
      "Precision: 0.9361702127659575, Recall: 0.6068965517241379, F1-score: 0.7364016736401674\n",
      "Epoch 70/100, Loss: 1.3148998477115667e-05\n",
      "Validation Loss: 32.90261616504618, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 71/100, Loss: 3.236752507485008e-05\n",
      "Validation Loss: 31.779945377792632, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 72/100, Loss: 0.00024368506863832926\n",
      "Validation Loss: 32.329179957509034, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 73/100, Loss: 2.9756480973447408e-05\n",
      "Validation Loss: 34.492573712021105, Validation Accuracy: 0.6548223350253807\n",
      "Precision: 0.9139784946236559, Recall: 0.5862068965517241, F1-score: 0.7142857142857143\n",
      "Epoch 74/100, Loss: 1.584044394052168e-05\n",
      "Validation Loss: 29.42262079194188, Validation Accuracy: 0.6802030456852792\n",
      "Precision: 0.9361702127659575, Recall: 0.6068965517241379, F1-score: 0.7364016736401674\n",
      "Epoch 75/100, Loss: 2.6576146384710286e-05\n",
      "Validation Loss: 33.34064570867589, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 76/100, Loss: 9.146590712744151e-06\n",
      "Validation Loss: 33.45645068798746, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 77/100, Loss: 2.8618475890399935e-05\n",
      "Validation Loss: 33.35168578156403, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 78/100, Loss: 9.695234799877994e-06\n",
      "Validation Loss: 33.00608833027737, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 79/100, Loss: 6.942378668819045e-06\n",
      "Validation Loss: 31.982542315764082, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 80/100, Loss: 7.456531006736859e-05\n",
      "Validation Loss: 32.52568698301911, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 81/100, Loss: 8.414904385449043e-06\n",
      "Validation Loss: 27.832965519811427, Validation Accuracy: 0.6852791878172588\n",
      "Precision: 0.9278350515463918, Recall: 0.6206896551724138, F1-score: 0.743801652892562\n",
      "Epoch 82/100, Loss: 4.386335116522237e-06\n",
      "Validation Loss: 33.35694936556475, Validation Accuracy: 0.6700507614213198\n",
      "Precision: 0.9166666666666666, Recall: 0.6068965517241379, F1-score: 0.7302904564315352\n",
      "Epoch 83/100, Loss: 7.5908821096000905e-06\n",
      "Validation Loss: 32.00538063475064, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 84/100, Loss: 1.3409121049079431e-05\n",
      "Validation Loss: 32.0781151418175, Validation Accuracy: 0.6700507614213198\n",
      "Precision: 0.9166666666666666, Recall: 0.6068965517241379, F1-score: 0.7302904564315352\n",
      "Epoch 85/100, Loss: 1.0107878792187108e-05\n",
      "Validation Loss: 34.458375935043605, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 86/100, Loss: 1.9878150340435496e-05\n",
      "Validation Loss: 32.62610859796405, Validation Accuracy: 0.6700507614213198\n",
      "Precision: 0.9166666666666666, Recall: 0.6068965517241379, F1-score: 0.7302904564315352\n",
      "Epoch 87/100, Loss: 1.370248643838464e-05\n",
      "Validation Loss: 34.35600371818457, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 88/100, Loss: 5.003403016049883e-06\n",
      "Validation Loss: 29.102605183741876, Validation Accuracy: 0.6700507614213198\n",
      "Precision: 0.9347826086956522, Recall: 0.593103448275862, F1-score: 0.7257383966244726\n",
      "Epoch 89/100, Loss: 5.486961190866631e-06\n",
      "Validation Loss: 28.83790635317564, Validation Accuracy: 0.6802030456852792\n",
      "Precision: 0.9361702127659575, Recall: 0.6068965517241379, F1-score: 0.7364016736401674\n",
      "Epoch 90/100, Loss: 9.680596571905639e-06\n",
      "Validation Loss: 34.148615857852356, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 91/100, Loss: 1.7726252075744853e-05\n",
      "Validation Loss: 33.55713376402855, Validation Accuracy: 0.6598984771573604\n",
      "Precision: 0.9148936170212766, Recall: 0.593103448275862, F1-score: 0.7196652719665272\n",
      "Epoch 92/100, Loss: 0.00021153129214009544\n",
      "Validation Loss: 32.669358629733324, Validation Accuracy: 0.6700507614213198\n",
      "Precision: 0.9166666666666666, Recall: 0.6068965517241379, F1-score: 0.7302904564315352\n",
      "Epoch 93/100, Loss: 1.475898959898044e-05\n",
      "Validation Loss: 32.39137096383742, Validation Accuracy: 0.6700507614213198\n",
      "Precision: 0.9166666666666666, Recall: 0.6068965517241379, F1-score: 0.7302904564315352\n",
      "Epoch 94/100, Loss: 1.6887914548596727e-05\n",
      "Validation Loss: 32.47137063369155, Validation Accuracy: 0.6700507614213198\n",
      "Precision: 0.9166666666666666, Recall: 0.6068965517241379, F1-score: 0.7302904564315352\n",
      "Epoch 95/100, Loss: 4.150407692256793e-05\n",
      "Validation Loss: 33.42189526717578, Validation Accuracy: 0.6700507614213198\n",
      "Precision: 0.9166666666666666, Recall: 0.6068965517241379, F1-score: 0.7302904564315352\n",
      "Epoch 96/100, Loss: 7.5153189533309446e-06\n",
      "Validation Loss: 33.20179786639494, Validation Accuracy: 0.6446700507614214\n",
      "Precision: 0.8865979381443299, Recall: 0.593103448275862, F1-score: 0.7107438016528925\n",
      "Epoch 97/100, Loss: 1.0964290471223345e-05\n",
      "Validation Loss: 32.747005362063646, Validation Accuracy: 0.6751269035532995\n",
      "Precision: 0.9175257731958762, Recall: 0.6137931034482759, F1-score: 0.7355371900826446\n",
      "Epoch 98/100, Loss: 1.5933889330188578e-06\n",
      "Validation Loss: 31.694328393787146, Validation Accuracy: 0.6802030456852792\n",
      "Precision: 0.9183673469387755, Recall: 0.6206896551724138, F1-score: 0.7407407407407407\n",
      "Epoch 99/100, Loss: 3.298570817378277e-06\n",
      "Validation Loss: 29.07538802868553, Validation Accuracy: 0.6700507614213198\n",
      "Precision: 0.9166666666666666, Recall: 0.6068965517241379, F1-score: 0.7302904564315352\n",
      "Epoch 100/100, Loss: 5.206933618874994e-06\n",
      "Validation Loss: 32.319113069346976, Validation Accuracy: 0.6751269035532995\n",
      "Precision: 0.9175257731958762, Recall: 0.6137931034482759, F1-score: 0.7355371900826446\n",
      "Validation Loss: 6.7444245756736825, Validation Accuracy: 0.6649746192893401\n",
      "Precision: 1.0, Recall: 0.5448275862068965, F1-score: 0.7053571428571429\n",
      "Confusion Matrix:\n",
      "[[52  0]\n",
      " [66 79]]\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch 1/100, Loss: 0.6568854057695717\n",
      "Validation Loss: 0.598573577989425, Validation Accuracy: 0.7908163265306123\n",
      "Precision: 0.8245614035087719, Recall: 0.8173913043478261, F1-score: 0.8209606986899564\n",
      "Model saved to ensemble_model_fold_4.pth\n",
      "Epoch 2/100, Loss: 0.17372079127623388\n",
      "Validation Loss: 1.2491931578302424, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.875, Recall: 0.8521739130434782, F1-score: 0.8634361233480177\n",
      "Epoch 3/100, Loss: 0.05509221213287674\n",
      "Validation Loss: 1.75294767309567, Validation Accuracy: 0.7908163265306123\n",
      "Precision: 0.7846153846153846, Recall: 0.8869565217391304, F1-score: 0.8326530612244898\n",
      "Epoch 4/100, Loss: 0.24535614914687662\n",
      "Validation Loss: 1.6824380309426488, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8938053097345132, Recall: 0.8782608695652174, F1-score: 0.8859649122807017\n",
      "Epoch 5/100, Loss: 0.02778257106547244\n",
      "Validation Loss: 2.1877691311771224, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8793103448275862, Recall: 0.8869565217391304, F1-score: 0.8831168831168831\n",
      "Epoch 6/100, Loss: 0.0431290533185044\n",
      "Validation Loss: 2.4901374253761284, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 7/100, Loss: 0.007694609830953898\n",
      "Validation Loss: 2.5148179504452526, Validation Accuracy: 0.8520408163265306\n",
      "Precision: 0.864406779661017, Recall: 0.8869565217391304, F1-score: 0.8755364806866953\n",
      "Epoch 8/100, Loss: 0.00322686615678928\n",
      "Validation Loss: 2.6076357912787325, Validation Accuracy: 0.8469387755102041\n",
      "Precision: 0.8571428571428571, Recall: 0.8869565217391304, F1-score: 0.8717948717948718\n",
      "Epoch 9/100, Loss: 0.0013487936224313064\n",
      "Validation Loss: 2.448679418963788, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 10/100, Loss: 0.0009184644253158089\n",
      "Validation Loss: 2.390079827709768, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 11/100, Loss: 0.0012869784632130177\n",
      "Validation Loss: 2.1318289413943563, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 12/100, Loss: 0.012090246685602324\n",
      "Validation Loss: 2.507807206890282, Validation Accuracy: 0.8469387755102041\n",
      "Precision: 0.8571428571428571, Recall: 0.8869565217391304, F1-score: 0.8717948717948718\n",
      "Epoch 13/100, Loss: 0.04268205183385968\n",
      "Validation Loss: 2.7018329787236843, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 14/100, Loss: 0.0076821217327657605\n",
      "Validation Loss: 2.792058927982233, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 15/100, Loss: 0.012882078137787781\n",
      "Validation Loss: 2.876863831494597, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 16/100, Loss: 0.0010951944760932975\n",
      "Validation Loss: 3.0941577654653707, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 17/100, Loss: 0.0006269044659958922\n",
      "Validation Loss: 3.0107835126460105, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 18/100, Loss: 0.00040045997487444157\n",
      "Validation Loss: 3.068686055249419, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 19/100, Loss: 0.00041779614923598274\n",
      "Validation Loss: 3.070895369521831, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 20/100, Loss: 0.0005619724804605634\n",
      "Validation Loss: 3.1675357190579154, Validation Accuracy: 0.8367346938775511\n",
      "Precision: 0.8429752066115702, Recall: 0.8869565217391304, F1-score: 0.864406779661017\n",
      "Epoch 21/100, Loss: 0.00027651526481046557\n",
      "Validation Loss: 3.0390808204370177, Validation Accuracy: 0.8367346938775511\n",
      "Precision: 0.8429752066115702, Recall: 0.8869565217391304, F1-score: 0.864406779661017\n",
      "Epoch 22/100, Loss: 0.0002605014084196\n",
      "Validation Loss: 3.0825115942458257, Validation Accuracy: 0.8367346938775511\n",
      "Precision: 0.8429752066115702, Recall: 0.8869565217391304, F1-score: 0.864406779661017\n",
      "Epoch 23/100, Loss: 0.00029740417625134796\n",
      "Validation Loss: 3.1179511520312864, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 24/100, Loss: 0.0002481125520906365\n",
      "Validation Loss: 3.281372157057885, Validation Accuracy: 0.8367346938775511\n",
      "Precision: 0.8429752066115702, Recall: 0.8869565217391304, F1-score: 0.864406779661017\n",
      "Epoch 25/100, Loss: 0.0002962966196875527\n",
      "Validation Loss: 3.111006422224185, Validation Accuracy: 0.8367346938775511\n",
      "Precision: 0.8429752066115702, Recall: 0.8869565217391304, F1-score: 0.864406779661017\n",
      "Epoch 26/100, Loss: 0.0007181562363408981\n",
      "Validation Loss: 2.878289198619679, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 27/100, Loss: 0.00047028724437344255\n",
      "Validation Loss: 2.829606036201767, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 28/100, Loss: 0.00027104985204573495\n",
      "Validation Loss: 3.181695115826046, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 29/100, Loss: 0.0011135039408429748\n",
      "Validation Loss: 3.2641682384573656, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 30/100, Loss: 0.005574727356034259\n",
      "Validation Loss: 3.1722116405736154, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 31/100, Loss: 0.002204341134643073\n",
      "Validation Loss: 3.8038983498341037, Validation Accuracy: 0.8163265306122449\n",
      "Precision: 0.816, Recall: 0.8869565217391304, F1-score: 0.85\n",
      "Epoch 32/100, Loss: 0.001281539068723229\n",
      "Validation Loss: 3.9472850577024508, Validation Accuracy: 0.8163265306122449\n",
      "Precision: 0.816, Recall: 0.8869565217391304, F1-score: 0.85\n",
      "Epoch 33/100, Loss: 0.00022351019731559063\n",
      "Validation Loss: 3.31440507766495, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 34/100, Loss: 0.00019733480455386143\n",
      "Validation Loss: 3.612369936424102, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 35/100, Loss: 0.00013695561777637977\n",
      "Validation Loss: 3.849838911420574, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 36/100, Loss: 0.0001866140298384759\n",
      "Validation Loss: 3.423729485680172, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 37/100, Loss: 0.0001057241765352046\n",
      "Validation Loss: 3.1670188462740043, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 38/100, Loss: 0.00041799460038779063\n",
      "Validation Loss: 3.4900700970397014, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 39/100, Loss: 0.0001518677402610654\n",
      "Validation Loss: 3.7765401750784884, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 40/100, Loss: 0.00011452528249182119\n",
      "Validation Loss: 3.8107747563281413, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 41/100, Loss: 0.00015678152575067847\n",
      "Validation Loss: 3.8371059303824495, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 42/100, Loss: 9.756724209116403e-05\n",
      "Validation Loss: 3.4136113879499783, Validation Accuracy: 0.8367346938775511\n",
      "Precision: 0.8429752066115702, Recall: 0.8869565217391304, F1-score: 0.864406779661017\n",
      "Epoch 43/100, Loss: 0.0001174799273992259\n",
      "Validation Loss: 3.247519108263597, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 44/100, Loss: 6.240024301954843e-05\n",
      "Validation Loss: 3.3846749968174015, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 45/100, Loss: 0.00012163239799178882\n",
      "Validation Loss: 3.9499331760617684, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 46/100, Loss: 7.099862663532501e-05\n",
      "Validation Loss: 3.7594908438612316, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 47/100, Loss: 5.990818826617783e-05\n",
      "Validation Loss: 3.906959847147667, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 48/100, Loss: 0.00021262944278917692\n",
      "Validation Loss: 3.586986342709127, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 49/100, Loss: 5.548683075318195e-05\n",
      "Validation Loss: 3.4877636586754113, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 50/100, Loss: 7.757288855891886e-05\n",
      "Validation Loss: 3.7675182303144914, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 51/100, Loss: 9.150201971882173e-05\n",
      "Validation Loss: 3.975709347852593, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 52/100, Loss: 0.00014823598856613293\n",
      "Validation Loss: 3.9371089498910754, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 53/100, Loss: 0.00014734310603851478\n",
      "Validation Loss: 3.6184454054666566, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 54/100, Loss: 0.00018477470472610946\n",
      "Validation Loss: 3.772292329796439, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 55/100, Loss: 4.7595897811447685e-05\n",
      "Validation Loss: 3.963719304118809, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 56/100, Loss: 0.00010116535418891459\n",
      "Validation Loss: 3.8933749475648693, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 57/100, Loss: 5.638595395396351e-05\n",
      "Validation Loss: 3.874950438737798, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 58/100, Loss: 9.395352936092394e-05\n",
      "Validation Loss: 3.7767679121875313, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 59/100, Loss: 9.60718051559913e-05\n",
      "Validation Loss: 3.855674337595612, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 60/100, Loss: 6.111045509031114e-05\n",
      "Validation Loss: 3.9405628762074434, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 61/100, Loss: 4.620487237320484e-05\n",
      "Validation Loss: 3.6958757905014994, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 62/100, Loss: 4.2984710533507574e-05\n",
      "Validation Loss: 3.1759547892132622, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 63/100, Loss: 6.52246905588072e-05\n",
      "Validation Loss: 3.6581757478382024, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 64/100, Loss: 6.375641168173314e-05\n",
      "Validation Loss: 3.940012972269705, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 65/100, Loss: 4.1025601850227154e-05\n",
      "Validation Loss: 3.5558340677162414, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 66/100, Loss: 4.1430580220473225e-05\n",
      "Validation Loss: 3.8986658842435418, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 67/100, Loss: 0.00011099344668726492\n",
      "Validation Loss: 3.7635729786538508, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 68/100, Loss: 4.438916422492648e-05\n",
      "Validation Loss: 3.9508826290922374, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 69/100, Loss: 2.8397885943813133e-05\n",
      "Validation Loss: 3.4880269483649777, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 70/100, Loss: 6.0772671086876486e-05\n",
      "Validation Loss: 3.665589971201394, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 71/100, Loss: 0.00011577980058063986\n",
      "Validation Loss: 3.6552772937071714, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 72/100, Loss: 6.339466065798567e-05\n",
      "Validation Loss: 4.015301387757044, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 73/100, Loss: 9.029242065790773e-05\n",
      "Validation Loss: 3.6077059464783923, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 74/100, Loss: 5.5743776828857485e-05\n",
      "Validation Loss: 3.8520880586334068, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 75/100, Loss: 5.43967268011869e-05\n",
      "Validation Loss: 4.004581916012922, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 76/100, Loss: 6.889836301038343e-05\n",
      "Validation Loss: 3.760291952639538, Validation Accuracy: 0.8316326530612245\n",
      "Precision: 0.8360655737704918, Recall: 0.8869565217391304, F1-score: 0.8607594936708861\n",
      "Epoch 77/100, Loss: 0.00032607247193094935\n",
      "Validation Loss: 4.173602631581673, Validation Accuracy: 0.826530612244898\n",
      "Precision: 0.8292682926829268, Recall: 0.8869565217391304, F1-score: 0.8571428571428571\n",
      "Epoch 78/100, Loss: 0.0001082738499995628\n",
      "Validation Loss: 3.8923959726961193, Validation Accuracy: 0.8367346938775511\n",
      "Precision: 0.8429752066115702, Recall: 0.8869565217391304, F1-score: 0.864406779661017\n",
      "Epoch 79/100, Loss: 0.012127080680796118\n",
      "Validation Loss: 4.165173463271848, Validation Accuracy: 0.8724489795918368\n",
      "Precision: 0.8947368421052632, Recall: 0.8869565217391304, F1-score: 0.8908296943231441\n",
      "Epoch 80/100, Loss: 0.848284119631605\n",
      "Validation Loss: 6.715629850115095, Validation Accuracy: 0.8061224489795918\n",
      "Precision: 0.8407079646017699, Recall: 0.8260869565217391, F1-score: 0.8333333333333334\n",
      "Epoch 81/100, Loss: 0.06958574751312578\n",
      "Validation Loss: 4.40969614844237, Validation Accuracy: 0.8418367346938775\n",
      "Precision: 0.85, Recall: 0.8869565217391304, F1-score: 0.8680851063829788\n",
      "Epoch 82/100, Loss: 0.042275597734771964\n",
      "Validation Loss: 4.011887101622826, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8793103448275862, Recall: 0.8869565217391304, F1-score: 0.8831168831168831\n",
      "Epoch 83/100, Loss: 0.009534512677217796\n",
      "Validation Loss: 4.4152762671626204, Validation Accuracy: 0.8571428571428571\n",
      "Precision: 0.8717948717948718, Recall: 0.8869565217391304, F1-score: 0.8793103448275862\n",
      "Epoch 84/100, Loss: 0.008612191675543576\n",
      "Validation Loss: 4.3584537691063545, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8793103448275862, Recall: 0.8869565217391304, F1-score: 0.8831168831168831\n",
      "Epoch 85/100, Loss: 0.002791063222874849\n",
      "Validation Loss: 4.000904697816745, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8793103448275862, Recall: 0.8869565217391304, F1-score: 0.8831168831168831\n",
      "Epoch 86/100, Loss: 0.0003606542074443553\n",
      "Validation Loss: 4.521540219684409, Validation Accuracy: 0.8622448979591837\n",
      "Precision: 0.8793103448275862, Recall: 0.8869565217391304, F1-score: 0.8831168831168831\n",
      "Epoch 87/100, Loss: 0.0002285996230793804\n",
      "Validation Loss: 4.82845325341613, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 88/100, Loss: 0.0007365753820115136\n",
      "Validation Loss: 4.211257367336656, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 89/100, Loss: 0.00025960885686041973\n",
      "Validation Loss: 4.721207865086334, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 90/100, Loss: 0.005874363305405694\n",
      "Validation Loss: 4.989086827321962, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 91/100, Loss: 0.02398135885248583\n",
      "Validation Loss: 5.038641099582359, Validation Accuracy: 0.8112244897959183\n",
      "Precision: 0.8095238095238095, Recall: 0.8869565217391304, F1-score: 0.8464730290456431\n",
      "Epoch 92/100, Loss: 0.054965473665485355\n",
      "Validation Loss: 6.111084776374075, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 93/100, Loss: 0.0013663323691919989\n",
      "Validation Loss: 6.516889504546386, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 94/100, Loss: 0.0004343379836223941\n",
      "Validation Loss: 6.692802091753295, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 95/100, Loss: 0.0002663823053058086\n",
      "Validation Loss: 6.611399112913398, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 96/100, Loss: 0.00029519575732213826\n",
      "Validation Loss: 6.6102911749718, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 97/100, Loss: 0.0003425356362261785\n",
      "Validation Loss: 6.774511011573914, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 98/100, Loss: 0.0007882021248069767\n",
      "Validation Loss: 6.181022167670946, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 99/100, Loss: 0.00017128703854041305\n",
      "Validation Loss: 5.936680100249105, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Epoch 100/100, Loss: 0.0003792853226679919\n",
      "Validation Loss: 5.8588704590391405, Validation Accuracy: 0.8673469387755102\n",
      "Precision: 0.8869565217391304, Recall: 0.8869565217391304, F1-score: 0.8869565217391304\n",
      "Validation Loss: 0.598573577989425, Validation Accuracy: 0.7908163265306123\n",
      "Precision: 0.8245614035087719, Recall: 0.8173913043478261, F1-score: 0.8209606986899564\n",
      "Confusion Matrix:\n",
      "[[61 20]\n",
      " [21 94]]\n",
      "\n",
      "Average results across all folds:\n",
      "Accuracy: 0.7876\n",
      "Precision: 0.8492\n",
      "Recall: 0.8314\n",
      "F1-score: 0.8324\n",
      "Final model saved to final_ensemble_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 51), padding='same')\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.depthwiseConv2d = nn.Conv2d(16, 32, (65, 1), groups=16, padding='same')\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.activation = nn.ELU()\n",
    "        self.pooling = nn.AvgPool2d((1, 4))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(32 * 65 * 31, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.depthwiseConv2d(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class PolygraphNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(PolygraphNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 51), padding='same')\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.depthwiseConv2d = nn.Conv2d(16, 32, (4, 1), groups=16, padding='same')\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.activation = nn.ELU()\n",
    "        self.pooling = nn.AvgPool2d((1, 4))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(32 * 4 * 1118, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.depthwiseConv2d(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, eeg_model, poly_model):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.eeg_model = eeg_model\n",
    "        self.poly_model = poly_model\n",
    "        self.fc = nn.Linear(4, 2)\n",
    "\n",
    "    def forward(self, eeg_input, poly_input):\n",
    "        eeg_output = self.eeg_model(eeg_input)\n",
    "        poly_output = self.poly_model(poly_input)\n",
    "        combined_output = torch.cat((eeg_output, poly_output), dim=1)\n",
    "        output = self.fc(combined_output)\n",
    "        return output\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    all_labels, all_predictions = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for eeg_X_batch, eeg_y_batch, poly_X_batch, poly_y_batch in data_loader:\n",
    "            eeg_X_batch, poly_X_batch = eeg_X_batch.to(device), poly_X_batch.to(device)\n",
    "            labels = eeg_y_batch.to(device)  # Use EEG labels (they should be the same as Poly labels)\n",
    "            \n",
    "            outputs = model(eeg_X_batch, poly_X_batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(all_labels, all_predictions, average='binary', zero_division=1)\n",
    "    recall = recall_score(all_labels, all_predictions, average='binary', zero_division=1)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='binary', zero_division=1)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions, labels=[0, 1])\n",
    "\n",
    "    return total_loss / len(data_loader), accuracy, precision, recall, f1, conf_matrix\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, save_path):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for eeg_X_batch, eeg_y_batch, poly_X_batch, poly_y_batch in train_loader:\n",
    "            eeg_X_batch, poly_X_batch = eeg_X_batch.to(device), poly_X_batch.to(device)\n",
    "            labels = eeg_y_batch.to(device)  # Use EEG labels (they should be the same as Poly labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(eeg_X_batch, poly_X_batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss}')\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy, val_precision, val_recall, val_f1, val_conf_matrix = evaluate_model(model, val_loader, criterion, device)\n",
    "        print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "        print(f'Precision: {val_precision}, Recall: {val_recall}, F1-score: {val_f1}')\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'val_accuracy': val_accuracy,\n",
    "                'val_precision': val_precision,\n",
    "                'val_recall': val_recall,\n",
    "                'val_f1': val_f1,\n",
    "            }, save_path)\n",
    "            print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "# Load data\n",
    "print(\"Loading EEG data...\")\n",
    "eeg_X, eeg_y, file_sample_counts = load_eeg_data(EEG_DATA_DIR)\n",
    "print(\"Loading Poly data...\")\n",
    "poly_X, poly_y = load_poly_data(POLY_DATA_DIR)\n",
    "\n",
    "# Create splits based on file indices\n",
    "splits = create_file_based_splits(file_sample_counts, n_splits=5)\n",
    "\n",
    "for fold, (train_file_indices, val_file_indices) in enumerate(splits):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Split data based on file indices\n",
    "    train_sample_counts = [file_sample_counts[i] for i in train_file_indices]\n",
    "    val_sample_counts = [file_sample_counts[i] for i in val_file_indices]\n",
    "    \n",
    "    train_eeg_indices = np.concatenate([np.arange(sum(file_sample_counts[:i]), \n",
    "                                                  sum(file_sample_counts[:i+1])) \n",
    "                                        for i in train_file_indices])\n",
    "    val_eeg_indices = np.concatenate([np.arange(sum(file_sample_counts[:i]), \n",
    "                                                sum(file_sample_counts[:i+1])) \n",
    "                                      for i in val_file_indices])\n",
    "\n",
    "    # Split EEG data\n",
    "    train_eeg_X, train_eeg_y = eeg_X[train_eeg_indices], eeg_y[train_eeg_indices]\n",
    "    val_eeg_X, val_eeg_y = eeg_X[val_eeg_indices], eeg_y[val_eeg_indices]\n",
    "\n",
    "    # Split Poly data\n",
    "    train_poly_X, train_poly_y = poly_X[train_file_indices], poly_y[train_file_indices]\n",
    "    val_poly_X, val_poly_y = poly_X[val_file_indices], poly_y[val_file_indices]\n",
    "\n",
    "    # Normalize data for this fold\n",
    "    eeg_scaler = StandardScaler()\n",
    "    poly_scaler = StandardScaler()\n",
    "\n",
    "\n",
    "    train_eeg_X_2d = train_eeg_X.reshape(-1, train_eeg_X.shape[-1])  \n",
    "    train_eeg_X_2d_scaled = eeg_scaler.fit_transform(train_eeg_X_2d)\n",
    "    train_eeg_X_scaled = train_eeg_X_2d_scaled.reshape(train_eeg_X.shape)\n",
    "    \n",
    "    # Reshape and transform validation data\n",
    "    val_eeg_X_2d = val_eeg_X.reshape(-1, val_eeg_X.shape[-1])\n",
    "    val_eeg_X_2d_scaled = eeg_scaler.transform(val_eeg_X_2d)\n",
    "    val_eeg_X_scaled = val_eeg_X_2d_scaled.reshape(val_eeg_X.shape)\n",
    "    \n",
    "    train_poly_X_2d = train_poly_X.reshape(-1, train_poly_X.shape[-1])\n",
    "    train_poly_X_2d_scaled = poly_scaler.fit_transform(train_poly_X_2d)\n",
    "    train_poly_X_scaled = train_poly_X_2d_scaled.reshape(train_poly_X.shape)\n",
    "    \n",
    "    val_poly_X_2d = val_poly_X.reshape(-1, val_poly_X.shape[-1])\n",
    "    val_poly_X_2d_scaled = poly_scaler.transform(val_poly_X_2d)\n",
    "    val_poly_X_scaled = val_poly_X_2d_scaled.reshape(val_poly_X.shape)\n",
    "\n",
    "    # Create datasets for this fold\n",
    "    train_dataset = CombinedDataset(train_eeg_X_scaled, train_eeg_y, train_poly_X_scaled, train_poly_y, train_sample_counts)\n",
    "    val_dataset = CombinedDataset(val_eeg_X_scaled, val_eeg_y, val_poly_X_scaled, val_poly_y, val_sample_counts)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize models\n",
    "    eeg_model = EEGNet(num_classes=2).to(device)\n",
    "    poly_model = PolygraphNet(num_classes=2).to(device)\n",
    "    ensemble_model = EnsembleModel(eeg_model, poly_model).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    ensemble_optimizer = optim.Adam(ensemble_model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train and evaluate model (rest of your code remains the same)\n",
    "    ...\n",
    "    # Train the model and save it\n",
    "    save_path = f'ensemble_model_fold_{fold}.pth'\n",
    "    best_model_path = train_model(ensemble_model, train_loader, val_loader, criterion, ensemble_optimizer, num_epochs, device, save_path)\n",
    "\n",
    "    # Load the best model and evaluate on validation set\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    ensemble_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    val_loss, val_accuracy, val_precision, val_recall, val_f1, val_conf_matrix = evaluate_model(ensemble_model, val_loader, criterion, device)\n",
    "    \n",
    "    print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "    print(f'Precision: {val_precision}, Recall: {val_recall}, F1-score: {val_f1}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(val_conf_matrix)\n",
    "    \n",
    "    results.append({\n",
    "        'fold': fold,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    })\n",
    "\n",
    "# Print average results\n",
    "avg_accuracy = np.mean([r['val_accuracy'] for r in results])\n",
    "avg_precision = np.mean([r['val_precision'] for r in results])\n",
    "avg_recall = np.mean([r['val_recall'] for r in results])\n",
    "avg_f1 = np.mean([r['val_f1'] for r in results])\n",
    "\n",
    "print(\"\\nAverage results across all folds:\")\n",
    "print(f\"Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Precision: {avg_precision:.4f}\")\n",
    "print(f\"Recall: {avg_recall:.4f}\")\n",
    "print(f\"F1-score: {avg_f1:.4f}\")\n",
    "\n",
    "# Save the final model (you can choose to save the model from the best fold instead)\n",
    "final_model_path = 'final_ensemble_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': ensemble_model.state_dict(),\n",
    "    'avg_accuracy': avg_accuracy,\n",
    "    'avg_precision': avg_precision,\n",
    "    'avg_recall': avg_recall,\n",
    "    'avg_f1': avg_f1,\n",
    "}, final_model_path)\n",
    "print(f\"Final model saved to {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911294f-a9f1-4b9a-a912-afea5f59c972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
